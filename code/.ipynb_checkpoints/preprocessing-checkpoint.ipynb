{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "34690b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json, os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "from transformers import AutoTokenizer, TFAutoModel, TFAutoModelForSequenceClassification #, BertModel, BertTokenizer, TFBertForSequenceClassification\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.backend as K\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, \\\n",
    "roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool1D\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e0fe139",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "491f340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join('..','data', 'ffmpeg_data_reduced.csv'))\n",
    "#data = pd.read_csv(os.path.join('..','data', 'qemu_data_reduced.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bf86a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    4624\n",
      "0    4434\n",
      "Name: target, dtype: int64\n",
      "565\n"
     ]
    }
   ],
   "source": [
    "print(data[\"target\"].value_counts())\n",
    "max_length = data['length'].max()\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a12568c",
   "metadata": {},
   "source": [
    "Word2Vec NL pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af9f6531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.test.utils import common_texts\n",
    "# from gensim.models import Word2Vec\n",
    "\n",
    "# model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "# model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0d3cbee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "# w2v_vectors = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1af13111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w2v_vectors.most_similar('facebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8625eba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\iliaskaloup\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download the Punkt tokenizer models if not already downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "tokenized_list = [word_tokenize(sentence) for sentence in data[\"func\"].tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53dc6fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode each token using Word2Vec embeddings\n",
    "encoded_list = []\n",
    "for sentence_tokens in tokenized_list:\n",
    "    encoded_sentence = []\n",
    "    for token in sentence_tokens:\n",
    "        if token in w2v_vectors:\n",
    "            encoded_token = w2v_vectors[token]\n",
    "            encoded_sentence.append(encoded_token)\n",
    "    encoded_list.append(encoded_sentence)\n",
    "\n",
    "data[\"w2v_func\"] = encoded_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad805fd3",
   "metadata": {},
   "source": [
    "FastText NL pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3c9ddd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "#fastText_vectors = gensim.downloader.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b6dd8249",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_tokenized_list = [word_tokenize(sentence) for sentence in data[\"func\"].tolist()]\n",
    "\n",
    "# Encode each token using fastText embeddings\n",
    "encoded_list = []\n",
    "for sentence_tokens in f_tokenized_list:\n",
    "    encoded_sentence = []\n",
    "    for token in sentence_tokens:\n",
    "        if token in fastText_vectors:\n",
    "            encoded_token = fastText_vectors[token]\n",
    "            encoded_sentence.append(encoded_token)\n",
    "        else:\n",
    "            continue\n",
    "    encoded_list.append(encoded_sentence)\n",
    "\n",
    "data[\"ft_func\"] = encoded_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7011e742",
   "metadata": {},
   "source": [
    "BERT pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a829b987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 28.0/28.0 [00:00<00:00, 28.7kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████| 570/570 [00:00<?, ?B/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 226k/226k [00:00<00:00, 1.69MB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 455k/455k [00:00<00:00, 1.61MB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 511M/511M [00:21<00:00, 24.9MB/s]\n",
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_variation = \"bert-base-uncased\" # \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_variation)\n",
    "bert = TFAutoModel.from_pretrained(model_variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "74ab0363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "bert_embeddings = bert.get_input_embeddings()\n",
    "embedding_matrix = bert_embeddings.weights[0].numpy()\n",
    "num_words = len(embedding_matrix)\n",
    "print(num_words)\n",
    "dim = len(embedding_matrix[0])\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955f4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [tokenizer.encode(sente, padding=True, truncation=True, add_special_tokens=False, return_tensors=\"tf\").numpy() for sente in data[\"func\"]] # Tokenize the complete sentences\n",
    "\n",
    "lines_pad = []\n",
    "for seq in sequences:\n",
    "    lines_pad.append(seq[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6804af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"bert_func\"] = lines_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29ff931",
   "metadata": {},
   "source": [
    "CodeBERT pre-trained CPP embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0f21e145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 476M/476M [00:20<00:00, 24.4MB/s]\n",
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_variation = \"microsoft/codebert-base\" # \"neulab/codebert-cpp\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_variation, do_lower_case=False) # , do_lower_case=True\n",
    "codebert = TFAutoModel.from_pretrained(model_variation) # , from_pt=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7fbd33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_embeddings = codebert.get_input_embeddings()\n",
    "embedding_matrix = codebert_embeddings.weights[0].numpy()\n",
    "num_words = len(embedding_matrix)\n",
    "print(num_words)\n",
    "dim = len(embedding_matrix[0])\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5df843db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [tokenizer(sente, return_tensors=\"tf\", padding=True, truncation=True, add_special_tokens=False) for sente in data[\"func\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2730bfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iliaskaloup\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel_launcher.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def extractEmbList(sequences):\n",
    "    lines_pad = []\n",
    "    for sequence in sequences:\n",
    "        seq = sequence['input_ids'].numpy()[0]\n",
    "#         if len(seq) < max_len:\n",
    "#             for i in range(len(seq), max_len):\n",
    "#                 seq = np.append(seq, 0)\n",
    "        lines_pad.append(seq)\n",
    "    \n",
    "    [arr.tolist() for arr in lines_pad]\n",
    "    \n",
    "    return lines_pad\n",
    "\n",
    "lines_pad = np.array(extractEmbList(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b423524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"codebert_func\"] = lines_pad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
