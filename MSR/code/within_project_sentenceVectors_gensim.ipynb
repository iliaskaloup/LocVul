{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b75d92e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json, os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "from transformers import AutoTokenizer, TFAutoModel, TFAutoModelForSequenceClassification #, BertModel, BertTokenizer, TFBertForSequenceClassification\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.backend as K\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, \\\n",
    "roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "import io\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import Masking\n",
    "from tensorflow.keras.layers import Embedding, MaxPool1D\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.layers import Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.initializers import glorot_uniform, RandomUniform, lecun_uniform, Constant\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, GlobalMaxPool1D\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool1D\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from keras_preprocessing.text import tokenizer_from_json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from gensim.models import Word2Vec, FastText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4cbca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30a24011",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [\"w2v\", \"ft\"]\n",
    "embedding = embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6059895e",
   "metadata": {},
   "source": [
    "Choose a project among Chrome and Linux or the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6d86c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(os.path.join('..','data', 'full_data_reduced.csv'))\n",
    "#data = pd.read_csv(os.path.join('..','data', 'chrome_data_reduced.csv'))\n",
    "data = pd.read_csv(os.path.join('..','data', 'linux_data_reduced.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c5b1cf",
   "metadata": {},
   "source": [
    "Shuffle the dataset before starting operating on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a95914",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "#data = data.iloc[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8597edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                func  vul  length\n",
      "0  static inline void __ap_schedule_poll_timer(vo...    0      30\n",
      "1  static int sctp_autobind(struct sock *sk)\\n{\\n...    0      36\n",
      "2  static ssize_t ucma_init_qp_attr(struct ucma_f...    0      88\n",
      "3  static void __blk_mq_requeue_request(struct re...    0      24\n",
      "4  static void vhost_net_flush(struct vhost_net *...    0      37\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baebd02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(data[\"length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "485b09ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of words: 209\n"
     ]
    }
   ],
   "source": [
    "word_counts = data[\"func\"].apply(lambda x: len(x.split()))\n",
    "max_length = word_counts.max()\n",
    "print(\"Maximum number of words:\", max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69061a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    95\n",
      "1     5\n",
      "Name: vul, dtype: int64\n",
      "Vulnerability Percentage:  5.263157894736842 %\n"
     ]
    }
   ],
   "source": [
    "print(data[\"vul\"].value_counts())\n",
    "\n",
    "print(\"Vulnerability Percentage: \", (data[\"vul\"].value_counts()[1]/data[\"vul\"].value_counts()[0])*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffa700",
   "metadata": {},
   "source": [
    "PRE_PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9302ce9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\iliaskaloup\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "tokenized_list = [word_tokenize(sentence) for sentence in data[\"func\"].tolist()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d708d8b",
   "metadata": {},
   "source": [
    "Train-val-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d15b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test and then train into train and val (90% train, 10% test and then 90% train and 20% val)\n",
    "shuffle_seeders = [seed, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "shuffle_seeder = shuffle_seeders[0]\n",
    "\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(tokenized_list, data[\"vul\"].tolist(), stratify = data[\"vul\"].tolist(), test_size=0.1, random_state=shuffle_seeder)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, stratify = y_train_val, test_size=0.1, random_state=shuffle_seeder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de42decc",
   "metadata": {},
   "source": [
    "Train word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "981cdc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(word_model, words, dim):\n",
    "    words_vecs = [word_model.wv[word] for word in words if word in word_model.wv]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(dim)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b50dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 100\n",
    "methods = [\"w2v\", \"fastText\"]\n",
    "method = methods[0]\n",
    "\n",
    "if method == \"w2v\":\n",
    "    word_model = Word2Vec(x_train, vector_size=dim, window=20, workers=4, epochs=2, min_count=1) # , sg=1\n",
    "elif method == \"fastText\":\n",
    "    word_model = FastText(x_train, vector_size=dim, window=20, workers=4, epochs=2, min_count=1)\n",
    "\n",
    "#create sentence-level vectors\n",
    "x_train_val = np.array([vectorize(word_model, sentence, dim) for sentence in x_train_val])\n",
    "x_train = np.array([vectorize(word_model, sentence, dim) for sentence in x_train])\n",
    "x_test = np.array([vectorize(word_model, sentence, dim) for sentence in x_test])\n",
    "x_val = np.array([vectorize(word_model, sentence, dim) for sentence in x_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "147299f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to integers\n",
    "y_train_val = [int(label) for label in y_train_val]\n",
    "y_test = [int(label) for label in y_test]\n",
    "y_train = [int(label) for label in y_train]\n",
    "y_val = [int(label) for label in y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17875e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "userModels = [\"RF\", \"SVM\", \"DT\", \"NB\", \"KNN\", \"LR\"]\n",
    "userModel = userModels[0]\n",
    "\n",
    "if userModel == \"svm\":\n",
    "    myModel = SVC(kernel='rbf', gamma=100)\n",
    "elif userModel == \"RF\":\n",
    "    myModel = RandomForestClassifier(n_estimators=100, bootstrap = True, max_features = 'sqrt')\n",
    "elif userModel == \"DT\":\n",
    "    myModel = tree.DecisionTreeClassifier(max_depth=120)\n",
    "elif userModel == \"NB\":\n",
    "    myModel = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cdd437",
   "metadata": {},
   "source": [
    "Hyperparameter tuning - Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8313ce34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8540\\2502954454.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mrecall\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    570\u001b[0m             \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m         )\n\u001b[0;32m    574\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# multilabel-indicator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         raise ValueError(\n\u001b[1;32m--> 338\u001b[1;33m             \u001b[1;34m\"Only one class present in y_true. ROC AUC score \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m             \u001b[1;34m\"is not defined in that case.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "# Training\n",
    "myModel.fit(x_train, y_train) # y_train.ravel()\n",
    "\n",
    "# Predicting\n",
    "predictions = myModel.predict(x_val)\n",
    "#predScores = myModel.predict_proba(x_val)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "precision = precision_score(y_val, predictions)\n",
    "recall = recall_score(y_val, predictions)\n",
    "f1 = f1_score(y_val, predictions)\n",
    "roc_auc = roc_auc_score(y_val, predictions)\n",
    "f2 = 5*precision*recall / (4*precision+recall)\n",
    "\n",
    "cm = confusion_matrix(y_val, predictions, labels=[0, 1])\n",
    "#print(cm)\n",
    "sns.heatmap(cm, annot=True)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"TP=\",tp)\n",
    "print(\"TN=\",tn)\n",
    "print(\"FP=\",fp)\n",
    "print(\"FN=\",fn)\n",
    "\n",
    "print(\"Accuracy:%.2f%%\"%(accuracy*100))\n",
    "print(\"Precision:%.2f%%\"%(precision*100))\n",
    "print(\"Recall:%.2f%%\"%(recall*100))\n",
    "print(\"F1 score:%.2f%%\"%(f1*100))\n",
    "print(\"Roc_Auc score:%.2f%%\"%(roc_auc*100))\n",
    "print(\"F2 score:%.2f%%\"%(f2*100))\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df04455b",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training\n",
    "# myModel.fit(x_train_val, y_train_val) # y_train.ravel()\n",
    "\n",
    "# # Predicting\n",
    "# predictions = myModel.predict(x_test)\n",
    "# #predScores = myModel.predict_proba(x_test)\n",
    "\n",
    "# # Evaluation\n",
    "# accuracy = accuracy_score(y_test, predictions)\n",
    "# precision = precision_score(y_test, predictions)\n",
    "# recall = recall_score(y_test, predictions)\n",
    "# f1 = f1_score(y_test, predictions)\n",
    "# roc_auc = roc_auc_score(y_test, predictions)\n",
    "# f2 = 5*precision*recall / (4*precision+recall)\n",
    "\n",
    "# cm = confusion_matrix(y_test, predictions, labels=[0, 1])\n",
    "# #print(cm)\n",
    "# sns.heatmap(cm, annot=True)\n",
    "# tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# print(\"TP=\",tp)\n",
    "# print(\"TN=\",tn)\n",
    "# print(\"FP=\",fp)\n",
    "# print(\"FN=\",fn)\n",
    "\n",
    "# print(\"Accuracy:%.2f%%\"%(accuracy*100))\n",
    "# print(\"Precision:%.2f%%\"%(precision*100))\n",
    "# print(\"Recall:%.2f%%\"%(recall*100))\n",
    "# print(\"F1 score:%.2f%%\"%(f1*100))\n",
    "# print(\"Roc_Auc score:%.2f%%\"%(roc_auc*100))\n",
    "# print(\"F2 score:%.2f%%\"%(f2*100))\n",
    "# print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ec372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
