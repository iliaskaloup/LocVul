{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b75d92e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json, os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "from transformers import AutoTokenizer, TFAutoModel, TFAutoModelForSequenceClassification #, BertModel, BertTokenizer, TFBertForSequenceClassification\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.backend as K\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, \\\n",
    "roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "import io\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import Masking\n",
    "from tensorflow.keras.layers import Embedding, MaxPool1D\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.layers import Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.initializers import glorot_uniform, RandomUniform, lecun_uniform, Constant\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, GlobalMaxPool1D\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool1D\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from keras_preprocessing.text import tokenizer_from_json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4cbca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30a24011",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [\"bert\", \"codebert\"]\n",
    "embedding = embeddings[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6059895e",
   "metadata": {},
   "source": [
    "Choose a project among Chrome and Linux or the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6d86c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(os.path.join('..','data', 'full_data_reduced.csv'))\n",
    "#data = pd.read_csv(os.path.join('..','data', 'chrome_data_reduced.csv'))\n",
    "data = pd.read_csv(os.path.join('..','data', 'linux_data_reduced.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c5b1cf",
   "metadata": {},
   "source": [
    "Shuffle the dataset before starting operating on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60a95914",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "#data = data.iloc[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8597edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                func  vul  length\n",
      "0  static inline void __ap_schedule_poll_timer(vo...    0      30\n",
      "1  static int sctp_autobind(struct sock *sk)\\n{\\n...    0      36\n",
      "2  static ssize_t ucma_init_qp_attr(struct ucma_f...    0      88\n",
      "3  static void __blk_mq_requeue_request(struct re...    0      24\n",
      "4  static void vhost_net_flush(struct vhost_net *...    0      37\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "baebd02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(data[\"length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "485b09ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of words: 237\n"
     ]
    }
   ],
   "source": [
    "word_counts = data[\"func\"].apply(lambda x: len(x.split()))\n",
    "max_length = word_counts.max()\n",
    "print(\"Maximum number of words:\", max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69061a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    43024\n",
      "1     1439\n",
      "Name: vul, dtype: int64\n",
      "Vulnerability Percentage:  3.344644849386389 %\n"
     ]
    }
   ],
   "source": [
    "print(data[\"vul\"].value_counts())\n",
    "\n",
    "print(\"Vulnerability Percentage: \", (data[\"vul\"].value_counts()[1]/data[\"vul\"].value_counts()[0])*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffa700",
   "metadata": {},
   "source": [
    "PRE_PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9302ce9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\iliaskaloup\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "tokenized_list = [word_tokenize(sentence) for sentence in data[\"func\"].tolist()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d8f5db",
   "metadata": {},
   "source": [
    "BERT pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2f89d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding == \"bert\":\n",
    "    model_variation = \"bert-base-uncased\" # \"roberta-base\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_variation)\n",
    "    bert = TFAutoModel.from_pretrained(model_variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "016286a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding == \"bert\": \n",
    "    sentences = data[\"func\"].tolist()\n",
    "\n",
    "    sequences = [tokenizer.encode(sente, truncation=True, max_length=512, padding=\"max_length\", add_special_tokens=False, return_tensors=\"tf\") for sente in sentences]\n",
    "    embeddings = [bert(sequence)[0][:, 0, :].numpy() for sequence in sequences]  # Extract embeddings from BERT's output\n",
    "    extracted_embeddings = [arr[0] for arr in embeddings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e7efba",
   "metadata": {},
   "source": [
    "CodeBERT pre-trained CPP embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c8c38dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at microsoft/codebert-base-mlm were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base-mlm.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "if embedding == \"codebert\":\n",
    "    model_variation = \"microsoft/codebert-base-mlm\" # \"neulab/codebert-cpp\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_variation, do_lower_case=False) # , do_lower_case=True\n",
    "    codebert = TFAutoModel.from_pretrained(model_variation) # , from_pt=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1cad3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding == \"codebert\": \n",
    "    sentences = data[\"func\"].tolist()\n",
    "\n",
    "    sequences = [tokenizer.encode(sente, truncation=True, max_length=512, padding=\"max_length\", add_special_tokens=False, return_tensors=\"tf\") for sente in sentences]\n",
    "    embeddings = [codebert(sequence)[0][:, 0, :].numpy() for sequence in sequences]  # Extract embeddings from CodeBERT's output\n",
    "    extracted_embeddings = [arr[0] for arr in embeddings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d708d8b",
   "metadata": {},
   "source": [
    "Train-val-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d15b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test and then train into train and val (90% train, 10% test and then 90% train and 20% val)\n",
    "shuffle_seeders = [seed, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "shuffle_seeder = shuffle_seeders[0]\n",
    "\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(extracted_embeddings, data[\"vul\"].tolist(), stratify = data[\"vul\"].tolist(), test_size=0.1, random_state=shuffle_seeder)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, stratify = y_train_val, test_size=0.1, random_state=shuffle_seeder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41a8c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to integers\n",
    "y_train_val = [int(label) for label in y_train_val]\n",
    "y_test = [int(label) for label in y_test]\n",
    "y_train = [int(label) for label in y_train]\n",
    "y_val = [int(label) for label in y_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683ca126",
   "metadata": {},
   "source": [
    "<b>Handling imbalanced data</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b6f573",
   "metadata": {},
   "source": [
    "Class weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0942fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total observations / (number of classes * observations in class)\n",
    "class_weights = {0:len(data) / (len(vc) * vc[0]), 1:len(data) / (len(vc) * vc[1])}\n",
    "#class_weights = {0:1, 1:1}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f21617d",
   "metadata": {},
   "source": [
    "Under-sampling of the clean samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd31b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply under-sampling with the specified strategy\n",
    "class_counts = pd.Series(y_train).value_counts()\n",
    "print(\"Class distribution \", class_counts)\n",
    "majority_class = class_counts.idxmax()\n",
    "print(\"Majority class \", majority_class)\n",
    "target_count = int(class_counts.iloc[0] / 2) \n",
    "print(\"Targeted number of majority class\", target_count)\n",
    "\n",
    "# under\n",
    "sampling_strategy = {majority_class: target_count}        \n",
    "rus = RandomUnderSampler(random_state=seed, sampling_strategy=sampling_strategy)\n",
    "x_train_resampled, y_train_resampled = rus.fit_resample(x_train, y_train) \n",
    "print(\"Class distribution after under-sampling\", pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f7ac44",
   "metadata": {},
   "source": [
    "Random Over-sampling of the vulnerable samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply random over-sampling with the specified strategy\n",
    "# class_counts = pd.Series(y_train_resampled).value_counts()\n",
    "# print(\"Class distribution \", class_counts)\n",
    "# minority_class = class_counts.idxmin()\n",
    "# print(\"Minority class \", minority_class)\n",
    "# target_count = class_counts.iloc[0] #int(class_counts.iloc[1] * 2) \n",
    "# print(\"Targeted number of minority class\", target_count)\n",
    "\n",
    "# # over\n",
    "# sampling_strategy = {minority_class: target_count}        \n",
    "# ros = RandomOverSampler(random_state=seed, sampling_strategy=sampling_strategy)\n",
    "# x_train_resampled, y_train_resampled = ros.fit_resample(x_train_resampled, y_train_resampled) \n",
    "# print(\"Class distribution after over-sampling\", pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a38d65",
   "metadata": {},
   "source": [
    "Synthetic Minority Over-sampling of the vulnerable samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b258cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote = SMOTE(random_state=seed, sampling_strategy='auto')  # 'auto' means it will resample to have the same number of samples as the majority class\n",
    "# x_train_resampled, y_train_resampled = smote.fit_resample(x_train_resampled, y_train_resampled)\n",
    "\n",
    "# # Class distribution after SMOTE\n",
    "# class_counts_after_smote = pd.Series(y_train_resampled).value_counts()\n",
    "# print(\"Class distribution after SMOTE\", class_counts_after_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df68cbd6",
   "metadata": {},
   "source": [
    "Adaptive Synthetic Sampling with ADASYN - Over-sampling of the vulnerable samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b61a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn = ADASYN(random_state=seed, sampling_strategy='auto')  # 'auto' means it will resample to have the same number of samples as the majority class\n",
    "x_train_resampled, y_train_resampled = adasyn.fit_resample(x_train_resampled, y_train_resampled)\n",
    "\n",
    "# Class distribution after ADASYN\n",
    "class_counts_after_adasyn = pd.Series(y_train_resampled).value_counts()\n",
    "print(\"Class distribution after ADASYN\", class_counts_after_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0897bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the resampled data while preserving the correspondence between features and labels\n",
    "x_train_resampled, y_train_resampled = shuffle(x_train_resampled, y_train_resampled, random_state=seed)\n",
    "\n",
    "# rename\n",
    "X_train = x_train_resampled\n",
    "Y_train = y_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17875e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "userModels = [\"RF\", \"SVM\", \"DT\", \"NB\", \"KNN\", \"LR\"]\n",
    "userModel = userModels[0]\n",
    "\n",
    "if userModel == \"svm\":\n",
    "    myModel = SVC(kernel='rbf', gamma=100)\n",
    "elif userModel == \"RF\":\n",
    "    myModel = RandomForestClassifier(n_estimators=100, bootstrap = True, max_features = 'sqrt')\n",
    "elif userModel == \"DT\":\n",
    "    myModel = tree.DecisionTreeClassifier(max_depth=120)\n",
    "elif userModel == \"NB\":\n",
    "    myModel = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cdd437",
   "metadata": {},
   "source": [
    "Hyperparameter tuning - Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8313ce34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP= 0\n",
      "TN= 87\n",
      "FP= 0\n",
      "FN= 3\n",
      "Accuracy:96.67%\n",
      "Precision:0.00%\n",
      "Recall:0.00%\n",
      "F1 score:0.00%\n",
      "Roc_Auc score:50.00%\n",
      "F2 score:nan%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        87\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.97        90\n",
      "   macro avg       0.48      0.50      0.49        90\n",
      "weighted avg       0.93      0.97      0.95        90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "D:\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "myModel.fit(x_train, y_train) # y_train.ravel()\n",
    "\n",
    "# Predicting\n",
    "predictions = myModel.predict(x_val)\n",
    "#predScores = myModel.predict_proba(x_val)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "precision = precision_score(y_val, predictions)\n",
    "recall = recall_score(y_val, predictions)\n",
    "f1 = f1_score(y_val, predictions)\n",
    "roc_auc = roc_auc_score(y_val, predictions)\n",
    "f2 = 5*precision*recall / (4*precision+recall)\n",
    "\n",
    "cm = confusion_matrix(y_val, predictions, labels=[0, 1])\n",
    "#print(cm)\n",
    "sns.heatmap(cm, annot=True)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"TP=\",tp)\n",
    "print(\"TN=\",tn)\n",
    "print(\"FP=\",fp)\n",
    "print(\"FN=\",fn)\n",
    "\n",
    "print(\"Accuracy:%.2f%%\"%(accuracy*100))\n",
    "print(\"Precision:%.2f%%\"%(precision*100))\n",
    "print(\"Recall:%.2f%%\"%(recall*100))\n",
    "print(\"F1 score:%.2f%%\"%(f1*100))\n",
    "print(\"Roc_Auc score:%.2f%%\"%(roc_auc*100))\n",
    "print(\"F2 score:%.2f%%\"%(f2*100))\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df04455b",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training\n",
    "# myModel.fit(x_train_val, y_train_val) # y_train.ravel()\n",
    "\n",
    "# # Predicting\n",
    "# predictions = myModel.predict(x_test)\n",
    "# #predScores = myModel.predict_proba(x_test)\n",
    "\n",
    "# # Evaluation\n",
    "# accuracy = accuracy_score(y_test, predictions)\n",
    "# precision = precision_score(y_test, predictions)\n",
    "# recall = recall_score(y_test, predictions)\n",
    "# f1 = f1_score(y_test, predictions)\n",
    "# roc_auc = roc_auc_score(y_test, predictions)\n",
    "# f2 = 5*precision*recall / (4*precision+recall)\n",
    "\n",
    "# cm = confusion_matrix(y_test, predictions, labels=[0, 1])\n",
    "# #print(cm)\n",
    "# sns.heatmap(cm, annot=True)\n",
    "# tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# print(\"TP=\",tp)\n",
    "# print(\"TN=\",tn)\n",
    "# print(\"FP=\",fp)\n",
    "# print(\"FN=\",fn)\n",
    "\n",
    "# print(\"Accuracy:%.2f%%\"%(accuracy*100))\n",
    "# print(\"Precision:%.2f%%\"%(precision*100))\n",
    "# print(\"Recall:%.2f%%\"%(recall*100))\n",
    "# print(\"F1 score:%.2f%%\"%(f1*100))\n",
    "# print(\"Roc_Auc score:%.2f%%\"%(roc_auc*100))\n",
    "# print(\"F2 score:%.2f%%\"%(f2*100))\n",
    "# print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ec372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
