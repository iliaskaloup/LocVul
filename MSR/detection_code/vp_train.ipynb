{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b75d92e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json, os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "from transformers import AutoTokenizer, TFAutoModel, TFAutoModelForSequenceClassification #, BertModel, BertTokenizer, TFBertForSequenceClassification\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.backend as K\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, \\\n",
    "roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "import io\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import Masking\n",
    "from tensorflow.keras.layers import Embedding, MaxPool1D\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.layers import Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.initializers import glorot_uniform, RandomUniform, lecun_uniform, Constant, TruncatedNormal\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, GlobalMaxPool1D, Flatten\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool1D\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from keras_preprocessing.text import tokenizer_from_json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "from nlpaug.util.file.download import DownloadUtil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4cbca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a8cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [\"w2v\", \"ft\", \"bert\", \"codebert\"]\n",
    "embedding = embeddings[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6059895e",
   "metadata": {},
   "source": [
    "Choose a project among Chrome and Linux or the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6d86c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(os.path.join('..','data', 'full_data_reduced.csv'))\n",
    "data = pd.read_csv(os.path.join('..','data', 'chrome_data_reduced.csv'))\n",
    "#data = pd.read_csv(os.path.join('..','data', 'linux_data_reduced.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c5b1cf",
   "metadata": {},
   "source": [
    "Shuffle the dataset before starting operating on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a95914",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1, random_state=seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8597edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                func  vul  length\n",
      "0    midimanagerusbtest() : message_loop_(new bas...    0      14\n",
      "1  void renderframehostimpl::cancelblockedrequest...    0       8\n",
      "2  void renderthreadimpl::removeobserver(renderth...    0       7\n",
      "3  void webstorestandaloneinstaller::initinstalld...    0       7\n",
      "4  omniboxstate::omniboxstate(const omniboxeditmo...    0      15\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baebd02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(data[\"length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "485b09ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of words: 80\n"
     ]
    }
   ],
   "source": [
    "word_counts = data[\"func\"].apply(lambda x: len(x.split()))\n",
    "max_length = word_counts.max()\n",
    "print(\"Maximum number of words:\", max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69061a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    70232\n",
      "1     3000\n",
      "Name: vul, dtype: int64\n",
      "Vulnerability Percentage:  4.271557124957284 %\n"
     ]
    }
   ],
   "source": [
    "vc = data[\"vul\"].value_counts()\n",
    "\n",
    "print(vc)\n",
    "\n",
    "print(\"Vulnerability Percentage: \", (vc[1] / vc[0])*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9251f04f",
   "metadata": {},
   "source": [
    "Train-val-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ebe5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test and then train into train and val (90% train, 10% test and then 90% train and 10% val)\n",
    "shuffle_seeders = [seed, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "shuffle_seeder = shuffle_seeders[0]\n",
    "\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(data[\"func\"].tolist(), data[\"vul\"].tolist(), stratify = data[\"vul\"].tolist(), test_size=0.1, random_state=shuffle_seeder)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, stratify = y_train_val, test_size=0.1, random_state=shuffle_seeder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003c0c5a",
   "metadata": {},
   "source": [
    "<b>Handling imbalanced data</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0931d2fe",
   "metadata": {},
   "source": [
    "Class weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b76ec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "class_weights = {0:1, 1:1}\n",
    "#class_weights = {0:len(data) / (len(vc) * vc[0]), 1:len(data) / (len(vc) * vc[1])} #total observations / (number of classes * observations in class)\n",
    "#class_weights = dict(enumerate(compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f96c2e",
   "metadata": {},
   "source": [
    "Under-sampling of the clean samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4ffcbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59317, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb3a86da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution  0    56887\n",
      "1     2430\n",
      "dtype: int64\n",
      "Majority class  0\n",
      "Targeted number of majority class 28443\n",
      "Class distribution after augmentation 0    28443\n",
      "1     2430\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply under-sampling with the specified strategy\n",
    "class_counts = pd.Series(y_train).value_counts()\n",
    "print(\"Class distribution \", class_counts)\n",
    "majority_class = class_counts.idxmax()\n",
    "print(\"Majority class \", majority_class)\n",
    "target_count = int(class_counts.iloc[0] / 2) \n",
    "print(\"Targeted number of majority class\", target_count)\n",
    "\n",
    "# under\n",
    "sampling_strategy = {majority_class: target_count}        \n",
    "rus = RandomUnderSampler(random_state=seed, sampling_strategy=sampling_strategy)\n",
    "x_train_resampled, y_train_resampled = rus.fit_resample(x_train, y_train) \n",
    "print(\"Class distribution after augmentation\", pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89c5468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_resampled = x_train_resampled.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df73781c",
   "metadata": {},
   "source": [
    "Random word augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee15229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug = naw.RandomWordAug(action='delete', name='RandomWord_Aug', aug_min=1, aug_max=10, aug_p=0.3, stopwords=None, \n",
    "#                         target_words=None, tokenizer=None, reverse_tokenizer=None, stopwords_regex=None, verbose=0)\n",
    "\n",
    "# num_minority_samples = pd.Series(y_train_resampled).value_counts()[1]\n",
    "# num_majority_samples = pd.Series(y_train_resampled).value_counts()[0]\n",
    "# difference  = num_majority_samples - num_minority_samples\n",
    "# num_augmentations_per_sentence = difference // num_minority_samples\n",
    "\n",
    "# x_augm = []\n",
    "# y_augm = []\n",
    "# for i in range(0, len(x_train_resampled)):\n",
    "#     # check for minority class\n",
    "#     if y_train_resampled[i] == 1:\n",
    "#         sentence = x_train_resampled[i]\n",
    "        \n",
    "#         for _ in range(num_augmentations_per_sentence):\n",
    "#             # Apply synonym augmentation\n",
    "#             augmented_sentence = aug.augment(sentence[0])\n",
    "#             # Store the augmented sentence\n",
    "#             x_augm.append(augmented_sentence)\n",
    "#             y_augm.append(1)\n",
    "            \n",
    "# x_train_resampled = x_train_resampled + x_augm\n",
    "# y_train_resampled = y_train_resampled + y_augm\n",
    "\n",
    "# print(\"Class distribution after augmentation\", pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc44591",
   "metadata": {},
   "source": [
    "Synonym word augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c11cb2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug = naw.SynonymAug(aug_src='wordnet', model_path=None, name='Synonym_Aug', aug_min=1, aug_max=10, aug_p=0.3, lang='eng', \n",
    "#                      stopwords=None, tokenizer=None, reverse_tokenizer=None, stopwords_regex=None, force_reload=False, \n",
    "#                      verbose=0)\n",
    "\n",
    "# num_minority_samples = pd.Series(y_train_resampled).value_counts()[1]\n",
    "# num_majority_samples = pd.Series(y_train_resampled).value_counts()[0]\n",
    "# difference  = num_majority_samples - num_minority_samples\n",
    "# num_augmentations_per_sentence = difference // num_minority_samples\n",
    "\n",
    "# x_augm = []\n",
    "# y_augm = []\n",
    "# for i in range(0, len(x_train_resampled)):\n",
    "#     # check for minority class\n",
    "#     if y_train_resampled[i] == 1:\n",
    "#         sentence = x_train_resampled[i]\n",
    "        \n",
    "#         for _ in range(num_augmentations_per_sentence):\n",
    "#             # Apply synonym augmentation\n",
    "#             augmented_sentence = aug.augment(sentence[0])\n",
    "#             # Store the augmented sentence\n",
    "#             x_augm.append(augmented_sentence)\n",
    "#             y_augm.append(1)\n",
    "            \n",
    "# x_train_resampled = x_train_resampled + x_augm\n",
    "# y_train_resampled = y_train_resampled + y_augm\n",
    "\n",
    "# print(\"Class distribution after under-sampling\", pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f19a9b6",
   "metadata": {},
   "source": [
    "Word2vec similar words augmentation - substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b24a68fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DownloadUtil.download_word2vec(dest_dir='.') # Download word2vec model\n",
    "#DownloadUtil.download_glove(model_name='glove.6B', dest_dir='.') # Download GloVe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc7dc46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aug_w2v = naw.WordEmbsAug(\n",
    "# #     model_type='word2vec', model_path='GoogleNews-vectors-negative300.bin',\n",
    "# #     action=\"substitute\")\n",
    "\n",
    "# aug_w2v = naw.WordEmbsAug(\n",
    "#     model_type='word2vec', model_path='w2v_model.model',\n",
    "#     action=\"substitute\")\n",
    "\n",
    "# num_minority_samples = pd.Series(y_train_resampled).value_counts()[1]\n",
    "# num_majority_samples = pd.Series(y_train_resampled).value_counts()[0]\n",
    "# difference  = num_majority_samples - num_minority_samples\n",
    "# num_augmentations_per_sentence = difference // num_minority_samples\n",
    "\n",
    "# x_augm = []\n",
    "# y_augm = []\n",
    "# for i in range(0, len(x_train_resampled)):\n",
    "#     # check for minority class\n",
    "#     if y_train_resampled[i] == 1:\n",
    "#         sentence = x_train_resampled[i]\n",
    "        \n",
    "#         for _ in range(num_augmentations_per_sentence):\n",
    "#             # Apply synonym augmentation\n",
    "#             augmented_sentence = aug_w2v.augment(sentence[0])\n",
    "#             # Store the augmented sentence\n",
    "#             x_augm.append(augmented_sentence)\n",
    "#             y_augm.append(1)\n",
    "            \n",
    "# x_train_resampled = x_train_resampled + x_augm\n",
    "# y_train_resampled = y_train_resampled + y_augm\n",
    "\n",
    "# print(\"Class distribution after under-sampling\", pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216f09eb",
   "metadata": {},
   "source": [
    "FastText similar words augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b70b2cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DownloadUtil.download_fasttext(model_name='wiki-news-300d-1M', dest_dir='.') # Download fasttext model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "885babb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug_w2v = naw.WordEmbsAug(\n",
    "#     model_type='fasttext', model_path='.',\n",
    "#     action=\"substitute\")\n",
    "\n",
    "# num_minority_samples = pd.Series(y_train_resampled).value_counts()[1]\n",
    "# num_majority_samples = pd.Series(y_train_resampled).value_counts()[0]\n",
    "# difference  = num_majority_samples - num_minority_samples\n",
    "# num_augmentations_per_sentence = difference // num_minority_samples\n",
    "\n",
    "# x_augm = []\n",
    "# y_augm = []\n",
    "# for i in range(0, len(x_train_resampled)):\n",
    "#     # check for minority class\n",
    "#     if y_train_resampled[i] == 1:\n",
    "#         sentence = x_train_resampled[i]\n",
    "        \n",
    "#         for _ in range(num_augmentations_per_sentence):\n",
    "#             # Apply synonym augmentation\n",
    "#             augmented_sentence = aug_w2v.augment(sentence[0])\n",
    "#             # Store the augmented sentence\n",
    "#             x_augm.append(augmented_sentence)\n",
    "#             y_augm.append(1)\n",
    "\n",
    "# x_train_resampled = x_train_resampled + x_augm\n",
    "# y_train_resampled = y_train_resampled + y_augm\n",
    "\n",
    "# print(\"Class distribution after under-sampling\", pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a65c63",
   "metadata": {},
   "source": [
    "Contextual augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26ce089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOPK = 50 #default=100 # 20\n",
    "# ACT = 'substitute' #\"substitute\" #\"insert\"\n",
    " \n",
    "# aug_bert = naw.ContextualWordEmbsAug(\n",
    "#     model_path='microsoft/codebert-base-mlm', \n",
    "#     #device='cuda',\n",
    "#     action=ACT, top_k=TOPK)\n",
    "\n",
    "# num_minority_samples = pd.Series(y_train_resampled).value_counts()[1]\n",
    "# num_majority_samples = pd.Series(y_train_resampled).value_counts()[0]\n",
    "# difference  = num_majority_samples - num_minority_samples\n",
    "# num_augmentations_per_sentence = difference // num_minority_samples\n",
    "\n",
    "# x_augm = []\n",
    "# y_augm = []\n",
    "# for i in range(0, len(x_train_resampled)):\n",
    "#     # check for minority class\n",
    "#     if y_train_resampled[i] == 1:\n",
    "#         sentence = x_train_resampled[i]\n",
    "#         for _ in range(num_augmentations_per_sentence):\n",
    "#             # Apply synonym augmentation\n",
    "#             augmented_sentence = aug_bert.augment(sentence[0])\n",
    "#             # Store the augmented sentence\n",
    "#             x_augm.append(augmented_sentence)\n",
    "#             y_augm.append(1)\n",
    "            \n",
    "# x_train_resampled = x_train_resampled + x_augm\n",
    "# y_train_resampled = y_train_resampled + y_augm\n",
    "\n",
    "# print(\"Class distribution after under-sampling\", pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68ea1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resampled_df = pd.DataFrame({'func': x_train_resampled, 'vul': y_train_resampled})\n",
    "# resampled_df.to_csv('augmented_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65e6517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the resampled data while preserving the correspondence between features and labels\n",
    "x_train_resampled, y_train_resampled = shuffle(x_train_resampled, y_train_resampled, random_state=seed)\n",
    "\n",
    "# rename\n",
    "X_train = x_train_resampled\n",
    "Y_train = y_train_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d8f5db",
   "metadata": {},
   "source": [
    "BERT pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2f89d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding == \"bert\":\n",
    "    model_variation = \"bert-base-uncased\" # \"roberta-base\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_variation)\n",
    "    bert = TFAutoModel.from_pretrained(model_variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ef02bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding == \"bert\":\n",
    "    bert_embeddings = bert.get_input_embeddings()\n",
    "    embedding_matrix = bert_embeddings.weights[0].numpy()\n",
    "    num_words = len(embedding_matrix)\n",
    "    print(num_words)\n",
    "    dim = len(embedding_matrix[0])\n",
    "    print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ab68807",
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding == \"bert\":\n",
    "    sentences = X_train.tolist()\n",
    "    sequences = [tokenizer.encode(sente[0], truncation=True, add_special_tokens=False, return_tensors=\"tf\").numpy() for sente in sentences] # Tokenize the complete sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d09c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding == \"bert\":\n",
    "    lines_pad_x_train = []\n",
    "    for seq in sequences:\n",
    "        lines_pad_x_train.append(seq[0])\n",
    "\n",
    "    lines_pad_x_train = pad_sequences(lines_pad_x_train, padding = 'post', maxlen = 512)\n",
    "    lines_pad_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f66a1dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding == \"bert\":\n",
    "    sentences = x_val\n",
    "    sequences = [tokenizer.encode(sente, truncation=True, add_special_tokens=False, return_tensors=\"tf\").numpy() for sente in sentences] # Tokenize the complete sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63675629",
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding == \"bert\":\n",
    "    lines_pad_x_val = []\n",
    "    for seq in sequences:\n",
    "        lines_pad_x_val.append(seq[0])\n",
    "\n",
    "    lines_pad_x_val = pad_sequences(lines_pad_x_val, padding = 'post', maxlen = 512)\n",
    "    lines_pad_x_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e7efba",
   "metadata": {},
   "source": [
    "CodeBERT pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c8c38dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at microsoft/codebert-base-mlm were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base-mlm.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "if embedding == \"codebert\":\n",
    "    model_variation = \"microsoft/codebert-base-mlm\" # \"neulab/codebert-cpp\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_variation, do_lower_case=False) # , do_lower_case=True\n",
    "    codebert = TFAutoModel.from_pretrained(model_variation) # , from_pt=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea203cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50265\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "if embedding == \"codebert\":\n",
    "    codebert_embeddings = codebert.get_input_embeddings()\n",
    "    embedding_matrix = codebert_embeddings.weights[0].numpy()\n",
    "    num_words = len(embedding_matrix)\n",
    "    print(num_words)\n",
    "    dim = len(embedding_matrix[0])\n",
    "    print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd3d25a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding == \"codebert\":\n",
    "    sentences = X_train\n",
    "    sequences = [tokenizer(sente[0], return_tensors=\"tf\", truncation=True, add_special_tokens=False) for sente in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc259d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padSequences(sequences, max_len):\n",
    "    lines_pad = []\n",
    "    for sequence in sequences:\n",
    "        seq = sequence['input_ids'].numpy()[0]\n",
    "        if len(seq) < max_len:\n",
    "            for i in range(len(seq), max_len):\n",
    "                seq = np.append(seq, 0)\n",
    "        lines_pad.append(seq)\n",
    "    return lines_pad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7586bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(sequences):\n",
    "    max_len = 0\n",
    "    \n",
    "    for seq in sequences:\n",
    "        if len(seq['input_ids'].numpy()[0]) > max_len:\n",
    "            max_len = len(seq['input_ids'].numpy()[0])\n",
    "    \n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83c1e0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "if embedding == \"codebert\":\n",
    "    max_len = get_max_len(sequences)\n",
    "    print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1277690",
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding == \"codebert\":\n",
    "    lines_pad_x_train = padSequences(sequences, max_len)\n",
    "    lines_pad_x_train = [arr.tolist() for arr in lines_pad_x_train]\n",
    "    lines_pad_x_train = np.array(lines_pad_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e01ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding == \"codebert\":\n",
    "    sentences = x_val\n",
    "    sequences = [tokenizer(sente, return_tensors=\"tf\", truncation=True, add_special_tokens=False) for sente in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e1a627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding == \"codebert\":\n",
    "    lines_pad_x_val = padSequences(sequences, max_len)\n",
    "    lines_pad_x_val = [arr.tolist() for arr in lines_pad_x_val]\n",
    "    lines_pad_x_val = np.array(lines_pad_x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd9fa37",
   "metadata": {},
   "source": [
    "Functions for Deep Learnig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1cbeaf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation functions\n",
    "def recall_metric(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = (true_positives + K.epsilon()) / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_metric(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = (true_positives + K.epsilon()) / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "\n",
    "    prec = precision_metric(y_true, y_pred)\n",
    "    rec = recall_metric(y_true, y_pred)\n",
    "    f1 = 2*((prec*rec)/(prec+rec+K.epsilon()))\n",
    "    return f1\n",
    "\n",
    "def f2_metric(y_true, y_pred):\n",
    "\n",
    "    prec = precision_metric(y_true, y_pred)\n",
    "    rec = recall_metric(y_true, y_pred)\n",
    "    f2 = 5*((prec*rec)/(4*prec+rec+K.epsilon()))\n",
    "    return f2\n",
    "\n",
    "def f2_loss(y_true, y_pred):\n",
    "\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    #tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f2 = 5*p*r / (4*p+r+K.epsilon())\n",
    "    f2 = tf.where(tf.math.is_nan(f2), tf.zeros_like(f2), f2)\n",
    "    \n",
    "    return 1 - K.mean(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13eb0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "# Add attention layer to the deep learning network\n",
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1), \n",
    "                               initializer='random_normal', trainable=True)\n",
    "        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1), \n",
    "                               initializer='zeros', trainable=True)        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        # Alignment scores. Pass them through tanh function\n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        # Remove dimension of size 1\n",
    "        e = K.squeeze(e, axis=-1)   \n",
    "        # Compute the weights\n",
    "        alpha = K.softmax(e)\n",
    "        # Reshape to tensorFlow format\n",
    "        alpha = K.expand_dims(alpha, axis=-1)\n",
    "        # Compute the context vector\n",
    "        context = x * alpha\n",
    "        context = K.sum(context, axis=1)\n",
    "        return context\n",
    "\n",
    "def buildLstmWithBahdanauAttention(max_len, top_words, dim, seed, embedding_matrix, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    kernel_initializer = glorot_uniform()\n",
    "    model.add(Embedding(input_dim=top_words, output_dim=dim, input_length=max_len, weights=[embedding_matrix], mask_zero=True, trainable=False))\n",
    "    model.add(GRU(500, activation='tanh', dropout=0.2, return_sequences=True, stateful=False, kernel_constraint=max_norm(3), bias_constraint=max_norm(3), kernel_initializer=kernel_initializer)) \n",
    "\n",
    "    model.add(GRU(100, activation='tanh', dropout=0.1, return_sequences=True, stateful=False, kernel_initializer=kernel_initializer))\n",
    "    model.add(GRU(200, activation='tanh', dropout=0.1, return_sequences=True, stateful=False, kernel_initializer=kernel_initializer))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Add BahdanauAttention layer before the final output layer\n",
    "    model.add(attention())\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=kernel_initializer))\n",
    "\n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[f2_metric])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b991073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning Models - Classifiers\n",
    "def buildLstm(max_len, top_words, dim, seed, embedding_matrix, learning_rate=0.001):\n",
    "    model=Sequential()\n",
    "    kernel_initializer = glorot_uniform() # glorot_uniform, RandomUniform, lecun_uniform, Constant, TruncatedNormal\n",
    "    model.add(Embedding(input_dim=top_words, output_dim=dim, input_length=None, weights=[embedding_matrix], mask_zero=True, trainable=False))\n",
    "    model.add(GRU(500, activation='tanh', dropout=0.2, return_sequences=True, stateful=False, kernel_constraint=max_norm(3), bias_constraint=max_norm(3), kernel_initializer=kernel_initializer)) # , recurrent_constraint=max_norm(3)\n",
    "    model.add(GRU(100, activation='tanh', dropout=0.1, return_sequences=True, stateful=False, kernel_initializer=kernel_initializer))\n",
    "    model.add(GRU(200, activation='tanh', dropout=0.1, stateful=False, kernel_initializer=kernel_initializer))\n",
    "    #model.add(SimpleRNN(300, dropout=0.3, stateful=False))\n",
    "    #model.add(Bidirectional(LSTM(300, dropout=0.3, stateful=False)))\n",
    "    #model.add(GRU(300, dropout=0.3, stateful=False))\n",
    "    model.add(BatchNormalization()) # default momentum=0.99\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=kernel_initializer))\n",
    "    #model.add(Dropout(0.2))\n",
    "    \n",
    "    #optimizer = optimizers.SGD(lr=learning_rate, decay=0.1, momentum=0.2, nesterov=True)\n",
    "    #optimizer = optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "    #optimizer = optimizers.Adagrad(lr=learning_rate, epsilon=None, decay=0.004)\n",
    "    #optimizer = optimizers.Nadam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate) # default 0.001\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[f2_metric])  \n",
    "    return model\n",
    "\n",
    "def buildCnn(max_len, top_words, dim, seed, embedding_matrix):\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Embedding(top_words, dim, input_length=None, weights=[embedding_matrix], mask_zero=True, trainable=False))\n",
    "    cnn_model.add(Conv1D(filters = 128, kernel_size = 5, activation = 'relu'))\n",
    "    '''cnn_model.add(MaxPooling1D(pool_size = 5))\n",
    "    cnn_model.add(Conv1D(filters = 128, kernel_size = 5, activation = 'relu'))\n",
    "    cnn_model.add(MaxPooling1D(pool_size = 5))\n",
    "    cnn_model.add(Conv1D(filters = 128, kernel_size = 5, activation = 'relu'))'''\n",
    "    cnn_model.add(GlobalMaxPool1D())\n",
    "    #cnn_model.add(Dense(units = 128, activation = 'relu'))\n",
    "    cnn_model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    cnn_model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics=[f2_metric])\n",
    "    return cnn_model\n",
    "\n",
    "def buildLstmCNN(max_len, top_words, dim, seed, embedding_matrix, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    kernel_initializer = glorot_uniform()\n",
    "\n",
    "    # Embedding Layer\n",
    "    model.add(Embedding(input_dim=top_words, output_dim=dim, input_length=None, weights=[embedding_matrix], mask_zero=True, trainable=False))\n",
    "\n",
    "    # LSTM/GRU Layers\n",
    "    model.add(GRU(500, activation='tanh', dropout=0.2, return_sequences=True, stateful=False, kernel_constraint=max_norm(3), bias_constraint=max_norm(3), kernel_initializer=kernel_initializer))\n",
    "    model.add(GRU(100, activation='tanh', dropout=0.1, return_sequences=True, stateful=False, kernel_initializer=kernel_initializer))\n",
    "    model.add(GRU(200, activation='tanh', dropout=0.1, return_sequences=True, stateful=False, kernel_initializer=kernel_initializer))\n",
    "    \n",
    "    # CNN Layers\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu', kernel_initializer=kernel_initializer)) \n",
    "    model.add(GlobalMaxPool1D())\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    #model.add(Dense(64, activation='relu', kernel_initializer=kernel_initializer))\n",
    "    # Classification layer\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=kernel_initializer))\n",
    "\n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[f2_metric])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a63be2",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe521ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(Y_train)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d232a7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 768)         38603520  \n",
      "                                                                 \n",
      " gru (GRU)                   (None, None, 500)         1905000   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, None, 100)         180600    \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, None, 200)         181200    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 128)         128128    \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,998,577\n",
      "Trainable params: 2,395,057\n",
      "Non-trainable params: 38,603,520\n",
      "_________________________________________________________________\n",
      "model summary\\m None\n",
      "Epoch 1/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.2008 - f2_metric: 0.3093\n",
      "Epoch 1: val_f2_metric improved from -inf to 0.51185, saving model to best_model.h5\n",
      "483/483 [==============================] - 76s 123ms/step - loss: 0.2008 - f2_metric: 0.3093 - val_loss: 0.0997 - val_f2_metric: 0.5119\n",
      "Epoch 2/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.1353 - f2_metric: 0.5890\n",
      "Epoch 2: val_f2_metric did not improve from 0.51185\n",
      "483/483 [==============================] - 55s 115ms/step - loss: 0.1353 - f2_metric: 0.5890 - val_loss: 0.0963 - val_f2_metric: 0.4634\n",
      "Epoch 3/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.1278 - f2_metric: 0.6473\n",
      "Epoch 3: val_f2_metric improved from 0.51185 to 0.60764, saving model to best_model.h5\n",
      "483/483 [==============================] - 56s 116ms/step - loss: 0.1278 - f2_metric: 0.6473 - val_loss: 0.0978 - val_f2_metric: 0.6076\n",
      "Epoch 4/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.1208 - f2_metric: 0.6840\n",
      "Epoch 4: val_f2_metric improved from 0.60764 to 0.61559, saving model to best_model.h5\n",
      "483/483 [==============================] - 56s 116ms/step - loss: 0.1208 - f2_metric: 0.6840 - val_loss: 0.0962 - val_f2_metric: 0.6156\n",
      "Epoch 5/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.1141 - f2_metric: 0.6914\n",
      "Epoch 5: val_f2_metric improved from 0.61559 to 0.62035, saving model to best_model.h5\n",
      "483/483 [==============================] - 57s 117ms/step - loss: 0.1141 - f2_metric: 0.6914 - val_loss: 0.0937 - val_f2_metric: 0.6204\n",
      "Epoch 6/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.1047 - f2_metric: 0.7290\n",
      "Epoch 6: val_f2_metric did not improve from 0.62035\n",
      "483/483 [==============================] - 55s 114ms/step - loss: 0.1047 - f2_metric: 0.7290 - val_loss: 0.0924 - val_f2_metric: 0.4306\n",
      "Epoch 7/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0971 - f2_metric: 0.7609\n",
      "Epoch 7: val_f2_metric improved from 0.62035 to 0.67129, saving model to best_model.h5\n",
      "483/483 [==============================] - 56s 117ms/step - loss: 0.0971 - f2_metric: 0.7609 - val_loss: 0.1119 - val_f2_metric: 0.6713\n",
      "Epoch 8/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0895 - f2_metric: 0.7693\n",
      "Epoch 8: val_f2_metric did not improve from 0.67129\n",
      "483/483 [==============================] - 55s 114ms/step - loss: 0.0895 - f2_metric: 0.7693 - val_loss: 0.0954 - val_f2_metric: 0.6530\n",
      "Epoch 9/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0799 - f2_metric: 0.7987\n",
      "Epoch 9: val_f2_metric did not improve from 0.67129\n",
      "483/483 [==============================] - 55s 113ms/step - loss: 0.0799 - f2_metric: 0.7987 - val_loss: 0.0952 - val_f2_metric: 0.5971\n",
      "Epoch 10/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0699 - f2_metric: 0.8243\n",
      "Epoch 10: val_f2_metric did not improve from 0.67129\n",
      "483/483 [==============================] - 55s 115ms/step - loss: 0.0699 - f2_metric: 0.8243 - val_loss: 0.1034 - val_f2_metric: 0.6414\n",
      "Epoch 11/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0612 - f2_metric: 0.8445\n",
      "Epoch 11: val_f2_metric did not improve from 0.67129\n",
      "483/483 [==============================] - 55s 114ms/step - loss: 0.0612 - f2_metric: 0.8445 - val_loss: 0.1282 - val_f2_metric: 0.6615\n",
      "Epoch 12/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0544 - f2_metric: 0.8646\n",
      "Epoch 12: val_f2_metric did not improve from 0.67129\n",
      "483/483 [==============================] - 55s 114ms/step - loss: 0.0544 - f2_metric: 0.8646 - val_loss: 0.1121 - val_f2_metric: 0.5040\n",
      "Epoch 13/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0458 - f2_metric: 0.8793\n",
      "Epoch 13: val_f2_metric did not improve from 0.67129\n",
      "483/483 [==============================] - 56s 116ms/step - loss: 0.0458 - f2_metric: 0.8793 - val_loss: 0.1209 - val_f2_metric: 0.5774\n",
      "Epoch 14/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0431 - f2_metric: 0.8814\n",
      "Epoch 14: val_f2_metric did not improve from 0.67129\n",
      "483/483 [==============================] - 56s 116ms/step - loss: 0.0431 - f2_metric: 0.8814 - val_loss: 0.1324 - val_f2_metric: 0.4587\n",
      "Epoch 15/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0369 - f2_metric: 0.8974\n",
      "Epoch 15: val_f2_metric improved from 0.67129 to 0.67901, saving model to best_model.h5\n",
      "483/483 [==============================] - 57s 117ms/step - loss: 0.0369 - f2_metric: 0.8974 - val_loss: 0.1403 - val_f2_metric: 0.6790\n",
      "Epoch 16/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0308 - f2_metric: 0.9198\n",
      "Epoch 16: val_f2_metric did not improve from 0.67901\n",
      "483/483 [==============================] - 56s 116ms/step - loss: 0.0308 - f2_metric: 0.9198 - val_loss: 0.1555 - val_f2_metric: 0.6255\n",
      "Epoch 17/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0287 - f2_metric: 0.9210\n",
      "Epoch 17: val_f2_metric did not improve from 0.67901\n",
      "483/483 [==============================] - 56s 117ms/step - loss: 0.0287 - f2_metric: 0.9210 - val_loss: 0.1703 - val_f2_metric: 0.6349\n",
      "Epoch 18/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0274 - f2_metric: 0.9384\n",
      "Epoch 18: val_f2_metric did not improve from 0.67901\n",
      "483/483 [==============================] - 56s 117ms/step - loss: 0.0274 - f2_metric: 0.9384 - val_loss: 0.1400 - val_f2_metric: 0.5151\n",
      "Epoch 19/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0242 - f2_metric: 0.9466\n",
      "Epoch 19: val_f2_metric did not improve from 0.67901\n",
      "483/483 [==============================] - 56s 116ms/step - loss: 0.0242 - f2_metric: 0.9466 - val_loss: 0.1700 - val_f2_metric: 0.5980\n",
      "Epoch 20/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0216 - f2_metric: 0.9457\n",
      "Epoch 20: val_f2_metric did not improve from 0.67901\n",
      "483/483 [==============================] - 56s 116ms/step - loss: 0.0216 - f2_metric: 0.9457 - val_loss: 0.1517 - val_f2_metric: 0.5509\n",
      "Epoch 21/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0206 - f2_metric: 0.9502\n",
      "Epoch 21: val_f2_metric did not improve from 0.67901\n",
      "483/483 [==============================] - 56s 116ms/step - loss: 0.0206 - f2_metric: 0.9502 - val_loss: 0.1799 - val_f2_metric: 0.4832\n",
      "Epoch 22/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0218 - f2_metric: 0.9455\n",
      "Epoch 22: val_f2_metric did not improve from 0.67901\n",
      "483/483 [==============================] - 57s 118ms/step - loss: 0.0218 - f2_metric: 0.9455 - val_loss: 0.1662 - val_f2_metric: 0.4742\n",
      "Epoch 23/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0195 - f2_metric: 0.9505\n",
      "Epoch 23: val_f2_metric did not improve from 0.67901\n",
      "483/483 [==============================] - 56s 117ms/step - loss: 0.0195 - f2_metric: 0.9505 - val_loss: 0.1843 - val_f2_metric: 0.6385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0171 - f2_metric: 0.9593\n",
      "Epoch 24: val_f2_metric did not improve from 0.67901\n",
      "483/483 [==============================] - 57s 117ms/step - loss: 0.0171 - f2_metric: 0.9593 - val_loss: 0.1812 - val_f2_metric: 0.5938\n",
      "Epoch 25/100\n",
      "483/483 [==============================] - ETA: 0s - loss: 0.0169 - f2_metric: 0.9628\n",
      "Epoch 25: val_f2_metric did not improve from 0.67901\n",
      "483/483 [==============================] - 57s 117ms/step - loss: 0.0169 - f2_metric: 0.9628 - val_loss: 0.1797 - val_f2_metric: 0.6195\n",
      "Epoch 25: early stopping\n",
      "206/206 [==============================] - 11s 33ms/step\n",
      "TP= 211\n",
      "TN= 6124\n",
      "FP= 197\n",
      "FN= 59\n",
      "Accuracy:96.12%\n",
      "Precision:51.72%\n",
      "Recall:78.15%\n",
      "F1 score:62.24%\n",
      "Roc_Auc score:87.52%\n",
      "F2 score:70.90%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      6321\n",
      "           1       0.52      0.78      0.62       270\n",
      "\n",
      "    accuracy                           0.96      6591\n",
      "   macro avg       0.75      0.88      0.80      6591\n",
      "weighted avg       0.97      0.96      0.96      6591\n",
      "\n",
      "Cross Validation is completed after 1439678\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhEAAAGdCAYAAACsBCEsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzdUlEQVR4nO3df1yUZb7/8fckMKnBrIjMOKVFyZqGlWGL6JaWiroRedoNW4psc/2xlkZIltvZzTobpJXYRpnaD00t21NRtlsotWWZokaxqWk/vpqmMqCF+CN2IJjvH57udm7Qbu7GGOv1PI/78WCu+zPXXPg4uR8/n+u6xxEIBAICAABopZPaegEAAODERBIBAABsIYkAAAC2kEQAAABbSCIAAIAtJBEAAMAWkggAAGALSQQAALCFJAIAANgS0dYL+EbDvm1tvQQg7MR0u6StlwCEpbq6Hcd1/lD+b1Jk3JkhmyvchE0SAQBA2GhqbOsVnBBoZwAAAFtIIgAAMAs0he5qpd27d+vaa69V586d1aFDB51//vkqLy//dmmBgGbMmCGv16v27dtr8ODB2rx5c9Acfr9fkydPVlxcnDp27KiMjAzt2rUrKKampkbZ2dlyuVxyuVzKzs7W/v37W7VWkggAAMyamkJ3tUJNTY0GDhyoyMhIvfrqq/rwww/1wAMP6Gc/+5kRM2vWLM2ePVtFRUXasGGDPB6Phg0bpoMHDxoxOTk5Ki4u1rJly7R69WodOnRI6enpamz8tk2TlZWliooKlZSUqKSkRBUVFcrOzm7Veh3h8lXgbKwEmmNjJdCy472xsn7P5u8OsijKe47l2Ntvv13vvPOO3n777RbvBwIBeb1e5eTk6LbbbpN0pOrgdrs1c+ZMTZgwQbW1terSpYsWL16s0aNHS5L27Nmjbt266ZVXXtHw4cO1ZcsW9e7dW2VlZUpJSZEklZWVKTU1VVu3blXPnj0trZdKBAAAx5Hf79eBAweCLr/f32Ls8uXL1a9fP1111VWKj49X3759tWDBAuP+9u3b5fP5lJaWZow5nU4NGjRIa9askSSVl5eroaEhKMbr9SopKcmIWbt2rVwul5FASFL//v3lcrmMGCtIIgAAMAthO6OgoMDYd/DNVVBQ0OLHbtu2TXPnzlViYqJWrFihiRMnasqUKXrqqackST6fT5LkdruD3ud2u417Pp9PUVFR6tSp0zFj4uPjm31+fHy8EWMFRzwBADCzsSHyaKZPn67c3NygMafT2WJsU1OT+vXrp/z8fElS3759tXnzZs2dO1fXXXedEedwOIKXGwg0GzMzx7QUb2We/0QlAgCA48jpdComJiboOloS0bVrV/Xu3TtorFevXtq5c6ckyePxSFKzakF1dbVRnfB4PKqvr1dNTc0xY6qqqpp9/t69e5tVOY6FJAIAALOmxtBdrTBw4EB99NFHQWMff/yxTj/9dElSQkKCPB6PSktLjfv19fVatWqVBgwYIElKTk5WZGRkUExlZaU2bdpkxKSmpqq2tlbr1683YtatW6fa2lojxgraGQAAmIWwndEat9xyiwYMGKD8/HxlZmZq/fr1mj9/vubPny/pSAsiJydH+fn5SkxMVGJiovLz89WhQwdlZWVJklwul8aOHaupU6eqc+fOio2NVV5envr06aOhQ4dKOlLdGDFihMaNG6d58+ZJksaPH6/09HTLJzMkkggAAMLGhRdeqOLiYk2fPl133323EhISNGfOHF1zzTVGzLRp01RXV6dJkyappqZGKSkpWrlypaKjo42YwsJCRUREKDMzU3V1dRoyZIgWLlyodu3aGTFLly7VlClTjFMcGRkZKioqatV6eU4EEMZ4TgTQsuP+nIht6787yKKoM38RsrnCDZUIAABMAm3UzjjRsLESAADYQiUCAACzVn7nxU8VSQQAAGa0MywhiQAAwKyVz3f4qWJPBAAAsIVKBAAAZrQzLCGJAADAjI2VltDOAAAAtlCJAADAjHaGJSQRAACY0c6whHYGAACwhUoEAAAmgQDPibCCJAIAADP2RFhCOwMAANhCJQIAADM2VlpCEgEAgBntDEtIIgAAMOMLuCxhTwQAALCFSgQAAGa0MywhiQAAwIyNlZbQzgAAALZQiQAAwIx2hiUkEQAAmNHOsIR2BgAAsIVKBAAAZlQiLCGJAADAhG/xtIZ2BgAAsIVKBAAAZrQzLCGJAADAjCOelpBEAABgRiXCEvZEAAAAW6hEAABgRjvDEpIIAADMaGdYQjsDAADYQiUCAAAz2hmWkEQAAGBGO8MS2hkAAMAWKhEAAJhRibCEJAIAADP2RFhCOwMAANhCJQIAADPaGZaQRAAAYEY7wxKSCAAAzKhEWMKeCAAAYAuVCAAAzGhnWEISAQCAGe0MS2hnAAAAW6hEAABgRiXCEpIIAADMAoG2XsEJgXYGAABhYsaMGXI4HEGXx+Mx7gcCAc2YMUNer1ft27fX4MGDtXnz5qA5/H6/Jk+erLi4OHXs2FEZGRnatWtXUExNTY2ys7PlcrnkcrmUnZ2t/fv3t3q9JBEAAJg1NYXuaqVzzjlHlZWVxrVx40bj3qxZszR79mwVFRVpw4YN8ng8GjZsmA4ePGjE5OTkqLi4WMuWLdPq1at16NAhpaenq7Gx0YjJyspSRUWFSkpKVFJSooqKCmVnZ7d6rbQzAAAwa8M9EREREUHVh28EAgHNmTNHd9xxh6688kpJ0qJFi+R2u/X0009rwoQJqq2t1eOPP67Fixdr6NChkqQlS5aoW7dueu211zR8+HBt2bJFJSUlKisrU0pKiiRpwYIFSk1N1UcffaSePXtaXiuVCAAAjiO/368DBw4EXX6//6jxn3zyibxerxISEnT11Vdr27ZtkqTt27fL5/MpLS3NiHU6nRo0aJDWrFkjSSovL1dDQ0NQjNfrVVJSkhGzdu1auVwuI4GQpP79+8vlchkxVpFEAABgFmgK2VVQUGDsPfjmKigoaPFjU1JS9NRTT2nFihVasGCBfD6fBgwYoC+++EI+n0+S5Ha7g97jdruNez6fT1FRUerUqdMxY+Lj45t9dnx8vBFjFe0MAADMQtjOmD59unJzc4PGnE5ni7EjR440fu7Tp49SU1N11llnadGiRerfv78kyeFwBL0nEAg0GzMzx7QUb2UeMyoRAACYBQIhu5xOp2JiYoKuoyURZh07dlSfPn30ySefGPskzNWC6upqozrh8XhUX1+vmpqaY8ZUVVU1+6y9e/c2q3J8F5IIAADClN/v15YtW9S1a1clJCTI4/GotLTUuF9fX69Vq1ZpwIABkqTk5GRFRkYGxVRWVmrTpk1GTGpqqmpra7V+/XojZt26daqtrTVirKKdAQCAWRudzsjLy9Pll1+u7t27q7q6Wn/5y1904MABjRkzRg6HQzk5OcrPz1diYqISExOVn5+vDh06KCsrS5Lkcrk0duxYTZ06VZ07d1ZsbKzy8vLUp08f47RGr169NGLECI0bN07z5s2TJI0fP17p6emtOpkhkUQAANBcGyURu3bt0m9/+1vt27dPXbp0Uf/+/VVWVqbTTz9dkjRt2jTV1dVp0qRJqqmpUUpKilauXKno6GhjjsLCQkVERCgzM1N1dXUaMmSIFi5cqHbt2hkxS5cu1ZQpU4xTHBkZGSoqKmr1eh2BQHg827Nh37a2XgIQdmK6XdLWSwDCUl3djuM7/+N5IZur/dj7QzZXuKESAQCAWYAv4LKCJAIAAJNAU1gU6cMepzMAAIAtVCIAADBrw+/OOJGQRAAAYMaeCEtoZwAAAFuoRAAAYMbGSktIIgAAMGNPhCUkEQAAmJFEWMKeCAAAYAuVCAAAzMLjGyHCHpWIE0DV3n267a5ZGjgyU/0uHaVfj7lRm7d+ctT4vfu+1LQZM5V+9e/V55e/0r1zHv1B1vnx/9uu62+8VcmXXKFLr7hWc59Yqv/8apb3/rVJ106cqoEjM5V8yRW6/Lfj9NSy4h9kbfjpyMubpNWrl6u6erN27CjX3/42X4mJZx73zx01aqTee+817d//sd577zVlZAwPi3XBpqam0F0/YiQRYa72wEFlT5yqyIgIPfrA/+ilpfN06+TfK/qUjkd9T31Dgzr9zKVxY65Wzx4JIVnH7soqJQ0cedT7hw4f1ricO9QlrrOWPf6gpt/yBy185nktWvaCEdO+/cnK+vXlWvTwfVr+9HyNv/63emjBIv3vS6+EZI2AJF10UYoeffQpDRo0Sunp16pduwj9/e+L1aFDe9tzXnvtb7RixbKj3k9JuUCLFxfp6adf0C9+MVJPP/2Clix5WBdeeP5xXRfQ1mhnhLknlv6vPPFd9Jc7co2xU7u6j/meU7u6NT1noiSp+B8rjxpX/I+VemLpc9pd6dOpHreuueoKXX1luq11/n3lG6qvr9c9d+QqKipKiWeeoR2f79ZTy4o15uor5XA41OvnPdTr5z2C1vnam++o/F+bddUVv7L1uYDZFVeMCXo9YUKePv/8ffXt20fvvLNekhQZGakZM/J09dWj5HLF6MMPP9Idd9yrt98us/WZN910g15/fbXuv/8RSdL99z+iiy5K0U033aAxY6ZYXhfCCEc8LaESEebeWF2mc85OVO5/36OLL7tav7n+Rj23/NXvPe9zy1/VX+ct0pTxY7R86XxNmXC9HlrwlF56pdTWfP/atFX9zu+jqKgoY2xgygWq3veFdldWtfieLR9/qopNW9Tv/D62PhOwIiYmWpJUU7PfGJs//36lpvbTddfdpAsvHK4XXnhFy5cv0llnnWHrM1JSLtDrr78VNPbaa2+pf//kVq0LYSTQFLrrR6zVlYhdu3Zp7ty5WrNmjXw+nxwOh9xutwYMGKCJEyeqW7dux2OdP1m79vj07Iv/0HWjr9S460Zr44cfq6DwUUVGRuqKkUNtz/vowmd06+RxGjZ4oCTpNK9H2z7bqb+99Kqu+NWwVs+374svm1VIOnfqdOTelzU6zesxxoeMulZf7q9VY2OTJt1wjX6TMcL27wF8l5kz/6R33lmvDz/8WJKUkNBdmZkZ6tEjRZWV1ZKkOXPma9iwQbruuqt05533tfoz3O4uqq7eFzRWXb1PbncXy+sCTkStSiJWr16tkSNHqlu3bkpLS1NaWpoCgYCqq6v14osv6qGHHtKrr76qgQMHHnMev98vv98fNHaS3y+n09n63+BHrqkpoHPOTlTOxOslSb1+3kOfbt+hvxX/w3YS8WXNfvmq9urPBXN058wHjfHGxkad0vHbvRZXXDNBe6qO/CX7zU7lC4f+l3Hf647XS0vnGa8dDkfQ5wR05D3Bo9KiR+7XV3V1+mDzVhXOfVLdT/PqV8MG2/pdgGMpLPwf9elztoYM+Y0x1rdvkk466SR98MGbQbFOZ5S+/LJGktStm1fvvfeacS8iop0iIyO1d++HxtgzzxRrypQ7jNcB025+h8PRbOxY60KYoZ1hSauSiFtuuUW///3vVVhYeNT7OTk52rBhwzHnKSgo0F133RU09t+3TtGfp93cmuX8JHTpHKuzzugeNHbmGd302pvv2J6z6f/+Yptx2xSde87ZQfdOOunbDtfcB+7W1183SjpyQuR3N92m5xc+bNyPiGhn/BzXOVb7vqgJmuvL/yvTdo7tFDT+TVXi52cl6Isv9+uRx5eQRCDkZs++S+npQzV0aKZ27/YZ4yeddJK+/vprDRiQrsbGxqD3HD78lSRpz54qpaR8u5F41KgRGjVqpK6//tu/ow4ePGT8XFW1t1nVoUuXzs2qE8daF8JL4Ed+qiJUWpVEbNq0SUuWLDnq/QkTJujRR7/7OOH06dOVm5sbNHbSwd2tWcpPRt9ze+uznbuCxnbs3K2unnjbc8bFdpK7S2ft2uNT+vBLjxrn9XzbnmjX7kjC0P00b4ux5yWdrb/OW6SGhgZFRkZKktasf0/xcZ2PuRE0EAiovqHBzq8BHFVh4d3KyBiutLTR2rHj86B7FRWbFRERofj4znrnnZb/wdPY2Kht23YYr6urv1Bd3b+Dxv7TunXv6dJLL9JDDz1ujA0ZcrHKysotrws4EbUqiejatavWrFmjnj17tnh/7dq16tq163fO43Q6m7UuGuqbZ+yQskePUvaEqZq/aJlGDLlYGz/8SM8tf1V3TptixBTOfVLV+75QwZ/yjLGtH/8/SdJXX/1bNftrtfXj/6fIyAidlXC6JOkPN1yre+c8qo4dO+ii/v1U39CgzVs/0YGDhzTm6itbvc7Lhl2iuU88rTvuma1x143Wjs93a8FTz2ri77KMNsczz7+sru4uSjj9yL6Z9z7YrIXPPK+s32TY/vMBzObM+YtGj87QVVeN06FDh40KQW3tAf373359+ul2PfNMsR57rFC33/4XVVRsVlxcJw0ePECbNn2kFSveaPVnPvzwkyot/ZumTp2ol18u1eWXD9Ollw4Mald817oQZmhnWNKqJCIvL08TJ05UeXm5hg0bJrfbLYfDIZ/Pp9LSUj322GOaM2fOcVrqT1OfXj01p+BPevDRhXp04dM6tatHt908IaiCsO+LL1X5zd6F//Ob391k/PzhR5/oH6VvyuuJ18rnFx25nzFC7U926smnn9PsRx5X+5NP1s/POkPXZo6ytc7oUzpqwZx7dM8Dj2j02CmKiT5F1119ZVBC0tTUpDmPLtTuSp/atWunbqd2Vc4ffqdMjncihCZMyJYklZb+LWh83LipWrLkOUnS+PF5uv32ybr33v+W1+vWF1/s1/r176mkpPUJhCSVlZXruusm6847p+rPf56qbdt2Kjv7Jm3YUNGqdSGM/MhPVYSKI3C0nT9H8eyzz6qwsFDl5eVGP7Fdu3ZKTk5Wbm6uMjMzbS2kYd82W+8Dfsxiul3S1ksAwlJdXcutpVA5fPc1IZur45+XhmyucNPqI56jR4/W6NGj1dDQoH37jrQg4uLijD44AAD4abD9xMrIyEhL+x8AADjhcDrDEh57DQCAGRsrLeGx1wAAwBYqEQAAmHE6wxKSCAAAzGhnWEI7AwAA2EIlAgAAE747wxqSCAAAzGhnWEI7AwAA2EIlAgAAMyoRlpBEAABgxhFPS0giAAAwoxJhCXsiAACALVQiAAAwCVCJsIQkAgAAM5IIS2hnAAAAW6hEAABgxhMrLSGJAADAjHaGJbQzAACALVQiAAAwoxJhCUkEAAAmgQBJhBW0MwAAgC1UIgAAMKOdYQlJBAAAZiQRlpBEAABgwmOvrWFPBAAAsIVKBAAAZlQiLKESAQCAWVMIL5sKCgrkcDiUk5NjjAUCAc2YMUNer1ft27fX4MGDtXnz5qD3+f1+TZ48WXFxcerYsaMyMjK0a9euoJiamhplZ2fL5XLJ5XIpOztb+/fvb/UaSSIAAAgzGzZs0Pz583XuuecGjc+aNUuzZ89WUVGRNmzYII/Ho2HDhungwYNGTE5OjoqLi7Vs2TKtXr1ahw4dUnp6uhobG42YrKwsVVRUqKSkRCUlJaqoqFB2dnar10kSAQCASaApELKrtQ4dOqRrrrlGCxYsUKdOnb5dUyCgOXPm6I477tCVV16ppKQkLVq0SF999ZWefvppSVJtba0ef/xxPfDAAxo6dKj69u2rJUuWaOPGjXrttdckSVu2bFFJSYkee+wxpaamKjU1VQsWLNDf//53ffTRR61aK0kEAABmTYGQXX6/XwcOHAi6/H7/UT/6xhtv1GWXXaahQ4cGjW/fvl0+n09paWnGmNPp1KBBg7RmzRpJUnl5uRoaGoJivF6vkpKSjJi1a9fK5XIpJSXFiOnfv79cLpcRYxVJBAAAx1FBQYGx9+Cbq6CgoMXYZcuWqby8vMX7Pp9PkuR2u4PG3W63cc/n8ykqKiqogtFSTHx8fLP54+PjjRirOJ0BAIDZ99gQaTZ9+nTl5uYGjTmdzmZxn3/+uW6++WatXLlSJ5988lHnczgcQa8DgUCzMTNzTEvxVuYxoxIBAIBJKPdEOJ1OxcTEBF0tJRHl5eWqrq5WcnKyIiIiFBERoVWrVumvf/2rIiIijAqEuVpQXV1t3PN4PKqvr1dNTc0xY6qqqpp9/t69e5tVOb4LSQQAAGFgyJAh2rhxoyoqKoyrX79+uuaaa1RRUaEzzzxTHo9HpaWlxnvq6+u1atUqDRgwQJKUnJysyMjIoJjKykpt2rTJiElNTVVtba3Wr19vxKxbt061tbVGjFW0MwAAMAthO8Oq6OhoJSUlBY117NhRnTt3NsZzcnKUn5+vxMREJSYmKj8/Xx06dFBWVpYkyeVyaezYsZo6dao6d+6s2NhY5eXlqU+fPsZGzV69emnEiBEaN26c5s2bJ0kaP3680tPT1bNnz1atmSQCAACTcP3ujGnTpqmurk6TJk1STU2NUlJStHLlSkVHRxsxhYWFioiIUGZmpurq6jRkyBAtXLhQ7dq1M2KWLl2qKVOmGKc4MjIyVFRU1Or1OAKBQFj8STXs29bWSwDCTky3S9p6CUBYqqvbcVzn//KKQSGbK/alVSGbK9ywJwIAANhCOwMAAJNAG+yJOBGRRAAAYEYSYQntDAAAYAuVCAAATGhnWEMSAQCAGUmEJbQzAACALVQiAAAwoZ1hDUkEAAAmJBHWkEQAAGBCEmENeyIAAIAtVCIAADALONp6BScEkggAAExoZ1hDOwMAANhCJQIAAJNAE+0MK0giAAAwoZ1hDe0MAABgC5UIAABMApzOsIQkAgAAE9oZ1tDOAAAAtlCJAADAhNMZ1pBEAABgEgi09QpODCQRAACYUImwhj0RAADAFioRAACYUImwhiQCAAAT9kRYQzsDAADYQiUCAAAT2hnWkEQAAGDCY6+toZ0BAABsoRIBAIAJ351hDUkEAAAmTbQzLKGdAQAAbKESAQCACRsrrSGJAADAhCOe1pBEAABgwhMrrWFPBAAAsIVKBAAAJrQzrCGJAADAhCOe1tDOAAAAtlCJAADAhCOe1pBEAABgwukMa2hnAAAAW6hEAABgwsZKa0giAAAwYU+ENbQzAACALVQiAAAwYWOlNSQRAACYsCfCmrBJItp7L2rrJQBhxxkR2dZLAH6S2BNhDXsiAACALSQRAACYNAUcIbtaY+7cuTr33HMVExOjmJgYpaam6tVXXzXuBwIBzZgxQ16vV+3bt9fgwYO1efPmoDn8fr8mT56suLg4dezYURkZGdq1a1dQTE1NjbKzs+VyueRyuZSdna39+/e3+s+JJAIAAJNACK/WOO2003Tvvffq3Xff1bvvvqtLL71UV1xxhZEozJo1S7Nnz1ZRUZE2bNggj8ejYcOG6eDBg8YcOTk5Ki4u1rJly7R69WodOnRI6enpamxsNGKysrJUUVGhkpISlZSUqKKiQtnZ2a3+c3IEAuGxBzUi6tS2XgIQdtgTAbTs8FefHdf5y7xXhmyu/nte+F7vj42N1X333acbbrhBXq9XOTk5uu222yQdqTq43W7NnDlTEyZMUG1trbp06aLFixdr9OjRkqQ9e/aoW7dueuWVVzR8+HBt2bJFvXv3VllZmVJSUiRJZWVlSk1N1datW9WzZ0/La6MSAQCASSjbGX6/XwcOHAi6/H7/d66hsbFRy5Yt0+HDh5Wamqrt27fL5/MpLS3NiHE6nRo0aJDWrFkjSSovL1dDQ0NQjNfrVVJSkhGzdu1auVwuI4GQpP79+8vlchkxVpFEAABgEgg4QnYVFBQYew++uQoKCo762Rs3btQpp5wip9OpiRMnqri4WL1795bP55Mkud3uoHi3223c8/l8ioqKUqdOnY4ZEx8f3+xz4+PjjRirwuaIJwAAP0bTp09Xbm5u0JjT6TxqfM+ePVVRUaH9+/fr+eef15gxY7Rq1SrjvsMRvFkzEAg0GzMzx7QUb2UeM5IIAABMmkI4l9PpPGbSYBYVFaUePXpIkvr166cNGzbowQcfNPZB+Hw+de3a1Yivrq42qhMej0f19fWqqakJqkZUV1drwIABRkxVVVWzz927d2+zKsd3oZ0BAIBJQI6QXd97LYGA/H6/EhIS5PF4VFpaatyrr6/XqlWrjAQhOTlZkZGRQTGVlZXatGmTEZOamqra2lqtX7/eiFm3bp1qa2uNGKuoRAAAECb++Mc/auTIkerWrZsOHjyoZcuW6c0331RJSYkcDodycnKUn5+vxMREJSYmKj8/Xx06dFBWVpYkyeVyaezYsZo6dao6d+6s2NhY5eXlqU+fPho6dKgkqVevXhoxYoTGjRunefPmSZLGjx+v9PT0Vp3MkEgiAABopqmNHn5QVVWl7OxsVVZWyuVy6dxzz1VJSYmGDRsmSZo2bZrq6uo0adIk1dTUKCUlRStXrlR0dLQxR2FhoSIiIpSZmam6ujoNGTJECxcuVLt27YyYpUuXasqUKcYpjoyMDBUVFbV6vTwnAghjPCcCaNnxfk7EP92ZIZvr0qq/hWyucEMlAgAAk1DsZfgpYGMlAACwhUoEAAAmoTzi+WNGEgEAgAntDGtoZwAAAFuoRAAAYEI7wxqSCAAATEgirKGdAQAAbKESAQCACRsrrSGJAADApIkcwhLaGQAAwBYqEQAAmDTRzrCEJAIAAJOw+GbKEwBJBAAAJhzxtIY9EQAAwBYqEQAAmDQ52BNhBUkEAAAm7ImwhnYGAACwhUoEAAAmbKy0hiQCAAATnlhpDe0MAABgC5UIAABMeGKlNSQRAACYcDrDGtoZAADAFioRAACYsLHSGpIIAABMOOJpDUkEAAAm7Imwhj0RAADAFioRAACYsCfCGpIIAABM2BNhDe0MAABgC5UIAABMqERYQxIBAIBJgD0RltDOAAAAtlCJAADAhHaGNSQRAACYkERYQzsDAADYQiUCAAATHnttDUkEAAAmPLHSGpIIAABM2BNhDXsiAACALVQiAAAwoRJhDUkEAAAmbKy0hnYGAACwhUoEAAAmnM6whiQCAAAT9kRYQzsDAADYQiUCAAATNlZaQxIBAIBJE2mEJbQzAACALSQRAACYNIXwao2CggJdeOGFio6OVnx8vEaNGqWPPvooKCYQCGjGjBnyer1q3769Bg8erM2bNwfF+P1+TZ48WXFxcerYsaMyMjK0a9euoJiamhplZ2fL5XLJ5XIpOztb+/fvb9V6SSIAADAJhPBqjVWrVunGG29UWVmZSktL9fXXXystLU2HDx82YmbNmqXZs2erqKhIGzZskMfj0bBhw3Tw4EEjJicnR8XFxVq2bJlWr16tQ4cOKT09XY2NjUZMVlaWKioqVFJSopKSElVUVCg7O7tV63UEAoGwaPxERJ3a1ksAwo4zIrKtlwCEpcNffXZc559x+jWhm2vHUtvv3bt3r+Lj47Vq1SpdfPHFCgQC8nq9ysnJ0W233SbpSNXB7XZr5syZmjBhgmpra9WlSxctXrxYo0ePliTt2bNH3bp10yuvvKLhw4dry5Yt6t27t8rKypSSkiJJKisrU2pqqrZu3aqePXtaWh+VCAAAjiO/368DBw4EXX6/39J7a2trJUmxsbGSpO3bt8vn8yktLc2IcTqdGjRokNasWSNJKi8vV0NDQ1CM1+tVUlKSEbN27Vq5XC4jgZCk/v37y+VyGTFWkEQAAGDS5AjdVVBQYOw7+OYqKCj4zjUEAgHl5ubql7/8pZKSkiRJPp9PkuR2u4Ni3W63cc/n8ykqKkqdOnU6Zkx8fHyzz4yPjzdirOCIJwAAJqE84nnH9OnKzc0NGnM6nd/5vptuukkffPCBVq9e3eyewxH8XO5AINBszMwc01K8lXn+E5UIAACOI6fTqZiYmKDru5KIyZMna/ny5XrjjTd02mmnGeMej0eSmlULqqurjeqEx+NRfX29ampqjhlTVVXV7HP37t3brMpxLCQRAACYtNXpjEAgoJtuukkvvPCC/vnPfyohISHofkJCgjwej0pLS42x+vp6rVq1SgMGDJAkJScnKzIyMiimsrJSmzZtMmJSU1NVW1ur9evXGzHr1q1TbW2tEWMF7QwAAEza6gu4brzxRj399NN66aWXFB0dbVQcXC6X2rdvL4fDoZycHOXn5ysxMVGJiYnKz89Xhw4dlJWVZcSOHTtWU6dOVefOnRUbG6u8vDz16dNHQ4cOlST16tVLI0aM0Lhx4zRv3jxJ0vjx45Wenm75ZIZEEgEAQNiYO3euJGnw4MFB408++aSuv/56SdK0adNUV1enSZMmqaamRikpKVq5cqWio6ON+MLCQkVERCgzM1N1dXUaMmSIFi5cqHbt2hkxS5cu1ZQpU4xTHBkZGSoqKmrVenlOBBDGeE4E0LLj/ZyI2874bcjmmvnZMyGbK9xQiQAAwCQs/nV9AmBjJQAAsIVKBAAAJm21sfJEQxIBAIBJKB829WNGEgEAgAkphDXsiQAAALZQiQAAwIQ9EdaQRAAAYBKgoWEJ7QwAAGALlQgAAExoZ1hDEgEAgAlHPK2hnQEAAGyhEgEAgAl1CGuoRPwE/flPufq6fnfQtWvn+8b9+Pg4Pf5YoXZ+Vq4D+z/VP15eoh49EtpwxUCwvLxJeuvtl+Sr2qTPPntXy56dr8TEM4/5Ho+ni5588kG9X/G6Dh7aplmz/vyDrPWcc3qqZMWz2vfFVn3yaZlunz4l6H7GFcP18suL9dmOclX6Nuqfb7ygoUMv/kHWhqNrUiBk148ZScRP1KbNW3Vqt/ON6/wLhhj3XnjuCZ2Z0F1X/voG9fvFcO3YuVsrXl2mDh3at+GKgW/98qIUzZ+3WJcM/i9dfnm2IiLaafnLTx3z/0ejopzat+9L3TfrYW3cuCUk6+je/bRjfiV1dPQpevnvS+SrrNLFF2Vo6tQ7dfPN4zRlyu+//V0Gpuif/1ytK6/8nX458HK99dZa/e9zj+m8884JyRqB44l2xk/U1183qqpqb7PxxMQz1b9/ss49/xJ9+OHHkqSbJk9X5e4PdPXoUXriyWd+6KUCzYy6YkzQ64kTbtWOne+pb98+eued9S2+Z+fOXbr11rskSdnXZR517uzsq5RzywSdcUY37dixS3PnPqkF85fYWufoq0fJ6XRq/Pg81dfX68MPP1ZijzM1ecrv9de/PiZJmjbt7qD3zLjzPl122TCN/NUQ/etfm219Lr4/TmdYQyXiJyqxR4J2flauTz5aq6VLHlFCQndJktMZJUn697/9RmxTU5Pq6+s1cOAv2mStwHeJiYmWJNXU7P9e81z/u6t154w83XXXfbqg7xDNmDFLf/rTVF1zza9tzZfyi75avXqd6uvrjbHXXntLXq9Hp59+WovvcTgcio7u+L1/F3w/gRD+348ZScRP0Pr17+v6G27Wr9Kv0cQ/TJPH3UVvr3pJsbGdtHXrp/rss891z1+m62c/cykyMlLTbr1RXbu61dUT39ZLB1p078z/1jvvrDeqZ3bdfvtkTb/9Hi1/aYV27Nil5S+tUFHR47phbJat+dzuLqquDq74Vf3fa7e75f+ebr55nDp06KAXnv+Hrc9EaDSF8PoxC3k74/PPP9edd96pJ5544qgxfr9ffr8/aCwQCMjhcIR6OWhByYo3jJ83aavWlr2rj7eu0XXZV2nOg/OVOXqc5s9/QPuqP9TXX3+t119/W6+++nobrhg4utmFdyspqZeGDv3N95onLi5W3bqdqkfmzlTRwwXGeEREhA7UHjBeb3h3pbp3P1WSjL+zqqq/bTvs3LlbF/ZLM14HTP8Q/eY9AfMNSVddlaE/3pGj0ZnjtHfvF9/r9wF+CCFPIr788kstWrTomElEQUGB7rrrrqAxx0mnyNEuJtTLgQVffVWnTZu2Gicw3nt/o/pdmKaYmGhFRUVq374vtWb1y3q3/IM2XikQ7P4HZuiyy4YqbVim9uz2fa+5TjrpSGH2phtv14YNFUH3GhsbjZ+v/K/fKTLyyF+dXq9HK1Y+q9T+vzLuNzR8bfxcVbVXbneXoLniu8RJUrMKxa9/na5H5s7UtddO0htvvPO9fhd8fz/2NkSotDqJWL58+THvb9u27TvnmD59unJzc4PGOnU+u7VLQYhERUXp7LMTtfqddUHjBw4clCT16JGg5OTzdOeM+9pieUCLHph9lzIyhmvE8Ku1Y8eu7z1fdfU+7d5dqTMSuuvZZ186atznn+82fv766yPJxbZtO1qMXbf+fc2YcasiIyPV0NAgSRoy5CLt2eMLWvNVV2Vo7qOzdP31U7Si5I0W58IP68fehgiVVicRo0aNksPhaLEU943vaks4nU45nc5WvQehM+veP+nv/yjVzs93K75LnP74x5sVE3OKnlr8v5KO/Ito394vtPPz3UpKOluFD9ytl5aXqPS1t9p45cARhXP+R5mZV2h05jgdOnTY+Nd+be0BY1PwXXdNk9fr1rhxU433nXtub0nSKad0UFxcrM49t7fq6+u1deunkqR77pmj+++foYMHDmnlyjfldEbpggvO1c9+FqOHHnq81ev827Mv6Y9/vFnz59+v++57WGf1SFDerZN0b8FfjZirrsrQgsce0K233qUN6983fpe6un8biTwQrhyBY2UDLTj11FP18MMPa9SoUS3er6ioUHJyclD5z4qIqFNbFQ/7li55RBf9MkVxcbHau/cLrVv/nu6ccZ+2bPlEknTTjTdoau4f5HbHqbKyWkuWPqe/3DPH+JcUfjjOiMi2XkJYOtqzGSaMz9OSJc9JkubNu1/dTz9NI0dcfcz37dixS717/dJ4nZmZoZxbJujss3vo8OE6bd78kR5++Am9vHxFs/d2736atmxdrY4dzjjqWs85p6dmF96tfv3O1/79tXrssaUqyH/QuP9qyTJdfHH/Zu9bsvg5TZiQd9R5f+qO9XyOUMg+/cqQzbV4xwshmyvctDqJyMjI0Pnnn6+77767xfv/+te/1LdvXzU1ta4YRBIBNEcSAbTseCcR14YwiVjyI04iWt3OuPXWW3X48OGj3u/Ro4feeIOeHgAAP3atTiIuuuiiY97v2LGjBg0aZHtBAAC0tR/7d16ECo+9BgDAhCOe1vDESgAAYAuVCAAATHhOhDUkEQAAmLAnwhqSCAAATNgTYQ17IgAAgC1UIgAAMGFPhDUkEQAAmLTyYc4/WbQzAACALVQiAAAw4XSGNSQRAACYsCfCGtoZAADAFioRAACY8JwIa0giAAAwYU+ENbQzAACALVQiAAAw4TkR1pBEAABgwukMa0giAAAwYWOlNeyJAAAAtlCJAADAhNMZ1pBEAABgwsZKa2hnAAAAW6hEAABgQjvDGpIIAABMOJ1hDe0MAADCxFtvvaXLL79cXq9XDodDL774YtD9QCCgGTNmyOv1qn379ho8eLA2b94cFOP3+zV58mTFxcWpY8eOysjI0K5du4JiampqlJ2dLZfLJZfLpezsbO3fv7/V6yWJAADApCkQCNnVGocPH9Z5552noqKiFu/PmjVLs2fPVlFRkTZs2CCPx6Nhw4bp4MGDRkxOTo6Ki4u1bNkyrV69WocOHVJ6eroaGxuNmKysLFVUVKikpEQlJSWqqKhQdnZ2q/+cHIEw2YIaEXVqWy8BCDvOiMi2XgIQlg5/9dlxnf+iU4eEbK63d79u630Oh0PFxcUaNWqUpCNVCK/Xq5ycHN12222SjlQd3G63Zs6cqQkTJqi2tlZdunTR4sWLNXr0aEnSnj171K1bN73yyisaPny4tmzZot69e6usrEwpKSmSpLKyMqWmpmrr1q3q2bOn5TVSiQAA4Djy+/06cOBA0OX3+1s9z/bt2+Xz+ZSWlmaMOZ1ODRo0SGvWrJEklZeXq6GhISjG6/UqKSnJiFm7dq1cLpeRQEhS//795XK5jBirSCIAADBpUiBkV0FBgbH34JuroKCg1Wvy+XySJLfbHTTudruNez6fT1FRUerUqdMxY+Lj45vNHx8fb8RYxekMAABMQnnEc/r06crNzQ0aczqdtudzOBxBrwOBQLMxM3NMS/FW5jGjEgEAgEkgEAjZ5XQ6FRMTE3TZSSI8Ho8kNasWVFdXG9UJj8ej+vp61dTUHDOmqqqq2fx79+5tVuX4LiQRAACcABISEuTxeFRaWmqM1dfXa9WqVRowYIAkKTk5WZGRkUExlZWV2rRpkxGTmpqq2tparV+/3ohZt26damtrjRiraGcAAGDSVk+sPHTokD799FPj9fbt21VRUaHY2Fh1795dOTk5ys/PV2JiohITE5Wfn68OHTooKytLkuRyuTR27FhNnTpVnTt3VmxsrPLy8tSnTx8NHTpUktSrVy+NGDFC48aN07x58yRJ48ePV3p6eqtOZkgkEQAANNNWT6x89913dckllxivv9lLMWbMGC1cuFDTpk1TXV2dJk2apJqaGqWkpGjlypWKjo423lNYWKiIiAhlZmaqrq5OQ4YM0cKFC9WuXTsjZunSpZoyZYpxiiMjI+Ooz6Y4Fp4TAYQxnhMBtOx4PyfiQu/FIZtrw563QjZXuKESAQCASZj8+zrskUQAAGDCt3haw+kMAABgC5UIAABMaGdYQxIBAIAJ7QxraGcAAABbqEQAAGDSVs+JONGQRAAAYNLEnghLSCIAADChEmENeyIAAIAtVCIAADChnWENSQQAACa0M6yhnQEAAGyhEgEAgAntDGtIIgAAMKGdYQ3tDAAAYAuVCAAATGhnWEMSAQCACe0Ma2hnAAAAW6hEAABgEgg0tfUSTggkEQAAmDTRzrCEJAIAAJMAGystYU8EAACwhUoEAAAmtDOsIYkAAMCEdoY1tDMAAIAtVCIAADDhiZXWkEQAAGDCEyutoZ0BAABsoRIBAIAJGyutIYkAAMCEI57W0M4AAAC2UIkAAMCEdoY1JBEAAJhwxNMakggAAEyoRFjDnggAAGALlQgAAEw4nWENSQQAACa0M6yhnQEAAGyhEgEAgAmnM6whiQAAwIQv4LKGdgYAALCFSgQAACa0M6whiQAAwITTGdbQzgAAALZQiQAAwISNldaQRAAAYEI7wxqSCAAATEgirGFPBAAAsIVKBAAAJtQhrHEEqNngP/j9fhUUFGj69OlyOp1tvRwgLPDfBdAykggEOXDggFwul2praxUTE9PWywHCAv9dAC1jTwQAALCFJAIAANhCEgEAAGwhiUAQp9OpO++8k81jwH/gvwugZWysBAAAtlCJAAAAtpBEAAAAW0giAACALSQRAADAFpIIGB555BElJCTo5JNPVnJyst5+++22XhLQpt566y1dfvnl8nq9cjgcevHFF9t6SUBYIYmAJOnZZ59VTk6O7rjjDr3//vu66KKLNHLkSO3cubOtlwa0mcOHD+u8885TUVFRWy8FCEsc8YQkKSUlRRdccIHmzp1rjPXq1UujRo1SQUFBG64MCA8Oh0PFxcUaNWpUWy8FCBtUIqD6+nqVl5crLS0taDwtLU1r1qxpo1UBAMIdSQS0b98+NTY2yu12B4273W75fL42WhUAINyRRMDgcDiCXgcCgWZjAAB8gyQCiouLU7t27ZpVHaqrq5tVJwAA+AZJBBQVFaXk5GSVlpYGjZeWlmrAgAFttCoAQLiLaOsFIDzk5uYqOztb/fr1U2pqqubPn6+dO3dq4sSJbb00oM0cOnRIn376qfF6+/btqqioUGxsrLp3796GKwPCA0c8YXjkkUc0a9YsVVZWKikpSYWFhbr44ovbellAm3nzzTd1ySWXNBsfM2aMFi5c+MMvCAgzJBEAAMAW9kQAAABbSCIAAIAtJBEAAMAWkggAAGALSQQAALCFJAIAANhCEgEAAGwhiQAAALaQRAAAAFtIIgAAgC0kEQAAwBaSCAAAYMv/ByAaMuVZWpJtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_epoch = 100\n",
    "BS = 64\n",
    "print(\"Training...\")\n",
    "milli_sec1 = int(round(time.time() * 1000))\n",
    "\n",
    "userModel = \"lstmCnn\"#\"lstm\"\n",
    "\n",
    "if userModel == \"cnn\":\n",
    "    myModel = buildCnn(max_len, num_words, dim, seed, embedding_matrix) \n",
    "elif userModel == \"lstm\":\n",
    "    myModel = buildLstm(max_len, num_words, dim, seed, embedding_matrix)\n",
    "elif userModel == \"lstmCnn\":\n",
    "    myModel = buildLstmCNN(max_len, num_words, dim, seed, embedding_matrix)\n",
    "elif userModel == \"lstmAtt\":\n",
    "    myModel = buildLstmWithBahdanauAttention(max_len, num_words, dim, seed, embedding_matrix)\n",
    "    \n",
    "print(\"model summary\\m\", myModel.summary())\n",
    "csv_logger = CSVLogger('log.csv', append=True, separator=',')\n",
    "es = EarlyStopping(monitor='val_f2_metric', mode='max', verbose=1, patience=10)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_f2_metric', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "history = myModel.fit(lines_pad_x_train, y_train, validation_data=(lines_pad_x_val, y_val), epochs = nb_epoch, batch_size = BS, shuffle=True, verbose=1, callbacks=[csv_logger,es,mc], class_weight=class_weights)\n",
    "\n",
    "#load best model\n",
    "#model = load_model('best_model.h5')\n",
    "myModel.load_weights(\"best_model.h5\")\n",
    "\n",
    "scores = myModel.evaluate(lines_pad_x_val, y_val, verbose=0)\n",
    "#predictions = myModel.predict_classes(X_test, verbose=0)\n",
    "predScores = myModel.predict(lines_pad_x_val)\n",
    "predictions = (predScores > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy=accuracy_score(y_val, predictions)\n",
    "precision=precision_score(y_val, predictions)\n",
    "recall=recall_score(y_val, predictions)\n",
    "f1=f1_score(y_val, predictions)\n",
    "roc_auc=roc_auc_score(y_val, predictions)\n",
    "f2=5*precision*recall / (4*precision+recall)\n",
    "\n",
    "cm = confusion_matrix(y_val, predictions, labels=[0, 1])\n",
    "#print(cm)\n",
    "sns.heatmap(cm, annot=True)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"TP=\",tp)\n",
    "print(\"TN=\",tn)\n",
    "print(\"FP=\",fp)\n",
    "print(\"FN=\",fn)\n",
    "\n",
    "acc = ((tp+tn)/(tp+tn+fp+fn))\n",
    "\n",
    "print(\"Accuracy:%.2f%%\"%(acc*100))\n",
    "print(\"Precision:%.2f%%\"%(precision*100))\n",
    "print(\"Recall:%.2f%%\"%(recall*100))\n",
    "print(\"F1 score:%.2f%%\"%(f1*100))\n",
    "print(\"Roc_Auc score:%.2f%%\"%(roc_auc*100))\n",
    "print(\"F2 score:%.2f%%\"%(f2*100))\n",
    "print(classification_report(y_val, predictions))\n",
    "\n",
    "milli_sec2 = int(round(time.time() * 1000))\n",
    "print(\"Cross Validation is completed after\", milli_sec2-milli_sec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5e815aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 11s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "#load best model\n",
    "myModel = load_model(\"best_model.h5\", custom_objects={\"f2_metric\": f2_metric})\n",
    "\n",
    "#y_val\n",
    "predScores = myModel.predict(lines_pad_x_val)\n",
    "predictions = (predScores > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7411349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives_indices = []\n",
    "\n",
    "for i in range(len(y_val)):\n",
    "    if y_val[i] == 1 and predictions[i][0] == 1:\n",
    "        true_positives_indices.append(i)\n",
    "\n",
    "true_positives = np.array(x_val)[true_positives_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "365ebc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['   virtual size_t getnumactiveinputmethods() {\\n    scoped_ptr<inputmethoddescriptors> descriptors(getactiveinputmethods());\\n     return descriptors->size();\\n   }\\n',\n",
       "       'extensionttscontroller::~extensionttscontroller() {\\n  finishcurrentutterance();\\n  clearutterancequeue();\\n}\\n',\n",
       "       ' void renderwidgethostviewandroid::acceleratedsurfacebuffersswapped(\\n     const gpuhostmsg_acceleratedsurfacebuffersswapped_params& params,\\n     int gpu_host_id) {\\n  texture_layer_->settextureid(params.surface_handle);\\n  dcheck(texture_layer_ == layer_);\\n  layer_->setbounds(params.size);\\n  texture_id_in_layer_ = params.surface_handle;\\n  texture_size_in_layer_ = params.size;\\n   dcheck(!compositorimpl::isthreadingenabled());\\n   uint32 sync_point =\\n       imagetransportfactoryandroid::getinstance()->insertsyncpoint();\\n   renderwidgethostimpl::acknowledgebufferpresent(\\n      params.route_id, gpu_host_id, true, sync_point);\\n }\\n',\n",
       "       'globalhistogramallocator::releasefortesting() {\\n  globalhistogramallocator* histogram_allocator = get();\\n  if (!histogram_allocator)\\n    return nullptr;\\n  persistentmemoryallocator* memory_allocator =\\n      histogram_allocator->memory_allocator();\\n  persistentmemoryallocator::iterator iter(memory_allocator);\\n   const persistenthistogramdata* data;\\n   while ((data = iter.getnextofobject<persistenthistogramdata>()) != nullptr) {\\n     statisticsrecorder::forgethistogramfortesting(data->name);\\n    dcheck_ne(kresulthistogram, data->name);\\n   }\\n   subtle::release_store(&g_histogram_allocator, 0);\\n  return wrapunique(histogram_allocator);\\n};\\n',\n",
       "       'bool printwebviewhelper::getprintsettingsfromuser(webkit::webframe* frame,\\n                                                  const webkit::webnode& node,\\n                                                  int expected_pages_count,\\n                                                  bool use_browser_overlays) {\\n  printhostmsg_scriptedprint_params params;\\n  printmsg_printpages_params print_settings;\\n  params.host_window_id = render_view()->gethostwindow();\\n  params.cookie = print_pages_params_->params.document_cookie;\\n  params.has_selection = frame->hasselection();\\n  params.expected_pages_count = expected_pages_count;\\n  printing::margintype margin_type = printing::default_margins;\\n  if (printingnodeorpdfframe(frame, node))\\n    margin_type = getmarginsforpdf(frame, node);\\n  params.margin_type = margin_type;\\n   send(new printhostmsg_didshowprintdialog(routing_id()));\\n   print_pages_params_.reset();\\n   ipc::syncmessage* msg =\\n       new printhostmsg_scriptedprint(routing_id(), params, &print_settings);\\n   msg->enablemessagepumping();\\n   send(msg);\\n   print_pages_params_.reset(new printmsg_printpages_params(print_settings));\\n   return (print_settings.params.dpi && print_settings.params.document_cookie);\\n }\\n',\n",
       "       ' bool svgelement::hassvgparent() const {\\n  return parentorshadowhostelement() &&\\n         parentorshadowhostelement()->issvgelement();\\n }\\n',\n",
       "       'fakeplatformsensor::fakeplatformsensor(mojom::sensortype type,\\n                                       mojo::scopedsharedbuffermapping mapping,\\n                                       platformsensorprovider* provider)\\n    : platformsensor(type, std::move(mapping), provider) {\\n   on_call(*this, startsensor(_))\\n       .willbydefault(\\n           invoke([this](const platformsensorconfiguration& configuration) {\\n            sensorreading reading;\\n            if (gettype() == mojom::sensortype::ambient_light) {\\n              reading.als.value = configuration.frequency();\\n              updatesharedbufferandnotifyclients(reading);\\n            }\\n            return true;\\n          }));\\n}\\n',\n",
       "       'bool appcachedatabase::findcacheforgroup(int64_t group_id,\\n                                         cacherecord* record) {\\n  dcheck(record);\\n  if (!lazyopen(kdontcreate))\\n     return false;\\n   static const char ksql[] =\\n      \"select cache_id, group_id, online_wildcard, update_time, cache_size\"\\n       \"  from caches where group_id = ?\";\\n   sql::statement statement(db_->getcachedstatement(sql_from_here, ksql));\\n  statement.bindint64(0, group_id);\\n  if (!statement.step())\\n    return false;\\n  readcacherecord(statement, record);\\n  return true;\\n}\\n',\n",
       "       'void speechsynthesis::handlespeakingcompleted(speechsynthesisutterance* utterance, bool erroroccurred)\\n {\\n     assert(utterance);\\n     bool didjustfinishcurrentutterance = false;\\n    if (utterance == currentspeechutterance()) {\\n        m_utterancequeue.removefirst();\\n        didjustfinishcurrentutterance = true;\\n    }\\n    fireevent(erroroccurred ? eventtypenames::error : eventtypenames::end, utterance, 0, string());\\n    if (didjustfinishcurrentutterance && !m_utterancequeue.isempty())\\n        startspeakingimmediately();\\n}\\n',\n",
       "       '  accesstype getextensionaccess(const extension* extension,\\n                                const gurl& url,\\n                                 int tab_id) {\\n     bool allowed_script = isallowedscript(extension, url, tab_id);\\n     bool allowed_capture = extension->permissions_data()->cancapturevisiblepage(\\n        url, tab_id, nullptr);\\n     if (allowed_script && allowed_capture)\\n       return allowed_script_and_capture;\\n    if (allowed_script)\\n      return allowed_script_only;\\n    if (allowed_capture)\\n      return allowed_capture_only;\\n    return disallowed;\\n  }\\n',\n",
       "       ' glboolean webglrenderingcontextbase::isshader(webglshader* shader) {\\n  if (!shader || iscontextlost())\\n     return 0;\\n   return contextgl()->isshader(shader->object());\\n }\\n',\n",
       "       ' void inputmethodtsf::oncaretboundschanged(const textinputclient* client) {\\n   if (istextinputclientfocused(client) && iswindowfocused(client))\\n     ui::tsfbridge::getinstance()->ontextlayoutchanged();\\n }\\n',\n",
       "       'peppermediadevicemanager* pepperplatformaudioinput::getmediadevicemanager() {\\n  dcheck(main_message_loop_proxy_->belongstocurrentthread());\\n   renderframeimpl* const render_frame =\\n       renderframeimpl::fromroutingid(render_frame_id_);\\n   return render_frame ?\\n      peppermediadevicemanager::getforrenderframe(render_frame) : null;\\n }\\n',\n",
       "       ' void imagebitmapfactories::imagebitmaploader::rejectpromise(\\n    imagebitmaprejectionreason reason) {\\n  switch (reason) {\\n    case kundecodableimagebitmaprejectionreason:\\n      resolver_->reject(\\n          domexception::create(domexceptioncode::kinvalidstateerror,\\n                               \"the source image could not be decoded.\"));\\n      break;\\n    case kallocationfailureimagebitmaprejectionreason:\\n      resolver_->reject(\\n          domexception::create(domexceptioncode::kinvalidstateerror,\\n                               \"the imagebitmap could not be allocated.\"));\\n      break;\\n     default:\\n       notreached();\\n   }\\n   factory_->didfinishloading(this);\\n }\\n',\n",
       "       'void historycontroller::updateforcommit(renderframeimpl* frame,\\n                                        const webhistoryitem& item,\\n                                        webhistorycommittype commit_type,\\n                                        bool navigation_within_page) {\\n  switch (commit_type) {\\n     case blink::webbackforwardcommit:\\n       if (!provisional_entry_)\\n         return;\\n      current_entry_.reset(provisional_entry_.release());\\n       if (historyentry::historynode* node =\\n               current_entry_->gethistorynodeforframe(frame)) {\\n         node->set_item(item);\\n      }\\n      break;\\n    case blink::webstandardcommit:\\n      createnewbackforwarditem(frame, item, navigation_within_page);\\n      break;\\n    case blink::webinitialcommitinchildframe:\\n      updateforinitialloadinchildframe(frame, item);\\n      break;\\n    case blink::webhistoryinertcommit:\\n      if (current_entry_) {\\n        if (historyentry::historynode* node =\\n                current_entry_->gethistorynodeforframe(frame)) {\\n          if (!navigation_within_page)\\n            node->removechildren();\\n          node->set_item(item);\\n        }\\n      }\\n      break;\\n    default:\\n      notreached() << \"invalid commit type: \" << commit_type;\\n  }\\n}\\n',\n",
       "       'void interstitialpage::observe(notificationtype type,\\n                               const notificationsource& source,\\n                               const notificationdetails& details) {\\n  switch (type.value) {\\n    case notificationtype::nav_entry_pending:\\n       disable();\\n      dcheck(!resource_dispatcher_host_notified_);\\n       takeactiononresourcedispatcher(cancel);\\n       break;\\n     case notificationtype::render_widget_host_destroyed:\\n      if (action_taken_ == no_action) {\\n        renderviewhost* rvh = source<renderviewhost>(source).ptr();\\n        dcheck(rvh->process()->id() == original_child_id_ &&\\n               rvh->routing_id() == original_rvh_id_);\\n        takeactiononresourcedispatcher(cancel);\\n      }\\n      break;\\n    case notificationtype::tab_contents_destroyed:\\n    case notificationtype::nav_entry_committed:\\n      if (action_taken_ == no_action) {\\n        dontproceed();\\n      } else {\\n        hide();\\n      }\\n      break;\\n    default:\\n      notreached();\\n  }\\n}\\n',\n",
       "       'static v8::handle<v8::value> convert2callback(const v8::arguments& args)\\n {\\n     inc_stats(\"dom.testobj.convert2\");\\n     if (args.length() < 1)\\n        return v8proxy::thrownotenoughargumentserror();\\n     testobj* imp = v8testobj::tonative(args.holder());\\n     exception_block(b*, , v8b::hasinstance(maybe_missing_parameter(args, 0, defaultisundefined)) ? v8b::tonative(v8::handle<v8::object>::cast(maybe_missing_parameter(args, 0, defaultisundefined))) : 0);\\n     imp->convert2();\\n    return v8::handle<v8::value>();\\n}\\n',\n",
       "       '  void setstate(mediastreamtype stream_type, mediarequeststate new_state) {\\n    if (stream_type == num_media_types) {\\n      for (int i = media_no_service + 1; i < num_media_types; ++i) {\\n        state_[static_cast<mediastreamtype>(i)] = new_state;\\n      }\\n    } else {\\n      state_[stream_type] = new_state;\\n    }\\n    mediaobserver* media_observer =\\n        getcontentclient()->browser()->getmediaobserver();\\n     if (!media_observer)\\n       return;\\n    media_observer->onmediarequeststatechanged(\\n        target_process_id_, target_frame_id_, page_request_id,\\n        security_origin.geturl(), stream_type, new_state);\\n   }\\n',\n",
       "       'void profilingservice::dumpprocessesfortracing(\\n     bool keep_small_allocations,\\n     bool strip_path_from_mapped_files,\\n     dumpprocessesfortracingcallback callback) {\\n  memory_instrumentation::memoryinstrumentation::getinstance()\\n      ->getvmregionsforheapprofiler(base::bind(\\n          &profilingservice::ongetvmregionscompletefordumpprocessesfortracing,\\n          weak_factory_.getweakptr(), keep_small_allocations,\\n          strip_path_from_mapped_files, base::passed(&callback)));\\n }\\n',\n",
       "       'void mediastreamdispatcherhost::bindrequest(\\n     mojom::mediastreamdispatcherhostrequest request) {\\n   dcheck_currently_on(browserthread::io);\\n  bindings_.addbinding(this, std::move(request));\\n }\\n',\n",
       "       ' void wtssessionprocessdelegate::core::onjobnotification(dword message,\\n                                                      dword pid) {\\n   dcheck(main_task_runner_->belongstocurrentthread());\\n   switch (message) {\\n    case job_object_msg_active_process_zero:\\n      check(setevent(process_exit_event_));\\n      break;\\n    case job_object_msg_new_process:\\n      worker_process_.set(openprocess(process_query_information, false, pid));\\n      break;\\n  }\\n}\\n',\n",
       "       '    shared_memory_handle(const gfx::gpumemorybufferhandle& handle) {\\n  if (handle.type != gfx::shared_memory_buffer &&\\n       handle.type != gfx::dxgi_shared_handle &&\\n       handle.type != gfx::android_hardware_buffer)\\n     return mojo::scopedsharedbufferhandle();\\n  return mojo::wrapsharedmemoryhandle(handle.handle, handle.handle.getsize(),\\n                                      false);\\n }\\n',\n",
       "       ' glboolean webglrenderingcontextbase::isframebuffer(\\n     webglframebuffer* framebuffer) {\\n  if (!framebuffer || iscontextlost())\\n     return 0;\\n   if (!framebuffer->haseverbeenbound())\\n    return 0;\\n  if (framebuffer->isdeleted())\\n    return 0;\\n  return contextgl()->isframebuffer(framebuffer->object());\\n }\\n',\n",
       "       'p2pquicstreamimpl* p2pquictransportimpl::createstreaminternal(\\n    quic::quicstreamid id) {\\n  dcheck_called_on_valid_thread(thread_checker_);\\n   dcheck(crypto_stream_);\\n   dcheck(isencryptionestablished());\\n   dcheck(!isclosed());\\n  return new p2pquicstreamimpl(id, this);\\n }\\n',\n",
       "       'void webpluginproxy::onresourcecreated(int resource_id, handle cookie) {\\n  webpluginresourceclient* resource_client =\\n      reinterpret_cast<webpluginresourceclient*>(cookie);\\n  if (!resource_client) {\\n    notreached();\\n    return;\\n  }\\n   dcheck(resource_clients_.find(resource_id) == resource_clients_.end());\\n  resource_clients_[resource_id] = resource_client;\\n }\\n',\n",
       "       'pp::var error(nacl::string call_name, const char* caller,\\n               const char* error, pp::var* exception) {\\n   nacl::stringstream error_stream;\\n   error_stream << call_name << \": \" << error;\\n  if (!exception->is_undefined()) {\\n    error_stream << \" - \" + exception->asstring();\\n  }\\n  std::string str = error_stream.str();\\n  const char* e = str.c_str();\\n  plugin_printf((\"scriptablehandle::%s (%s)\\\\n\", caller, e));\\n  *exception = pp::var(e);\\n  return pp::var();\\n}\\n',\n",
       "       'plugin::plugin(pp_instance pp_instance)\\n    : pp::instanceprivate(pp_instance),\\n      scriptable_plugin_(null),\\n      argc_(-1),\\n      argn_(null),\\n      argv_(null),\\n      main_subprocess_(\"main subprocess\", null, null),\\n      nacl_ready_state_(unsent),\\n      nexe_error_reported_(false),\\n      wrapper_factory_(null),\\n      last_error_string_(\"\"),\\n      ppapi_proxy_(null),\\n      enable_dev_interfaces_(false),\\n       init_time_(0),\\n       ready_time_(0),\\n       nexe_size_(0),\\n      time_of_last_progress_event_(0),\\n      using_ipc_proxy_(false) {\\n   plugin_printf((\"plugin::plugin (this=%p, pp_instance=%\"\\n                  nacl_prid32\")\\\\n\", static_cast<void*>(this), pp_instance));\\n   callback_factory_.initialize(this);\\n  nexe_downloader_.initialize(this);\\n}\\n',\n",
       "       ' void bluetoothdevicechromeos::setpasskey(uint32 passkey) {\\n  if (!agent_.get() || passkey_callback_.is_null())\\n     return;\\n  passkey_callback_.run(success, passkey);\\n  passkey_callback_.reset();\\n }\\n',\n",
       "       'gdatafile::gdatafile(gdatadirectory* parent,\\n                     gdatadirectoryservice* directory_service)\\n    : gdataentry(parent, directory_service),\\n       kind_(documententry::unknown),\\n       is_hosted_document_(false) {\\n   file_info_.is_directory = false;\\n}\\n',\n",
       "       '   compositedlayerrasterinvalidatortest& properties(\\n      const refcountedpropertytreestate& state) {\\n    data_.chunks.back().properties = state;\\n     return *this;\\n   }\\n',\n",
       "       '   virtual ~inputmethodlibraryimpl() {\\n   }\\n',\n",
       "       '  void canonlydiscardoncetest(discardreason reason) {\\n    lifecycleunit* background_lifecycle_unit = nullptr;\\n    lifecycleunit* foreground_lifecycle_unit = nullptr;\\n    createtwotabs(true /* focus_tab_strip */, &background_lifecycle_unit,\\n                  &foreground_lifecycle_unit);\\n    content::webcontents* initial_web_contents =\\n        tab_strip_model_->getwebcontentsat(0);\\n    expectcandiscardtrueallreasons(background_lifecycle_unit);\\n     expect_eq(lifecycleunitstate::active,\\n               background_lifecycle_unit->getstate());\\n    expect_call(tab_observer_, ondiscardedstatechange(testing::_, true));\\n     background_lifecycle_unit->discard(reason);\\n    testing::mock::verifyandclear(&tab_observer_);\\n     transitionfrompendingdiscardtodiscardedifneeded(reason,\\n                                                     background_lifecycle_unit);\\n    expect_ne(initial_web_contents, tab_strip_model_->getwebcontentsat(0));\\n    expect_false(tab_strip_model_->getwebcontentsat(0)\\n                     ->getcontroller()\\n                      .getpendingentry());\\n    expect_call(tab_observer_, ondiscardedstatechange(testing::_, false));\\n     tab_strip_model_->getwebcontentsat(0)->getcontroller().reload(\\n         content::reloadtype::normal, false);\\n    testing::mock::verifyandclear(&tab_observer_);\\n     expect_eq(lifecycleunitstate::active,\\n               background_lifecycle_unit->getstate());\\n     expect_true(tab_strip_model_->getwebcontentsat(0)\\n                    ->getcontroller()\\n                    .getpendingentry());\\n    expectcandiscardfalsetrivial(background_lifecycle_unit,\\n                                 discardreason::kexternal);\\n    expectcandiscardfalsetrivial(background_lifecycle_unit,\\n                                 discardreason::kproactive);\\n#if defined(os_chromeos)\\n    expectcandiscardtrue(background_lifecycle_unit, discardreason::kurgent);\\n#else\\n    expectcandiscardfalsetrivial(background_lifecycle_unit,\\n                                 discardreason::kurgent);\\n#endif\\n   }\\n',\n",
       "       'void tabspecificcontentsettings::oncontentblocked(\\n    contentsettingstype type,\\n     const std::string& resource_identifier) {\\n   dcheck(type != content_settings_type_geolocation)\\n       << \"geolocation settings handled by ongeolocationpermissionset\";\\n   content_accessed_[type] = true;\\n  std::string identifier;\\n  if (commandline::forcurrentprocess()->hasswitch(\\n      switches::kenableresourcecontentsettings)) {\\n    identifier = resource_identifier;\\n  }\\n  if (!identifier.empty())\\n    addblockedresource(type, identifier);\\n#if defined (os_android)\\n  if (type == content_settings_type_popups) {\\n    content_blocked_[type] = false;\\n    content_blockage_indicated_to_user_[type] = false;\\n  }\\n#endif\\n  if (!content_blocked_[type]) {\\n    content_blocked_[type] = true;\\n    content::notificationservice::current()->notify(\\n        chrome::notification_web_content_settings_changed,\\n        content::source<webcontents>(web_contents()),\\n        content::notificationservice::nodetails());\\n  }\\n}\\n',\n",
       "       ' int printpreviewui::getavailabledraftpagecount() {\\n  return print_preview_data_service()->getavailabledraftpagecount(\\n      preview_ui_addr_str_);\\n }\\n',\n",
       "       'void pageinfo::presentsiteidentity() {\\n  dcheck_ne(site_identity_status_, site_identity_status_unknown);\\n  dcheck_ne(site_connection_status_, site_connection_status_unknown);\\n  pageinfoui::identityinfo info;\\n  if (site_identity_status_ == site_identity_status_ev_cert)\\n    info.site_identity = utf16toutf8(organization_name());\\n  else\\n    info.site_identity = utf16toutf8(getsimplesitename(site_url_));\\n   info.connection_status = site_connection_status_;\\n   info.connection_status_description = utf16toutf8(site_connection_details_);\\n   info.identity_status = site_identity_status_;\\n  info.safe_browsing_status = safe_browsing_status_;\\n  info.identity_status_description = utf16toutf8(site_details_message_);\\n   info.certificate = certificate_;\\n   info.show_ssl_decision_revoke_button = show_ssl_decision_revoke_button_;\\n   info.show_change_password_buttons = show_change_password_buttons_;\\n  ui_->setidentityinfo(info);\\n}\\n',\n",
       "       'void cclayertreehosttest::endtest()\\n {\\n     if (!ismainthread())\\n        ccmainthread::posttask(createmainthreadtask(this, &cclayertreehosttest::endtest));\\n     else {\\n        if (m_beginning)\\n            m_endwhenbeginreturns = true;\\n        else\\n            onendtest(static_cast<void*>(this));\\n    }\\n}\\n',\n",
       "       '     vp9picturetovaapidecodesurface(const scoped_refptr<vp9picture>& pic) {\\n   vaapivp9picture* vaapi_pic = pic->asvaapivp9picture();\\n   check(vaapi_pic);\\n   return vaapi_pic->dec_surface();\\n}\\n',\n",
       "       'void printpreviewmessagehandler::ondidpreviewpage(\\n    const printhostmsg_didpreviewpage_params& params) {\\n  int page_number = params.page_number;\\n  if (page_number < first_page_index || !params.data_size)\\n    return;\\n  printpreviewui* print_preview_ui = getprintpreviewui();\\n   if (!print_preview_ui)\\n     return;\\n  scoped_refptr<base::refcountedbytes> data_bytes =\\n      getdatafromhandle(params.metafile_data_handle, params.data_size);\\n  dcheck(data_bytes);\\n  print_preview_ui->setprintpreviewdataforindex(page_number,\\n                                                std::move(data_bytes));\\n  print_preview_ui->ondidpreviewpage(page_number, params.preview_request_id);\\n }\\n',\n",
       "       'encodedjsvalue jsc_host_call jsdeprecatedpeerconnectionconstructor::constructjsdeprecatedpeerconnection(execstate* exec)\\n{\\n    jsdeprecatedpeerconnectionconstructor* jsconstructor = static_cast<jsdeprecatedpeerconnectionconstructor*>(exec->callee());\\n    scriptexecutioncontext* context = jsconstructor->scriptexecutioncontext();\\n    if (!context)\\n         return throwvmerror(exec, createreferenceerror(exec, \"deprecatedpeerconnection constructor associated document is unavailable\"));\\n     if (exec->argumentcount() < 2)\\n        return throwvmerror(exec, createtypeerror(exec, \"not enough arguments\"));\\n     string serverconfiguration = ustringtostring(exec->argument(0).tostring(exec)->value(exec));\\n     if (exec->hadexception())\\n        return jsvalue::encode(jsvalue());\\n    refptr<signalingcallback> signalingcallback = createfunctiononlycallback<jssignalingcallback>(exec, static_cast<jsdomglobalobject*>(exec->lexicalglobalobject()), exec->argument(1));\\n    if (exec->hadexception())\\n        return jsvalue::encode(jsvalue());\\n    refptr<deprecatedpeerconnection> peerconnection = deprecatedpeerconnection::create(context, serverconfiguration, signalingcallback.release());\\n    return jsvalue::encode(create_dom_wrapper(exec, jsconstructor->globalobject(), deprecatedpeerconnection, peerconnection.get()));\\n}\\n',\n",
       "       ' void paymentrequest::noupdatedpaymentdetails() {\\n   spec_->recomputespecfordetails();\\n }\\n',\n",
       "       'void registeroptimizationhintscomponent(componentupdateservice* cus,\\n                                        prefservice* profile_prefs) {\\n  if (!previews::params::isoptimizationhintsenabled()) {\\n     return;\\n   }\\n  bool data_saver_enabled =\\n      base::commandline::forcurrentprocess()->hasswitch(\\n          data_reduction_proxy::switches::kenabledatareductionproxy) ||\\n      (profile_prefs && profile_prefs->getboolean(\\n                            data_reduction_proxy::prefs::kdatasaverenabled));\\n  if (!data_saver_enabled)\\n     return;\\n   auto installer = base::makerefcounted<componentinstaller>(\\n       std::make_unique<optimizationhintscomponentinstallerpolicy>());\\n   installer->register(cus, base::onceclosure());\\n}\\n',\n",
       "       'void pulseaudiomixer::setmute(bool mute) {\\n   if (!mainlooplockifready())\\n     return;\\n   pa_operation* pa_op;\\n   pa_op = pa_context_set_sink_mute_by_index(pa_context_, device_id_,\\n                                             mute ? 1 : 0, null, null);\\n   pa_operation_unref(pa_op);\\n   mainloopunlock();\\n }\\n',\n",
       "       'backendimpl::backendimpl(\\n    const base::filepath& path,\\n    uint32_t mask,\\n    const scoped_refptr<base::singlethreadtaskrunner>& cache_thread,\\n    net::netlog* net_log)\\n    : background_queue_(this, fallbacktointernalifnull(cache_thread)),\\n      path_(path),\\n      block_files_(path),\\n      mask_(mask),\\n      max_size_(0),\\n      up_ticks_(0),\\n      cache_type_(net::disk_cache),\\n      uma_report_(0),\\n      user_flags_(kmask),\\n      init_(false),\\n      restarted_(false),\\n      unit_test_(false),\\n      read_only_(false),\\n      disabled_(false),\\n       new_eviction_(false),\\n       first_timer_(true),\\n       user_load_(false),\\n       net_log_(net_log),\\n       done_(base::waitableevent::resetpolicy::manual,\\n             base::waitableevent::initialstate::not_signaled),\\n      ptr_factory_(this) {}\\n',\n",
       "       ' void webgl2renderingcontextbase::bindsampler(gluint unit,\\n                                              webglsampler* sampler) {\\n  if (iscontextlost())\\n    return;\\n   bool deleted;\\n   if (!checkobjecttobebound(\"bindsampler\", sampler, deleted))\\n     return;\\n  if (deleted) {\\n    synthesizeglerror(gl_invalid_operation, \"bindsampler\",\\n                      \"attempted to bind a deleted sampler\");\\n    return;\\n  }\\n  if (unit >= sampler_units_.size()) {\\n    synthesizeglerror(gl_invalid_value, \"bindsampler\",\\n                      \"texture unit out of range\");\\n    return;\\n  }\\n  sampler_units_[unit] = sampler;\\n  contextgl()->bindsampler(unit, objectorzero(sampler));\\n}\\n',\n",
       "       ' bool win32stackframeunwinder::tryunwind(context* context) {\\n #ifdef _win64\\n   check(!at_top_frame_ || unwind_info_present_for_all_frames_);\\n  check(!pending_blacklisted_module_);\\n   ulong64 image_base;\\n  pruntime_function runtime_function =\\n      unwind_functions_->lookupfunctionentry(context->rip, &image_base);\\n  if (runtime_function) {\\n    unwind_functions_->virtualunwind(image_base, context->rip, runtime_function,\\n                                     context);\\n    at_top_frame_ = false;\\n  } else {\\n    if (at_top_frame_) {\\n      at_top_frame_ = false;\\n      if (leafunwindblacklist::getinstance()->isblacklisted(\\n              reinterpret_cast<const void*>(image_base))) {\\n        return false;\\n      }\\n      context->rip = context->rsp;\\n      context->rsp += 8;\\n      unwind_info_present_for_all_frames_ = false;\\n    } else {\\n       if (unwind_info_present_for_all_frames_) {\\n        pending_blacklisted_module_ =\\n            reinterpret_cast<const void *>(image_base);\\n       } else {\\n      }\\n      return false;\\n    }\\n  }\\n  return true;\\n#else\\n  notreached();\\n  return false;\\n#endif\\n }\\n',\n",
       "       'systemlibrary* croslibrary::getsystemlibrary() {\\n  return system_lib_.getdefaultimpl(use_stub_impl_);\\n}\\n',\n",
       "       ' devtoolssession::devtoolssession(devtoolsagenthostimpl* agent_host,\\n                                 devtoolsagenthostclient* client)\\n     : binding_(this),\\n       agent_host_(agent_host),\\n       client_(client),\\n       process_host_id_(childprocesshost::kinvaliduniqueid),\\n       host_(nullptr),\\n       dispatcher_(new protocol::uberdispatcher(this)),\\n      weak_factory_(this) {\\n  dispatcher_->setfallthroughfornotfound(true);\\n}\\n',\n",
       "       '  testcompletioncallback()\\n      : callback_(base::bind(&testcompletioncallback::setresult,\\n                             base::unretained(this))) {}\\n',\n",
       "       'void mimehandlerviewcontainer::onready() {\\n  if (!render_frame() || !is_embedded_)\\n    return;\\n  blink::weblocalframe* frame = render_frame()->getwebframe();\\n  blink::webassociatedurlloaderoptions options;\\n  dcheck(!loader_);\\n  loader_.reset(frame->createassociatedurlloader(options));\\n   blink::weburlrequest request(original_url_);\\n   request.setrequestcontext(blink::weburlrequest::krequestcontextobject);\\n   loader_->loadasynchronously(request, this);\\n }\\n',\n",
       "       'bool sharedmemory::create(const sharedmemorycreateoptions& options) {\\n  dcheck(!options.executable);\\n  dcheck(!mapped_file_);\\n  if (options.size == 0)\\n    return false;\\n   uint32 rounded_size = (options.size + 0xffff) & ~0xffff;\\n   name_ = asciitowide(options.name == null ? \"\" : *options.name);\\n   mapped_file_ = createfilemapping(invalid_handle_value, null,\\n       page_readwrite, 0, static_cast<dword>(rounded_size),\\n      name_.empty() ? null : name_.c_str());\\n  if (!mapped_file_)\\n    return false;\\n  created_size_ = options.size;\\n  if (getlasterror() == error_already_exists) {\\n    created_size_ = 0;\\n    if (!options.open_existing) {\\n      close();\\n      return false;\\n    }\\n  }\\n  return true;\\n}\\n',\n",
       "       'void biquaddspkernel::process(const float* source, float* destination, size_t framestoprocess)\\n{\\n    assert(source && destination && biquadprocessor());\\n    updatecoefficientsifnecessary(true, false);\\n     m_biquad.process(source, destination, framestoprocess);\\n }\\n',\n",
       "       '  void storeexistinggroup() {\\n    pushnexttask(\\n        base::bindonce(&appcachestorageimpltest::verify_storeexistinggroup,\\n                       base::unretained(this)));\\n     makecacheandgroup(kmanifesturl, 1, 1, true);\\n    expect_eq(kdefaultentrysize, storage()->usage_map_[korigin]);\\n     cache2_ = new appcache(storage(), 2);\\n    cache2_->addentry(kentryurl, appcacheentry(appcacheentry::master, 1,\\n                                               kdefaultentrysize + 100));\\n     storage()->storegroupandnewestcache(group_.get(), cache2_.get(),\\n                                        delegate());\\n    expect_false(delegate()->stored_group_success_);\\n  }\\n',\n",
       "       '   void processstatechangesplanb(webrtcsetdescriptionobserver::states states) {\\n     dcheck_eq(sdp_semantics_, webrtc::sdpsemantics::kplanb);\\n     std::vector<rtcrtpreceiver*> removed_receivers;\\n    for (auto it = handler_->rtp_receivers_.begin();\\n         it != handler_->rtp_receivers_.end(); ++it) {\\n      if (receiverwasremoved(*(*it), states.transceiver_states))\\n        removed_receivers.push_back(it->get());\\n    }\\n     for (auto& transceiver_state : states.transceiver_states) {\\n      if (receiverwasadded(transceiver_state)) {\\n         handler_->onaddreceiverplanb(transceiver_state.movereceiverstate());\\n       }\\n     }\\n     for (auto* removed_receiver : removed_receivers) {\\n      handler_->onremovereceiverplanb(rtcrtpreceiver::getid(\\n          removed_receiver->state().webrtc_receiver().get()));\\n     }\\n   }\\n',\n",
       "       ' static void reflectstringattributeattributegetter(const v8::functioncallbackinfo<v8::value>& info)\\n {\\n     v8::local<v8::object> holder = info.holder();\\n    element* impl = v8element::toimpl(holder);\\n     v8setreturnvaluestring(info, impl->fastgetattribute(htmlnames::reflectstringattributeattr), info.getisolate());\\n }\\n',\n",
       "       'void profilechooserview::removeaccount() {\\n  dcheck(!account_id_to_remove_.empty());\\n   profileoauth2tokenservice* oauth2_token_service =\\n       profileoauth2tokenservicefactory::getforprofile(browser_->profile());\\n   if (oauth2_token_service) {\\n    oauth2_token_service->revokecredentials(account_id_to_remove_);\\n     postactionperformed(profilemetrics::profile_desktop_menu_remove_acct);\\n   }\\n   account_id_to_remove_.clear();\\n  showviewfrommode(profiles::bubble_view_mode_account_management);\\n}\\n',\n",
       "       ' datareductionproxysettings::datareductionproxysettings()\\n     : unreachable_(false),\\n       deferred_initialization_(false),\\n       prefs_(nullptr),\\n       config_(nullptr),\\n       clock_(base::defaultclock::getinstance()) {}\\n',\n",
       "       'bool heapallocator::backingexpand(void* address, size_t newsize) {\\n  if (!address)\\n    return false;\\n  threadstate* state = threadstate::current();\\n  if (state->sweepforbidden())\\n    return false;\\n  assert(!state->isingc());\\n  assert(state->isallocationallowed());\\n  dcheck_eq(&state->heap(), &threadstate::fromobject(address)->heap());\\n  basepage* page = pagefromobject(address);\\n  if (page->islargeobjectpage() || page->arena()->getthreadstate() != state)\\n     return false;\\n   heapobjectheader* header = heapobjectheader::frompayload(address);\\n  assert(header->checkheader());\\n   normalpagearena* arena = static_cast<normalpage*>(page)->arenafornormalpage();\\n   bool succeed = arena->expandobject(header, newsize);\\n   if (succeed)\\n    state->allocationpointadjusted(arena->arenaindex());\\n  return succeed;\\n}\\n',\n",
       "       '  releaseaccelerator(ui::keyboardcode keycode,\\n                     bool shift_pressed,\\n                     bool ctrl_pressed,\\n                     bool alt_pressed)\\n      : ui::accelerator(keycode, shift_pressed, ctrl_pressed, alt_pressed) {\\n     set_type(ui::et_key_released);\\n   }\\n',\n",
       "       ' void quicstreamhost::finish() {\\n   dcheck_called_on_valid_thread(thread_checker_);\\n   dcheck(p2p_stream_);\\n  p2p_stream_->finish();\\n   writeable_ = false;\\n   if (!readable_ && !writeable_) {\\n     delete();\\n  }\\n}\\n',\n",
       "       '  void processrequest() {\\n    dcheck_currently_on(browserthread::ui);\\n    timer.stop();  // erase reference to self.\\n    wallpapermanager* manager = wallpapermanager::get();\\n    if (manager->pending_inactive_ == this)\\n      manager->pending_inactive_ = null;\\n     started_load_at_ = base::time::now();\\n     if (default_) {\\n      manager->dosetdefaultwallpaper(account_id_, std::move(on_finish_));\\n     } else if (!user_wallpaper_.isnull()) {\\n       setwallpaper(user_wallpaper_, info_);\\n     } else if (!wallpaper_path_.empty()) {\\n      manager->task_runner_->posttask(\\n          from_here,\\n          base::bindonce(&wallpapermanager::getcustomwallpaperinternal,\\n                         account_id_, info_, wallpaper_path_,\\n                         true /* update wallpaper */,\\n                         base::threadtaskrunnerhandle::get(),\\n                          base::passed(std::move(on_finish_)),\\n                          manager->weak_factory_.getweakptr()));\\n     } else if (!info_.location.empty()) {\\n      manager->loadwallpaper(account_id_, info_, true, std::move(on_finish_));\\n     } else {\\n       notreached();\\n      started_load_at_ = base::time();\\n    }\\n    on_finish_.reset();\\n  }\\n',\n",
       "       '  void setupconnectedstreams() {\\n    callbackrunloop run_loop(runner());\\n    assert_true(client_peer_->quic_transport()->isencryptionestablished());\\n    assert_true(server_peer_->quic_transport()->isencryptionestablished());\\n    client_peer_->createstreamwithdelegate();\\n    assert_true(client_peer_->stream());\\n    assert_true(client_peer_->stream_delegate());\\n    base::repeatingcallback<void()> callback = run_loop.createcallback();\\n    quicpeerfortest* server_peer_ptr = server_peer_.get();\\n    mockp2pquicstreamdelegate* stream_delegate =\\n        new mockp2pquicstreamdelegate();\\n    p2pquicstream* server_stream;\\n    expect_call(*server_peer_->quic_transport_delegate(), onstream(_))\\n        .willonce(invoke([&callback, &server_stream,\\n                          &stream_delegate](p2pquicstream* stream) {\\n          stream->setdelegate(stream_delegate);\\n          server_stream = stream;\\n           callback.run();\\n         }));\\n    client_peer_->stream()->writeorbufferdata(ktriggerremotestreamphrase,\\n                                              /*fin=*/false, nullptr);\\n     run_loop.rununtilcallbacksfired();\\n    server_peer_ptr->setstreamanddelegate(\\n        static_cast<p2pquicstreamimpl*>(server_stream),\\n        std::unique_ptr<mockp2pquicstreamdelegate>(stream_delegate));\\n    assert_true(client_peer_->stream());\\n    assert_true(client_peer_->stream_delegate());\\n  }\\n',\n",
       "       ' void printwebviewhelper::onprintpreview(const base::dictionaryvalue& settings) {\\n   print_preview_context_.onprintpreview();\\n   uma_histogram_enumeration(\"printpreview.previewevent\",\\n                            preview_event_requested, preview_event_max);\\n  if (!print_preview_context_.source_frame()) {\\n    didfinishprinting(fail_preview);\\n    return;\\n  }\\n  if (!updateprintsettings(print_preview_context_.source_frame(),\\n                           print_preview_context_.source_node(), settings)) {\\n    if (print_preview_context_.last_error() != preview_error_bad_setting) {\\n      send(new printhostmsg_printpreviewinvalidprintersettings(\\n          routing_id(), print_pages_params_\\n                            ? print_pages_params_->params.document_cookie\\n                            : 0));\\n      notify_browser_of_print_failure_ = false;  // already sent.\\n    }\\n    didfinishprinting(fail_preview);\\n    return;\\n  }\\n  if (print_pages_params_->params.is_first_request &&\\n      !print_preview_context_.ismodifiable()) {\\n    printhostmsg_setoptionsfromdocument_params options;\\n    if (setoptionsfrompdfdocument(&options))\\n      send(new printhostmsg_setoptionsfromdocument(routing_id(), options));\\n  }\\n  is_print_ready_metafile_sent_ = false;\\n  print_pages_params_->params.supports_alpha_blend = true;\\n  bool generate_draft_pages = false;\\n  if (!settings.getboolean(ksettinggeneratedraftdata, &generate_draft_pages)) {\\n    notreached();\\n  }\\n  print_preview_context_.set_generate_draft_pages(generate_draft_pages);\\n  prepareframeforpreviewdocument();\\n}\\n',\n",
       "       'void removeactioncallback(const actioncallback& callback) {\\n  dcheck(g_task_runner.get());\\n   dcheck(g_task_runner.get()->belongstocurrentthread());\\n   std::vector<actioncallback>* callbacks = g_callbacks.pointer();\\n   for (size_t i = 0; i < callbacks->size(); ++i) {\\n    if ((*callbacks)[i].equals(callback)) {\\n       callbacks->erase(callbacks->begin() + i);\\n       return;\\n     }\\n  }\\n}\\n',\n",
       "       '  virtual void treenodesadded(treemodel* model, treemodelnode* parent,\\n                              int start, int count) {\\n     added_count_++;\\n   }\\n',\n",
       "       ' void sendtabtoselfinfobardelegate::opentab() {\\n  notimplemented();\\n }\\n',\n",
       "       'cssstylesheet* cssstylesheet::createinline(node& owner_node,\\n                                           const kurl& base_url,\\n                                           const textposition& start_position,\\n                                            const wtf::textencoding& encoding) {\\n   cssparsercontext* parser_context = cssparsercontext::create(\\n       owner_node.getdocument(), owner_node.getdocument().baseurl(),\\n       owner_node.getdocument().getreferrerpolicy(), encoding);\\n   stylesheetcontents* sheet =\\n       stylesheetcontents::create(base_url.getstring(), parser_context);\\n  return new cssstylesheet(sheet, owner_node, true, start_position);\\n}\\n',\n",
       "       'void bluetoothdevicechromeos::release() {\\n  dcheck(agent_.get());\\n  dcheck(pairing_delegate_);\\n  vlog(1) << object_path_.value() << \": release\";\\n  pincode_callback_.reset();\\n  passkey_callback_.reset();\\n  confirmation_callback_.reset();\\n  unregisteragent();\\n}\\n',\n",
       "       ' bool addinitialurltopreconnectprediction(const gurl& initial_url,\\n                                          preconnectprediction* prediction) {\\n  gurl initial_origin = initial_url.getorigin();\\n  static const int kminsockets = 2;\\n  if (!prediction->requests.empty() &&\\n       prediction->requests.front().origin == initial_origin) {\\n     prediction->requests.front().num_sockets =\\n         std::max(prediction->requests.front().num_sockets, kminsockets);\\n  } else if (initial_origin.is_valid() &&\\n             initial_origin.schemeishttporhttps()) {\\n    url::origin origin = url::origin::create(initial_origin);\\n    prediction->requests.emplace(prediction->requests.begin(), initial_origin,\\n                                 kminsockets,\\n                                 net::networkisolationkey(origin, origin));\\n   }\\n   return !prediction->requests.empty();\\n}\\n',\n",
       "       '  factory(mojo::scopedsharedbuffermapping mapping,\\n           std::unique_ptr<platformsensorfusionalgorithm> fusion_algorithm,\\n           const platformsensorproviderbase::createsensorcallback& callback,\\n           platformsensorprovider* provider)\\n       : fusion_algorithm_(std::move(fusion_algorithm)),\\n         result_callback_(std::move(callback)),\\n        mapping_(std::move(mapping)),\\n         provider_(provider) {\\n     const auto& types = fusion_algorithm_->source_types();\\n     dcheck(!types.empty());\\n     dcheck(std::adjacent_find(types.begin(), types.end()) == types.end());\\n     dcheck(result_callback_);\\n    dcheck(mapping_);\\n     dcheck(provider_);\\n   }\\n',\n",
       "       'void webinspectorproxy::platformattach()\\n{\\n    grefptr<gtkwidget> inspectorview = m_inspectorview;\\n    if (m_inspectorwindow) {\\n        gtk_container_remove(gtk_container(m_inspectorwindow), m_inspectorview);\\n        gtk_widget_destroy(m_inspectorwindow);\\n         m_inspectorwindow = 0;\\n     }\\n     if (m_client.attach(this))\\n         return;\\n    gtk_container_add(gtk_container(m_page->viewwidget()), m_inspectorview);\\n    gtk_widget_show(m_inspectorview);\\n}\\n',\n",
       "       ' void webgraphicscontext3dcommandbufferimpl::flipvertically(\\n     uint8* framebuffer,\\n     unsigned int width,\\n     unsigned int height) {\\n  uint8* scanline = scanline_.get();\\n  if (!scanline)\\n     return;\\n   unsigned int row_bytes = width * 4;\\n   unsigned int count = height / 2;\\n   for (unsigned int i = 0; i < count; i++) {\\n    uint8* row_a = framebuffer + i * row_bytes;\\n    uint8* row_b = framebuffer + (height - i - 1) * row_bytes;\\n    memcpy(scanline, row_b, row_bytes);\\n    memcpy(row_b, row_a, row_bytes);\\n    memcpy(row_a, scanline, row_bytes);\\n  }\\n}\\n',\n",
       "       ' gpuchannelhost::gpuchannelhost(\\n    gpuchannelhostfactory* factory, int gpu_process_id, int client_id)\\n     : factory_(factory),\\n      gpu_process_id_(gpu_process_id),\\n       client_id_(client_id),\\n       state_(kunconnected) {\\n }\\n',\n",
       "       'void printwebviewhelper::print(webkit::webframe* frame, webkit::webnode* node) {\\n  if (print_web_view_)\\n    return;\\n   scoped_ptr<prepareframeandviewforprint> prepare;\\n  if (!initprintsettingsandprepareframe(frame, node, &prepare))\\n     return;  // failed to init print page settings.\\n   int expected_page_count = 0;\\n   bool use_browser_overlays = true;\\n  expected_page_count = prepare->getexpectedpagecount();\\n  if (expected_page_count)\\n    use_browser_overlays = prepare->shouldusebrowseroverlays();\\n  prepare.reset();\\n  if (!expected_page_count) {\\n    didfinishprinting(ok);  // release resources and fail silently.\\n    return;\\n  }\\n  if (!getprintsettingsfromuser(frame, expected_page_count,\\n                                use_browser_overlays)) {\\n    didfinishprinting(ok);  // release resources and fail silently.\\n    return;\\n  }\\n  if (!renderpagesforprint(frame, node, null)) {\\n    log(error) << \"renderpagesforprint failed\";\\n    didfinishprinting(fail_print);\\n  }\\n  resetscriptedprintcount();\\n}\\n',\n",
       "       ' void gpumessagefilter::establishchannelcallback(\\n     ipc::message* reply,\\n     const ipc::channelhandle& channel,\\n    base::processhandle gpu_process_for_browser,\\n     const content::gpuinfo& gpu_info) {\\n   dcheck(browserthread::currentlyon(browserthread::io));\\n  base::processhandle renderer_process_for_gpu;\\n  if (gpu_process_for_browser != 0) {\\n#if defined(os_win)\\n    duplicatehandle(base::getcurrentprocesshandle(),\\n                    peer_handle(),\\n                    gpu_process_for_browser,\\n                    &renderer_process_for_gpu,\\n                    process_dup_handle,\\n                    false,\\n                    0);\\n#else\\n    renderer_process_for_gpu = peer_handle();\\n#endif\\n  } else {\\n    renderer_process_for_gpu = 0;\\n  }\\n   gpuhostmsg_establishgpuchannel::writereplyparams(\\n      reply, render_process_id_, channel, renderer_process_for_gpu, gpu_info);\\n   send(reply);\\n }\\n',\n",
       "       ' png_get_uint_32(png_bytep buf)\\n {\\n   png_uint_32 i = ((png_uint_32)(*buf) << 24) +\\n      ((png_uint_32)(*(buf + 1)) << 16) +\\n      ((png_uint_32)(*(buf + 2)) << 8) +\\n      (png_uint_32)(*(buf + 3));\\n    return (i);\\n }\\n',\n",
       "       ' void pluginmodule::initasproxiednacl(\\n    scoped_ptr<plugindelegate::outofprocessproxy> out_of_process_proxy,\\n     pp_instance instance) {\\n  nacl_ipc_proxy_ = true;\\n  initasproxied(out_of_process_proxy.release());\\n  out_of_process_proxy_->addinstance(instance);\\n  plugininstance* plugin_instance = host_globals->getinstance(instance);\\n  if (!plugin_instance)\\n    return;\\n  plugin_instance->resetasproxied();\\n}\\n',\n",
       "       'void axtree::populateorderedsetitems(const axnode* ordered_set,\\n                                     const axnode* local_parent,\\n                                     std::vector<const axnode*>& items,\\n                                     bool node_is_radio_button) const {\\n  if (!(ordered_set == local_parent)) {\\n    if (local_parent->data().role == ordered_set->data().role)\\n      return;\\n  }\\n   for (int i = 0; i < local_parent->child_count(); ++i) {\\n     const axnode* child = local_parent->getunignoredchildatindex(i);\\n     if (node_is_radio_button &&\\n         child->data().role == ax::mojom::role::kradiobutton)\\n      items.push_back(child);\\n    if (!node_is_radio_button && child->setrolematchesitemrole(ordered_set))\\n      items.push_back(child);\\n    if (child->data().role == ax::mojom::role::kgenericcontainer ||\\n        child->data().role == ax::mojom::role::kignored) {\\n      populateorderedsetitems(ordered_set, child, items, node_is_radio_button);\\n    }\\n  }\\n}\\n',\n",
       "       '  bool isallowed(const scoped_refptr<const extension>& extension,\\n                 const gurl& url,\\n                 permittedfeature feature,\\n                 int tab_id) {\\n    const permissionsdata* permissions_data = extension->permissions_data();\\n     bool script =\\n         permissions_data->canaccesspage(url, tab_id, nullptr) &&\\n         permissions_data->canruncontentscriptonpage(url, tab_id, nullptr);\\n    bool capture = permissions_data->cancapturevisiblepage(url, tab_id, null);\\n     switch (feature) {\\n       case permitted_script_only:\\n         return script && !capture;\\n      case permitted_capture_only:\\n        return capture && !script;\\n      case permitted_both:\\n        return script && capture;\\n      case permitted_none:\\n        return !script && !capture;\\n    }\\n    notreached();\\n    return false;\\n  }\\n',\n",
       "       'bool pulseaudiomixer::initthread() {\\n   autolock lock(mixer_state_lock_);\\n   if (mixer_state_ != uninitialized)\\n     return false;\\n   if (thread_ == null) {\\n    thread_.reset(new base::thread(\"pulseaudiomixer\"));\\n     if (!thread_->start()) {\\n       thread_.reset();\\n       return false;\\n    }\\n  }\\n  mixer_state_ = initializing;\\n  return true;\\n }\\n',\n",
       "       'bool chromecontentutilityclient::onmessagereceived(\\n    const ipc::message& message) {\\n  if (filter_messages_ && !containskey(message_id_whitelist_, message.type()))\\n    return false;\\n  bool handled = true;\\n  ipc_begin_message_map(chromecontentutilityclient, message)\\n    ipc_message_handler(chromeutilitymsg_decodeimage, ondecodeimage)\\n#if defined(os_chromeos)\\n    ipc_message_handler(chromeutilitymsg_robustjpegdecodeimage,\\n                        onrobustjpegdecodeimage)\\n#endif  // defined(os_chromeos)\\n    ipc_message_handler(chromeutilitymsg_patchfilebsdiff,\\n                        onpatchfilebsdiff)\\n    ipc_message_handler(chromeutilitymsg_patchfilecourgette,\\n                        onpatchfilecourgette)\\n    ipc_message_handler(chromeutilitymsg_startupping, onstartupping)\\n #if defined(full_safe_browsing)\\n     ipc_message_handler(chromeutilitymsg_analyzezipfilefordownloadprotection,\\n                         onanalyzezipfilefordownloadprotection)\\n #endif\\n #if defined(enable_extensions)\\n     ipc_message_handler(chromeutilitymsg_parsemediametadata,\\n                        onparsemediametadata)\\n#endif\\n#if defined(os_chromeos)\\n    ipc_message_handler(chromeutilitymsg_createzipfile, oncreatezipfile)\\n#endif\\n    ipc_message_unhandled(handled = false)\\n  ipc_end_message_map()\\n  for (handlers::iterator it = handlers_.begin();\\n       !handled && it != handlers_.end(); ++it) {\\n    handled = (*it)->onmessagereceived(message);\\n  }\\n  return handled;\\n}\\n',\n",
       "       'void bluetoothoptionshandler::devicenotification(\\n    const dictionaryvalue& device) {\\n   web_ui_->calljavascriptfunction(\\n      \"options.systemoptions.addbluetoothdevice\", device);\\n }\\n',\n",
       "       'void inspectorclientimpl::clearbrowsercookies()\\n{\\n    if (webdevtoolsagentimpl* agent = devtoolsagent())\\n        agent->clearbrowsercookies();\\n}\\n',\n",
       "       'void mojoaudiooutputstream::onstreamcreated(\\n    int stream_id,\\n    const base::sharedmemory* shared_memory,\\n    std::unique_ptr<base::cancelablesyncsocket> foreign_socket) {\\n  dcheck_called_on_valid_sequence(sequence_checker_);\\n  dcheck(stream_created_callback_);\\n  dcheck(shared_memory);\\n  dcheck(foreign_socket);\\n  base::sharedmemoryhandle foreign_memory_handle =\\n      base::sharedmemory::duplicatehandle(shared_memory->handle());\\n  if (!base::sharedmemory::ishandlevalid(foreign_memory_handle)) {\\n    onstreamerror(/*not used*/ 0);\\n    return;\\n   }\\n   mojo::scopedsharedbufferhandle buffer_handle = mojo::wrapsharedmemoryhandle(\\n      foreign_memory_handle, shared_memory->requested_size(), false);\\n   mojo::scopedhandle socket_handle =\\n       mojo::wrapplatformfile(foreign_socket->release());\\n  dcheck(buffer_handle.is_valid());\\n  dcheck(socket_handle.is_valid());\\n  base::resetandreturn(&stream_created_callback_)\\n      .run(std::move(buffer_handle), std::move(socket_handle));\\n}\\n',\n",
       "       'void renderwidgethostimpl::oncompositorsurfacebuffersswapped(\\n      int32 surface_id,\\n      uint64 surface_handle,\\n      int32 route_id,\\n      const gfx::size& size,\\n      int32 gpu_process_host_id) {\\n  trace_event0(\"renderer_host\",\\n               \"renderwidgethostimpl::oncompositorsurfacebuffersswapped\");\\n   if (!view_) {\\n     renderwidgethostimpl::acknowledgebufferpresent(route_id,\\n                                                    gpu_process_host_id,\\n                                                   false,\\n                                                    0);\\n     return;\\n   }\\n  gpuhostmsg_acceleratedsurfacebuffersswapped_params gpu_params;\\n  gpu_params.surface_id = surface_id;\\n  gpu_params.surface_handle = surface_handle;\\n  gpu_params.route_id = route_id;\\n  gpu_params.size = size;\\n#if defined(os_macosx)\\n  gpu_params.window = gfx::knullpluginwindow;\\n#endif\\n  view_->acceleratedsurfacebuffersswapped(gpu_params,\\n                                          gpu_process_host_id);\\n}\\n',\n",
       "       ' bool omniboxviewviews::shouldshowplaceholdertext() const {\\n   return textfield::shouldshowplaceholdertext() &&\\n         !model()->is_caret_visible() && !model()->is_keyword_selected();\\n }\\n',\n",
       "       'void rtcpeerconnection::createoffer(passrefptr<rtcsessiondescriptioncallback> successcallback, passrefptr<rtcerrorcallback> errorcallback, const dictionary& mediaconstraints, exceptioncode& ec)\\n{\\n    if (m_readystate == readystateclosing || m_readystate == readystateclosed) {\\n        ec = invalid_state_err;\\n        return;\\n    }\\n    if (!successcallback) {\\n        ec = type_mismatch_err;\\n        return;\\n    }\\n    refptr<mediaconstraints> constraints = mediaconstraintsimpl::create(mediaconstraints, ec);\\n     if (ec)\\n         return;\\n    refptr<rtcsessiondescriptionrequestimpl> request = rtcsessiondescriptionrequestimpl::create(scriptexecutioncontext(), successcallback, errorcallback);\\n     m_peerhandler->createoffer(request.release(), constraints);\\n }\\n',\n",
       "       ' void updatecontentlengthprefs(\\n    int received_content_length, int original_content_length,\\n    bool with_data_reduction_proxy_enabled, bool via_data_reduction_proxy,\\n     prefservice* prefs) {\\n   int64 total_received = prefs->getint64(prefs::khttpreceivedcontentlength);\\n   int64 total_original = prefs->getint64(prefs::khttporiginalcontentlength);\\n  total_received += received_content_length;\\n  total_original += original_content_length;\\n  prefs->setint64(prefs::khttpreceivedcontentlength, total_received);\\n  prefs->setint64(prefs::khttporiginalcontentlength, total_original);\\n#if defined(os_android) || defined(os_ios)\\n  updatecontentlengthprefsfordatareductionproxy(\\n       received_content_length,\\n       original_content_length,\\n       with_data_reduction_proxy_enabled,\\n      via_data_reduction_proxy,\\n       base::time::now(),\\n       prefs);\\n #endif  // defined(os_android) || defined(os_ios)\\n}\\n',\n",
       "       ' pp_bool startppapiproxy(pp_instance instance) {\\n  if (commandline::forcurrentprocess()->hasswitch(\\n          switches::kenablenaclipcproxy)) {\\n    channelhandlemap& map = g_channel_handle_map.get();\\n    channelhandlemap::iterator it = map.find(instance);\\n    if (it == map.end())\\n      return pp_false;\\n    ipc::channelhandle channel_handle = it->second;\\n    map.erase(it);\\n    webkit::ppapi::plugininstance* plugin_instance =\\n        content::gethostglobals()->getinstance(instance);\\n    if (!plugin_instance)\\n      return pp_false;\\n    webview* web_view =\\n        plugin_instance->container()->element().document().frame()->view();\\n    renderview* render_view = content::renderview::fromwebview(web_view);\\n    webkit::ppapi::pluginmodule* plugin_module = plugin_instance->module();\\n    scoped_refptr<syncmessagestatusreceiver>\\n        status_receiver(new syncmessagestatusreceiver());\\n    scoped_ptr<outofprocessproxy> out_of_process_proxy(new outofprocessproxy);\\n    if (out_of_process_proxy->init(\\n            channel_handle,\\n            plugin_module->pp_module(),\\n            webkit::ppapi::pluginmodule::getlocalgetinterfacefunc(),\\n            ppapi::preferences(render_view->getwebkitpreferences()),\\n            status_receiver.get())) {\\n      plugin_module->initasproxiednacl(\\n          out_of_process_proxy.passas<plugindelegate::outofprocessproxy>(),\\n          instance);\\n      return pp_true;\\n    }\\n  }\\n   return pp_false;\\n }\\n',\n",
       "       'void urldata::set_has_opaque_data(bool has_opaque_data) {\\n  if (has_opaque_data_)\\n     return;\\n  has_opaque_data_ = has_opaque_data;\\n }\\n',\n",
       "       'bool appcachedatabase::findentry(int64_t cache_id,\\n                                 const gurl& url,\\n                                 entryrecord* record) {\\n  dcheck(record);\\n  if (!lazyopen(kdontcreate))\\n     return false;\\n   static const char ksql[] =\\n      \"select cache_id, url, flags, response_id, response_size from entries\"\\n       \"  where cache_id = ? and url = ?\";\\n   sql::statement statement(db_->getcachedstatement(sql_from_here, ksql));\\n  statement.bindint64(0, cache_id);\\n  statement.bindstring(1, url.spec());\\n  if (!statement.step())\\n    return false;\\n  readentryrecord(statement, record);\\n  dcheck(record->cache_id == cache_id);\\n  dcheck(record->url == url);\\n  return true;\\n}\\n',\n",
       "       ' void filereaderloader::start(scriptexecutioncontext* scriptexecutioncontext, blob* blob)\\n{\\n    m_urlforreading = bloburl::createpublicurl(scriptexecutioncontext->securityorigin());\\n    if (m_urlforreading.isempty()) {\\n         failed(fileerror::security_err);\\n         return;\\n     }\\n    threadableblobregistry::registerbloburl(scriptexecutioncontext->securityorigin(), m_urlforreading, blob->url());\\n     resourcerequest request(m_urlforreading);\\n    request.sethttpmethod(\"get\");\\n    if (m_hasrange)\\n        request.sethttpheaderfield(\"range\", string::format(\"bytes=%d-%d\", m_rangestart, m_rangeend));\\n    threadableloaderoptions options;\\n    options.sendloadcallbacks = sendcallbacks;\\n    options.sniffcontent = donotsniffcontent;\\n    options.preflightpolicy = considerpreflight;\\n    options.allowcredentials = allowstoredcredentials;\\n    options.crossoriginrequestpolicy = denycrossoriginrequests;\\n    options.contentsecuritypolicyenforcement = donotenforcecontentsecuritypolicy;\\n    if (m_client)\\n        m_loader = threadableloader::create(scriptexecutioncontext, this, request, options);\\n    else\\n        threadableloader::loadresourcesynchronously(scriptexecutioncontext, request, *this, options);\\n}\\n',\n",
       "       'void externalfeedbackreporterandroid::reportexternalfeedback(\\n//// static\\n     content::webcontents* web_contents,\\n     const gurl& url,\\n     const bool good) {\\n   if (!web_contents)\\n     return;\\n  windowandroidhelper* helper =\\n      content::webcontentsuserdata<windowandroidhelper>::fromwebcontents(\\n          web_contents);\\n  dcheck(helper);\\n  ui::windowandroid* window = helper->getwindowandroid();\\n  dcheck(window);\\n   jnienv* env = base::android::attachcurrentthread();\\n   scopedjavalocalref<jstring> jurl = base::android::convertutf8tojavastring(\\n       env, url_utils::getoriginalurlfromdistillerurl(url).spec());\\n  java_domdistillerfeedbackreporter_reportfeedbackwithwindow(\\n      env, window->getjavaobject().obj(), jurl.obj(), good);\\n//// static\\n }\\n',\n",
       "       ' bool printwebviewhelper::onmessagereceived(const ipc::message& message) {\\n   bool handled = true;\\n   ipc_begin_message_map(printwebviewhelper, message)\\n #if defined(enable_basic_printing)\\n    ipc_message_handler(printmsg_printpages, onprintpages)\\n    ipc_message_handler(printmsg_printforsystemdialog, onprintforsystemdialog)\\n#endif  // enable_basic_printing\\n    ipc_message_handler(printmsg_initiateprintpreview, oninitiateprintpreview)\\n    ipc_message_handler(printmsg_printpreview, onprintpreview)\\n    ipc_message_handler(printmsg_printforprintpreview, onprintforprintpreview)\\n    ipc_message_handler(printmsg_printingdone, onprintingdone)\\n     ipc_message_handler(printmsg_setscriptedprintingblocked,\\n                         setscriptedprintblocked)\\n     ipc_message_unhandled(handled = false)\\n    ipc_end_message_map()\\n   return handled;\\n }\\n',\n",
       "       'void linkchangeserializermarkupaccumulator::appendelement(stringbuilder& result, element* element, namespaces* namespaces)\\n{\\n    if (element->hastagname(htmlnames::basetag)) {\\n        result.append(\"<!--\");\\n    } else if (element->hastagname(htmlnames::htmltag)) {\\n        result.append(string::format(\"\\\\n<!-- saved from url=(%04d)%s -->\\\\n\",\\n            static_cast<int>(m_document->url().string().utf8().length()),\\n            m_document->url().string().utf8().data()));\\n    }\\n    serializermarkupaccumulator::appendelement(result, element, namespaces);\\n    if (element->hastagname(htmlnames::basetag)) {\\n        result.appendliteral(\"-->\");\\n        result.appendliteral(\"<base href=\\\\\".\\\\\"\");\\n        if (!m_document->basetarget().isempty()) {\\n            result.appendliteral(\" target=\\\\\"\");\\n            result.append(m_document->basetarget());\\n            result.append(\\'\"\\');\\n        }\\n        if (m_document->isxhtmldocument())\\n            result.appendliteral(\" />\");\\n        else\\n            result.appendliteral(\">\");\\n    }\\n}\\n',\n",
       "       'void gpucommandbufferstub::oncreatevideodecoder(\\n    media::videocodecprofile profile,\\n    ipc::message* reply_message) {\\n  int decoder_route_id = channel_->generaterouteid();\\n  gpucommandbuffermsg_createvideodecoder::writereplyparams(\\n      reply_message, decoder_route_id);\\n  gpuvideodecodeaccelerator* decoder =\\n       new gpuvideodecodeaccelerator(this, decoder_route_id, this);\\n   video_decoders_.addwithid(decoder, decoder_route_id);\\n   channel_->addroute(decoder_route_id, decoder);\\n  decoder->initialize(profile, reply_message,\\n                      channel_->renderer_process());\\n }\\n',\n",
       "       ' quotatask::quotatask(quotataskobserver* observer)\\n     : observer_(observer),\\n      original_task_runner_(base::messageloopproxy::current()) {\\n }\\n',\n",
       "       'void sharedworkerdevtoolsagenthost::attachsession(devtoolssession* session) {\\n   session->addhandler(std::make_unique<protocol::inspectorhandler>());\\n   session->addhandler(std::make_unique<protocol::networkhandler>(getid()));\\n   session->addhandler(std::make_unique<protocol::schemahandler>());\\n  session->setrenderer(getprocess(), nullptr);\\n   if (state_ == worker_ready)\\n     session->attachtoagent(ensureagent());\\n }\\n',\n",
       "       ' png_get_mmx_bitdepth_threshold (png_structp png_ptr)\\n {\\n     /* obsolete, to be removed from libpng-1.4.0 */\\n    return (png_ptr? 0: 0);\\n }\\n',\n",
       "       ' void platformsensorproviderandroid::createabsoluteorientationquaternionsensor(\\n     jnienv* env,\\n    mojo::scopedsharedbuffermapping mapping,\\n     const createsensorcallback& callback) {\\n   scopedjavalocalref<jobject> sensor = java_platformsensorprovider_createsensor(\\n       env, j_object_,\\n       static_cast<jint>(mojom::sensortype::absolute_orientation_quaternion));\\n   if (sensor.obj()) {\\n     auto concrete_sensor = base::makerefcounted<platformsensorandroid>(\\n        mojom::sensortype::absolute_orientation_quaternion, std::move(mapping),\\n         this, sensor);\\n     callback.run(concrete_sensor);\\n  } else {\\n    auto sensor_fusion_algorithm =\\n        std::make_unique<orientationquaternionfusionalgorithmusingeulerangles>(\\n            true /* absolute */);\\n    platformsensorfusion::create(std::move(mapping), this,\\n                                  std::move(sensor_fusion_algorithm), callback);\\n   }\\n }\\n',\n",
       "       ' entrysync* entrysync::moveto(directoryentrysync* parent, const string& name, exceptionstate& exceptionstate) const\\n {\\n    refptr<entrysynccallbackhelper> helper = entrysynccallbackhelper::create();\\n     m_filesystem->move(this, parent, name, helper->successcallback(), helper->errorcallback(), domfilesystembase::synchronous);\\n     return helper->getresult(exceptionstate);\\n }\\n',\n",
       "       'passrefptr<rtcsessiondescription> rtcpeerconnection::remotedescription(exceptioncode& ec)\\n{\\n    if (m_readystate == readystateclosing || m_readystate == readystateclosed) {\\n        ec = invalid_state_err;\\n        return 0;\\n    }\\n    refptr<rtcsessiondescriptiondescriptor> descriptor = m_peerhandler->remotedescription();\\n    if (!descriptor)\\n        return 0;\\n    refptr<rtcsessiondescription> desc = rtcsessiondescription::create(descriptor.release());\\n    return desc.release();\\n}\\n',\n",
       "       ' bool xmlreader::loadfile(const std::string& file_path) {\\n   const int kparseoptions = xml_parse_recover |  // recover on errors\\n                            xml_parse_nonet |    // forbid network access\\n                            xml_parse_noxxe;     // no external entities\\n   reader_ = xmlreaderforfile(file_path.c_str(), null, kparseoptions);\\n   return reader_ != null;\\n }\\n',\n",
       "       ' extensionsguestviewmessagefilter::~extensionsguestviewmessagefilter() {\\n   dcheck_currently_on(browserthread::io);\\n  (*getprocessidtofiltermap())[render_process_id_] = nullptr;\\n  base::posttaskwithtraits(\\n      from_here, browserthread::ui,\\n      base::bindonce(removeprocessidfromglobalmap, render_process_id_));\\n }\\n',\n",
       "       'void workerfetchcontext::dispatchwillsendrequest(\\n     unsigned long identifier,\\n     resourcerequest& request,\\n     const resourceresponse& redirect_response,\\n     const fetchinitiatorinfo& initiator_info) {\\n   probe::willsendrequest(global_scope_, identifier, nullptr, request,\\n                         redirect_response, initiator_info);\\n }\\n',\n",
       "       'socketstreamdispatcherhost::socketstreamdispatcherhost(\\n     int render_process_id,\\n     resourcemessagefilter::urlrequestcontextselector* selector,\\n     content::resourcecontext* resource_context)\\n    : allow_this_in_initializer_list(ssl_delegate_weak_factory_(this)),\\n      render_process_id_(render_process_id),\\n       url_request_context_selector_(selector),\\n       resource_context_(resource_context) {\\n   dcheck(selector);\\n  net::websocketjob::ensureinit();\\n}\\n',\n",
       "       'std::string sanitizeremotebase(const std::string& value) {\\n  gurl url(value);\\n  std::string path = url.path();\\n  std::vector<std::string> parts = base::splitstring(\\n      path, \"/\", base::keep_whitespace, base::split_want_all);\\n  std::string revision = parts.size() > 2 ? parts[2] : \"\";\\n  revision = sanitizerevision(revision);\\n  path = base::stringprintf(\"/%s/%s/\", kremotefrontendpath, revision.c_str());\\n  return sanitizefrontendurl(url, url::khttpsscheme,\\n                             kremotefrontenddomain, path, false).spec();\\n}\\n',\n",
       "       'bool gdatadirectory::fromproto(const gdatadirectoryproto& proto) {\\n  dcheck(proto.gdata_entry().file_info().is_directory());\\n   dcheck(!proto.gdata_entry().has_file_specific_info());\\n   for (int i = 0; i < proto.child_files_size(); ++i) {\\n    scoped_ptr<gdatafile> file(new gdatafile(null, directory_service_));\\n     if (!file->fromproto(proto.child_files(i))) {\\n       removechildren();\\n       return false;\\n     }\\n     addentry(file.release());\\n   }\\n   for (int i = 0; i < proto.child_directories_size(); ++i) {\\n    scoped_ptr<gdatadirectory> dir(new gdatadirectory(null,\\n                                                      directory_service_));\\n     if (!dir->fromproto(proto.child_directories(i))) {\\n       removechildren();\\n       return false;\\n    }\\n    addentry(dir.release());\\n  }\\n  if (!gdataentry::fromproto(proto.gdata_entry()))\\n    return false;\\n  return true;\\n}\\n',\n",
       "       '   void dotest(externalprotocolhandler::blockstate block_state,\\n               shell_integration::defaultwebclientstate os_state,\\n               action expected_action) {\\n    gurl url(\"mailto:test@test.com\");\\n     expect_false(delegate_.has_prompted());\\n     expect_false(delegate_.has_launched());\\n     expect_false(delegate_.has_blocked());\\n    delegate_.set_block_state(block_state);\\n    delegate_.set_os_state(os_state);\\n    externalprotocolhandler::launchurlwithdelegate(\\n        url, 0, 0, ui::page_transition_link, true, &delegate_);\\n    content::runalltasksuntilidle();\\n    expect_eq(expected_action == action::prompt, delegate_.has_prompted());\\n    expect_eq(expected_action == action::launch, delegate_.has_launched());\\n    expect_eq(expected_action == action::block, delegate_.has_blocked());\\n  }\\n',\n",
       "       'bool ppvartonpvariant(pp_var var, npvariant* result) {\\n  switch (var.type) {\\n    case pp_vartype_undefined:\\n      void_to_npvariant(*result);\\n      break;\\n    case pp_vartype_null:\\n      null_to_npvariant(*result);\\n      break;\\n    case pp_vartype_bool:\\n      boolean_to_npvariant(var.value.as_bool, *result);\\n      break;\\n    case pp_vartype_int32:\\n      int32_to_npvariant(var.value.as_int, *result);\\n      break;\\n    case pp_vartype_double:\\n      double_to_npvariant(var.value.as_double, *result);\\n      break;\\n    case pp_vartype_string: {\\n      scoped_refptr<stringvar> string(stringvar::fromppvar(var));\\n      if (!string) {\\n        void_to_npvariant(*result);\\n         return false;\\n       }\\n       const std::string& value = string->value();\\n      stringn_to_npvariant(base::strdup(value.c_str()), value.size(), *result);\\n       break;\\n     }\\n     case pp_vartype_object: {\\n      scoped_refptr<objectvar> object(objectvar::fromppvar(var));\\n      if (!object) {\\n        void_to_npvariant(*result);\\n        return false;\\n      }\\n      object_to_npvariant(webbindings::retainobject(object->np_object()),\\n                          *result);\\n      break;\\n    }\\n    case pp_vartype_array:\\n    case pp_vartype_dictionary:\\n      void_to_npvariant(*result);\\n      break;\\n  }\\n  return true;\\n}\\n',\n",
       "       ' bool printwebviewhelper::initprintsettingsandprepareframe(\\n     webkit::webframe* frame, webkit::webnode* node,\\n     scoped_ptr<prepareframeandviewforprint>* prepare) {\\n  if (!initprintsettings(frame, node, false))\\n     return false;\\n   dcheck(!prepare->get());\\n  prepare->reset(new prepareframeandviewforprint(print_pages_params_->params,\\n                                                 frame, node));\\n  updateprintablesizeinprintparameters(frame, node, prepare->get(),\\n                                       &print_pages_params_->params);\\n  send(new printhostmsg_didgetdocumentcookie(\\n        routing_id(), print_pages_params_->params.document_cookie));\\n  return true;\\n}\\n',\n",
       "       ' bool overscrollcontrollerandroid::animate(base::timeticks current_time,\\n                                           cc::layer* parent_layer) {\\n   dcheck(parent_layer);\\n  if (!enabled_)\\n     return false;\\n   return glow_effect_->animate(current_time, parent_layer);\\n}\\n',\n",
       "       ' bool clipboardutil::getfilenames(idataobject* data_object,\\n                                 std::vector<base::string16>* filenames) {\\n  dcheck(data_object && filenames);\\n  if (!hasfilenames(data_object))\\n     return false;\\n   stgmedium medium;\\n  if (!getdata(data_object, clipboard::getcfhdropformattype(), &medium))\\n    return false;\\n  hdrop hdrop = static_cast<hdrop>(globallock(medium.hglobal));\\n  if (!hdrop)\\n    return false;\\n  const int kmaxfilenamelen = 4096;\\n  const unsigned num_files = dragqueryfilew(hdrop, 0xffffffff, 0, 0);\\n  for (unsigned int i = 0; i < num_files; ++i) {\\n    wchar_t filename[kmaxfilenamelen];\\n    if (!dragqueryfilew(hdrop, i, filename, kmaxfilenamelen))\\n      continue;\\n    filenames->push_back(filename);\\n   }\\n  dragfinish(hdrop);\\n  globalunlock(medium.hglobal);\\n  return true;\\n }\\n',\n",
       "       'gdatadirectory::gdatadirectory(gdatadirectory* parent,\\n                               gdatadirectoryservice* directory_service)\\n    : gdataentry(parent, directory_service) {\\n   file_info_.is_directory = true;\\n }\\n',\n",
       "       ' response pagehandler::setdownloadbehavior(const std::string& behavior,\\n                                           maybe<std::string> download_path) {\\n   webcontentsimpl* web_contents = getwebcontents();\\n   if (!web_contents)\\n     return response::internalerror();\\n  if (behavior == page::setdownloadbehavior::behaviorenum::allow &&\\n      !download_path.isjust())\\n    return response::error(\"downloadpath not provided\");\\n  if (behavior == page::setdownloadbehavior::behaviorenum::default) {\\n    devtoolsdownloadmanagerhelper::removefromwebcontents(web_contents);\\n    download_manager_delegate_ = nullptr;\\n    return response::ok();\\n  }\\n  content::browsercontext* browser_context = web_contents->getbrowsercontext();\\n  dcheck(browser_context);\\n  content::downloadmanager* download_manager =\\n      content::browsercontext::getdownloadmanager(browser_context);\\n  download_manager_delegate_ =\\n      devtoolsdownloadmanagerdelegate::takeover(download_manager);\\n  devtoolsdownloadmanagerhelper::createforwebcontents(web_contents);\\n  devtoolsdownloadmanagerhelper* download_helper =\\n      devtoolsdownloadmanagerhelper::fromwebcontents(web_contents);\\n  download_helper->setdownloadbehavior(\\n      devtoolsdownloadmanagerhelper::downloadbehavior::deny);\\n  if (behavior == page::setdownloadbehavior::behaviorenum::allow) {\\n    download_helper->setdownloadbehavior(\\n        devtoolsdownloadmanagerhelper::downloadbehavior::allow);\\n    download_helper->setdownloadpath(download_path.fromjust());\\n  }\\n  return response::ok();\\n}\\n',\n",
       "       '   void removeclientsession() {\\n    context_.network_message_loop()->posttask(\\n        from_here, base::bind(\\n            &clientsession::onconnectionclosed, client_, connection_));\\n   }\\n',\n",
       "       ' networkreaderproxy::networkreaderproxy(\\n     int64 content_length,\\n     const base::closure& job_canceller)\\n    : remaining_content_length_(content_length),\\n       error_code_(net::ok),\\n       buffer_length_(0),\\n       job_canceller_(job_canceller) {\\n  dcheck(browserthread::currentlyon(browserthread::io));\\n}\\n',\n",
       "       'void resource::lastpluginrefwasdeleted(bool instance_destroyed) {\\n   dcheck(resource_id_ != 0);\\n   instance()->module()->getcallbacktracker()->postabortforresource(\\n       resource_id_);\\n   resource_id_ = 0;\\n  if (instance_destroyed)\\n    instance_ = null;\\n }\\n',\n",
       "       ' void localfilesystem::filesystemnotallowedinternal(\\n     passrefptrwillberawptr<executioncontext> context,\\n    passrefptr<callbackwrapper> callbacks)\\n {\\n     context->posttask(createcrossthreadtask(&reportfailure, callbacks->release(), fileerror::abort_err));\\n }\\n',\n",
       "       'void maybereportdownloaddeepscanningverdict(\\n    profile* profile,\\n    const gurl& url,\\n    const std::string& file_name,\\n     const std::string& download_digest_sha256,\\n     binaryuploadservice::result result,\\n     deepscanningclientresponse response) {\\n   if (response.malware_scan_verdict().verdict() ==\\n           malwaredeepscanningverdict::uws ||\\n       response.malware_scan_verdict().verdict() ==\\n           malwaredeepscanningverdict::malware) {\\n     extensions::safebrowsingprivateeventrouterfactory::getforprofile(profile)\\n         ->ondangerousdeepscanningresult(url, file_name, download_digest_sha256);\\n   }\\n }\\n',\n",
       "       'void resourcefetcher::preloadstarted(resource* resource) {\\n  if (preloads_ && preloads_->contains(resource))\\n    return;\\n  resource->increasepreloadcount();\\n  if (!preloads_)\\n     preloads_ = new heaplisthashset<member<resource>>;\\n   preloads_->insert(resource);\\n  if (preloaded_ur_ls_for_test_)\\n    preloaded_ur_ls_for_test_->insert(resource->url().getstring());\\n }\\n',\n",
       "       'void datareductionproxyconfig::initializeoniothread(\\n    scoped_refptr<network::sharedurlloaderfactory> url_loader_factory,\\n    warmupurlfetcher::createcustomproxyconfigcallback\\n        create_custom_proxy_config_callback,\\n    networkpropertiesmanager* manager) {\\n  dcheck(thread_checker_.calledonvalidthread());\\n  network_properties_manager_ = manager;\\n  network_properties_manager_->resetwarmupurlfetchmetrics();\\n  secure_proxy_checker_.reset(new secureproxychecker(url_loader_factory));\\n  warmup_url_fetcher_.reset(new warmupurlfetcher(\\n      url_loader_factory, create_custom_proxy_config_callback,\\n      base::bindrepeating(\\n          &datareductionproxyconfig::handlewarmupfetcherresponse,\\n          base::unretained(this)),\\n      base::bindrepeating(&datareductionproxyconfig::gethttprttestimate,\\n                           base::unretained(this)),\\n       ui_task_runner_));\\n  if (shouldadddefaultproxybypassrules())\\n    adddefaultproxybypassrules();\\n   network_connection_tracker_->addnetworkconnectionobserver(this);\\n   network_connection_tracker_->getconnectiontype(\\n      &connection_type_,\\n      base::bindonce(&datareductionproxyconfig::onconnectionchanged,\\n                      weak_factory_.getweakptr()));\\n }\\n',\n",
       "       'void bluetoothdevicechromeos::displaypincode(\\n    const dbus::objectpath& device_path,\\n    const std::string& pincode) {\\n  dcheck(agent_.get());\\n  dcheck(device_path == object_path_);\\n  vlog(1) << object_path_.value() << \": displaypincode: \" << pincode;\\n  uma_histogram_enumeration(\"bluetooth.pairingmethod\",\\n                            uma_pairing_method_display_pincode,\\n                            uma_pairing_method_count);\\n  dcheck(pairing_delegate_);\\n  pairing_delegate_->displaypincode(this, pincode);\\n  pairing_delegate_used_ = true;\\n}\\n',\n",
       "       ' std::string mediastreammanager::makemediaaccessrequest(\\n     int render_process_id,\\n     int render_frame_id,\\n     int page_request_id,\\n     const streamcontrols& controls,\\n     const url::origin& security_origin,\\n     mediaaccessrequestcallback callback) {\\n   dcheck_currently_on(browserthread::io);\\n   devicerequest* request = new devicerequest(\\n      render_process_id, render_frame_id, page_request_id,\\n       false /* user gesture */, media_device_access, controls,\\n       mediadevicesaltandorigin{std::string() /* salt */,\\n                                std::string() /* group_id_salt */,\\n                               security_origin});\\n  const std::string& label = addrequest(request);\\n  request->media_access_request_cb = std::move(callback);\\n  base::posttaskwithtraits(from_here, {browserthread::io},\\n                           base::bindonce(&mediastreammanager::setuprequest,\\n                                          base::unretained(this), label));\\n  return label;\\n}\\n',\n",
       "       'void databasemessagefilter::onhandlesqliteerror(\\n    const string16& origin_identifier,\\n     const string16& database_name,\\n     int error) {\\n   dcheck(browserthread::currentlyon(browserthread::file));\\n   db_tracker_->handlesqliteerror(origin_identifier, database_name, error);\\n }\\n',\n",
       "       'void svgdocumentextensions::startanimations()\\n{\\n     willbeheapvector<refptrwillbemember<svgsvgelement> > timecontainers;\\n     timecontainers.appendrange(m_timecontainers.begin(), m_timecontainers.end());\\n     willbeheapvector<refptrwillbemember<svgsvgelement> >::iterator end = timecontainers.end();\\n    for (willbeheapvector<refptrwillbemember<svgsvgelement> >::iterator itr = timecontainers.begin(); itr != end; ++itr)\\n        (*itr)->timecontainer()->begin();\\n }\\n',\n",
       "       '  void onreadallmetadata(\\n      const sessionstore::sessioninfo& session_info,\\n      sessionstore::factorycompletioncallback callback,\\n      std::unique_ptr<modeltypestore> store,\\n       std::unique_ptr<modeltypestore::recordlist> record_list,\\n       const base::optional<syncer::modelerror>& error,\\n       std::unique_ptr<syncer::metadatabatch> metadata_batch) {\\n     if (error) {\\n       std::move(callback).run(error, /*store=*/nullptr,\\n                               /*metadata_batch=*/nullptr);\\n      return;\\n    }\\n    std::map<std::string, sync_pb::sessionspecifics> initial_data;\\n    for (modeltypestore::record& record : *record_list) {\\n      const std::string& storage_key = record.id;\\n      sessionspecifics specifics;\\n      if (storage_key.empty() ||\\n          !specifics.parsefromstring(std::move(record.value))) {\\n        dvlog(1) << \"ignoring corrupt database entry with key: \" << storage_key;\\n        continue;\\n      }\\n      initial_data[storage_key].swap(&specifics);\\n    }\\n    auto session_store = std::make_unique<sessionstore>(\\n        sessions_client_, session_info, std::move(store),\\n        std::move(initial_data), metadata_batch->getallmetadata(),\\n        restored_foreign_tab_callback_);\\n    std::move(callback).run(/*error=*/base::nullopt, std::move(session_store),\\n                            std::move(metadata_batch));\\n  }\\n',\n",
       "       ' void webplugindelegateproxy::ongetwindowscriptnpobject(\\n    int route_id, bool* success, intptr_t* npobject_ptr) {\\n   *success = false;\\n   npobject* npobject = null;\\n   if (plugin_)\\n    npobject = plugin_->getwindowscriptnpobject();\\n  if (!npobject)\\n    return;\\n   window_script_object_ = (new npobjectstub(\\n       npobject, channel_host_.get(), route_id, 0, page_url_))->asweakptr();\\n   *success = true;\\n  *npobject_ptr = reinterpret_cast<intptr_t>(npobject);\\n }\\n',\n",
       "       ' void fakeplatformsensorprovider::createsensorinternal(\\n     mojom::sensortype type,\\n    mojo::scopedsharedbuffermapping mapping,\\n     const createsensorcallback& callback) {\\n   dcheck(type >= mojom::sensortype::first && type <= mojom::sensortype::last);\\n   auto sensor =\\n      base::makerefcounted<fakeplatformsensor>(type, std::move(mapping), this);\\n   docreatesensorinternal(type, std::move(sensor), callback);\\n }\\n',\n",
       "       'void paymentrequest::updatewith(mojom::paymentdetailsptr details) {\\n   std::string error;\\n   if (!validatepaymentdetails(convertpaymentdetails(details), &error)) {\\n    log(error) << error;\\n     onconnectionterminated();\\n     return;\\n   }\\n   if (details->shipping_address_errors &&\\n       !paymentsvalidators::isvalidaddresserrorsformat(\\n           details->shipping_address_errors, &error)) {\\n    dlog(error) << error;\\n     onconnectionterminated();\\n     return;\\n   }\\n   if (!details->total) {\\n    log(error) << \"missing total\";\\n     onconnectionterminated();\\n     return;\\n   }\\n  spec_->updatewith(std::move(details));\\n }\\n',\n",
       "       '   virtual std::string getkeyboardoverlayid(const std::string& input_method_id) {\\n     if (!initialized_successfully_)\\n       return \"\";\\n    return chromeos::getkeyboardoverlayid(input_method_id);\\n   }\\n',\n",
       "       'caststreamingnativehandler::caststreamingnativehandler(scriptcontext* context)\\n     : objectbackednativehandler(context),\\n       last_transport_id_(1),\\n       weak_factory_(this) {\\n  routefunction(\"createsession\",\\n                 base::bind(&caststreamingnativehandler::createcastsession,\\n                            weak_factory_.getweakptr()));\\n  routefunction(\"destroycastrtpstream\",\\n                 base::bind(&caststreamingnativehandler::destroycastrtpstream,\\n                            weak_factory_.getweakptr()));\\n   routefunction(\\n      \"getsupportedparamscastrtpstream\",\\n       base::bind(&caststreamingnativehandler::getsupportedparamscastrtpstream,\\n                  weak_factory_.getweakptr()));\\n  routefunction(\"startcastrtpstream\",\\n                 base::bind(&caststreamingnativehandler::startcastrtpstream,\\n                            weak_factory_.getweakptr()));\\n  routefunction(\"stopcastrtpstream\",\\n                 base::bind(&caststreamingnativehandler::stopcastrtpstream,\\n                            weak_factory_.getweakptr()));\\n  routefunction(\"destroycastudptransport\",\\n                 base::bind(&caststreamingnativehandler::destroycastudptransport,\\n                            weak_factory_.getweakptr()));\\n   routefunction(\\n      \"setdestinationcastudptransport\",\\n       base::bind(&caststreamingnativehandler::setdestinationcastudptransport,\\n                  weak_factory_.getweakptr()));\\n   routefunction(\\n      \"setoptionscastudptransport\",\\n       base::bind(&caststreamingnativehandler::setoptionscastudptransport,\\n                  weak_factory_.getweakptr()));\\n  routefunction(\"togglelogging\",\\n                 base::bind(&caststreamingnativehandler::togglelogging,\\n                            weak_factory_.getweakptr()));\\n  routefunction(\"getrawevents\",\\n                 base::bind(&caststreamingnativehandler::getrawevents,\\n                            weak_factory_.getweakptr()));\\n  routefunction(\"getstats\", base::bind(&caststreamingnativehandler::getstats,\\n                                       weak_factory_.getweakptr()));\\n  routefunction(\"startcastrtpreceiver\",\\n                 base::bind(&caststreamingnativehandler::startcastrtpreceiver,\\n                            weak_factory_.getweakptr()));\\n }\\n',\n",
       "       'void renderbox::stylewillchange(styledifference diff, const renderstyle& newstyle)\\n{\\n    renderstyle* oldstyle = style();\\n     if (oldstyle) {\\n        if (diff >= styledifferencerepaint && node() &&\\n            (ishtmlhtmlelement(*node()) || ishtmlbodyelement(*node()))) {\\n             view()->repaint();\\n             if (oldstyle->hasentirelyfixedbackground() != newstyle.hasentirelyfixedbackground())\\n                view()->compositor()->setneedsupdatefixedbackground();\\n        }\\n        if (diff == styledifferencelayout && parent() && oldstyle->position() != newstyle.position()) {\\n             markcontainingblocksforlayout();\\n             if (oldstyle->position() == staticposition)\\n                 repaint();\\n            else if (newstyle.hasoutofflowposition())\\n                parent()->setchildneedslayout();\\n            if (isfloating() && !isoutofflowpositioned() && newstyle.hasoutofflowposition())\\n                removefloatingorpositionedchildfromblocklists();\\n        }\\n    } else if (isbody())\\n        view()->repaint();\\n    renderboxmodelobject::stylewillchange(diff, newstyle);\\n}\\n',\n",
       "       ' void inspectorresourceagent::setuseragentoverride(errorstring*, const string& useragent)\\n {\\n     m_state->setstring(resourceagentstate::useragentoverride, useragent);\\n    m_overlay->setoverride(inspectoroverlay::useragentoverride, !useragent.isempty());\\n }\\n',\n",
       "       ' mediacontrolsprogressview::mediacontrolsprogressview(\\n     base::repeatingcallback<void(double)> seek_callback)\\n     : seek_callback_(std::move(seek_callback)) {\\n   setlayoutmanager(std::make_unique<views::boxlayout>(\\n      views::boxlayout::orientation::kvertical, kprogressviewinsets));\\n  progress_bar_ = addchildview(std::make_unique<views::progressbar>(5, false));\\n  progress_bar_->setborder(views::createemptyborder(kprogressbarinsets));\\n   gfx::font default_font;\\n  int font_size_delta = kprogresstimefontsize - default_font.getfontsize();\\n  gfx::font font = default_font.derive(font_size_delta, gfx::font::normal,\\n                                       gfx::font::weight::normal);\\n  gfx::fontlist font_list(font);\\n  auto time_view = std::make_unique<views::view>();\\n  auto* time_view_layout =\\n      time_view->setlayoutmanager(std::make_unique<views::flexlayout>());\\n  time_view_layout->setorientation(views::layoutorientation::khorizontal)\\n      .setmainaxisalignment(views::layoutalignment::kcenter)\\n      .setcrossaxisalignment(views::layoutalignment::kcenter)\\n      .setcollapsemargins(true);\\n  auto progress_time = std::make_unique<views::label>();\\n  progress_time->setfontlist(font_list);\\n  progress_time->setenabledcolor(sk_colorwhite);\\n  progress_time->setautocolorreadabilityenabled(false);\\n  progress_time_ = time_view->addchildview(std::move(progress_time));\\n  auto time_spacing = std::make_unique<views::view>();\\n  time_spacing->setpreferredsize(ktimespacingsize);\\n  time_spacing->setproperty(views::kflexbehaviorkey,\\n                            views::flexspecification::forsizerule(\\n                                views::minimumflexsizerule::kpreferred,\\n                                views::maximumflexsizerule::kunbounded));\\n  time_view->addchildview(std::move(time_spacing));\\n  auto duration = std::make_unique<views::label>();\\n  duration->setfontlist(font_list);\\n  duration->setenabledcolor(sk_colorwhite);\\n  duration->setautocolorreadabilityenabled(false);\\n  duration_ = time_view->addchildview(std::move(duration));\\n  addchildview(std::move(time_view));\\n}\\n',\n",
       "       ' void frameview::updatelayoutandstyleforpainting()\\n {\\n     refptr<frameview> protector(this);\\n     updatelayoutandstyleifneededrecursive();\\n     if (renderview* view = renderview()) {\\n         trace_event_instant1(trace_disabled_by_default(\"devtools.timeline\"), \"updatelayertree\", \"frame\", m_frame.get());\\n        inspectorinstrumentation::willupdatelayertree(m_frame.get());\\n        view->compositor()->updateifneededrecursive();\\n        if (view->compositor()->incompositingmode() && m_frame->islocalroot())\\n            m_frame->page()->scrollingcoordinator()->updateaftercompositingchangeifneeded();\\n        updatecompositedselectionboundsifneeded();\\n        inspectorinstrumentation::didupdatelayertree(m_frame.get());\\n        invalidatetreeifneededrecursive();\\n    }\\n    scrollcontentsifneededrecursive();\\n    assert(lifecycle().state() == documentlifecycle::paintinvalidationclean);\\n}\\n',\n",
       "       'passrefptr<sharedbuffer> readfile(const char* filename)\\n {\\n     string filepath = platform::current()->unittestsupport()->webkitrootdir();\\n     filepath.append(filename);\\n     return platform::current()->unittestsupport()->readfromfile(filepath);\\n}\\n',\n",
       "       ' void pluginchannel::onchannelerror() {\\n  base::closeprocesshandle(renderer_handle_);\\n  renderer_handle_ = 0;\\n   npchannelbase::onchannelerror();\\n   cleanup();\\n }\\n',\n",
       "       ' void webplugindelegatestub::onsendjavascriptstream(const gurl& url,\\n                                                    const std::string& result,\\n                                                    bool success,\\n                                                   bool notify_needed,\\n                                                   intptr_t notify_data) {\\n  delegate_->sendjavascriptstream(url, result, success, notify_needed,\\n                                  notify_data);\\n }\\n',\n",
       "       'v8::handle<v8::value> appwindowcustombindings::getview(\\n    const v8::arguments& args) {\\n  if (args.length() != 1)\\n    return v8::undefined();\\n  if (!args[0]->isint32())\\n    return v8::undefined();\\n  int view_id = args[0]->int32value();\\n  if (view_id == msg_routing_none)\\n    return v8::undefined();\\n  findviewbyid view_finder(view_id);\\n  content::renderview::foreach(&view_finder);\\n  content::renderview* view = view_finder.view();\\n  if (!view)\\n    return v8::undefined();\\n  content::renderview* render_view = getcurrentrenderview();\\n  if (!render_view)\\n    return v8::undefined();\\n   webkit::webframe* opener = render_view->getwebview()->mainframe();\\n   webkit::webframe* frame = view->getwebview()->mainframe();\\n   frame->setopener(opener);\\n   v8::local<v8::value> window = frame->mainworldscriptcontext()->global();\\n   return window;\\n}\\n',\n",
       "       'void gestureprovideraura::ontoucheventack(bool event_consumed) {\\n  dcheck(pending_gestures_.empty());\\n   dcheck(!handling_event_);\\n   base::autoreset<bool> handling_event(&handling_event_, true);\\n   filtered_gesture_provider_.ontoucheventack(event_consumed);\\n }\\n',\n",
       "       'windowopendisposition browserview::getdispositionforpopupbounds(\\n    const gfx::rect& bounds) {\\n  return windowopendisposition::new_popup;\\n}\\n',\n",
       "       'bool clipboardutil::getwebcustomdata(\\n    idataobject* data_object,\\n    std::map<base::string16, base::string16>* custom_data) {\\n  dcheck(data_object && custom_data);\\n  if (!hasdata(data_object, clipboard::getwebcustomdataformattype()))\\n    return false;\\n   stgmedium store;\\n   if (getdata(data_object, clipboard::getwebcustomdataformattype(), &store)) {\\n     {\\n      base::win::scopedhglobal<char> data(store.hglobal);\\n       readcustomdataintomap(data.get(), data.size(), custom_data);\\n     }\\n     releasestgmedium(&store);\\n    return true;\\n  }\\n  return false;\\n}\\n',\n",
       "       'printviewmanagerbase::printviewmanagerbase(content::webcontents* web_contents)\\n    : printmanager(web_contents),\\n      printing_rfh_(nullptr),\\n      printing_succeeded_(false),\\n      inside_inner_message_loop_(false),\\n #if !defined(os_macosx)\\n       expecting_first_page_(true),\\n #endif\\n      queue_(g_browser_process->print_job_manager()->queue()) {\\n   dcheck(queue_.get());\\n   profile* profile =\\n       profile::frombrowsercontext(web_contents->getbrowsercontext());\\n  printing_enabled_.init(\\n      prefs::kprintingenabled, profile->getprefs(),\\n      base::bind(&printviewmanagerbase::updateprintingenabled,\\n                 base::unretained(this)));\\n}\\n',\n",
       "       '  virtual inputmethoddescriptor previous_input_method() const {\\n     if (previous_input_method_.id.empty()) {\\n       return input_method::getfallbackinputmethoddescriptor();\\n     }\\n     return previous_input_method_;\\n   }\\n',\n",
       "       'void installablepaymentappcrawler::onpaymentmethodmanifestparsed(\\n    const gurl& method_manifest_url,\\n    const std::vector<gurl>& default_applications,\\n    const std::vector<url::origin>& supported_origins,\\n    bool all_origins_supported) {\\n  number_of_payment_method_manifest_to_parse_--;\\n  if (web_contents() == nullptr)\\n    return;\\n  content::permissionmanager* permission_manager =\\n      web_contents()->getbrowsercontext()->getpermissionmanager();\\n  if (permission_manager == nullptr)\\n    return;\\n  for (const auto& url : default_applications) {\\n    if (downloaded_web_app_manifests_.find(url) !=\\n        downloaded_web_app_manifests_.end()) {\\n       continue;\\n     }\\n     if (permission_manager->getpermissionstatus(\\n             content::permissiontype::payment_handler, url.getorigin(),\\n             url.getorigin()) != blink::mojom::permissionstatus::granted) {\\n      continue;\\n    }\\n    number_of_web_app_manifest_to_download_++;\\n    downloaded_web_app_manifests_.insert(url);\\n    downloader_->downloadwebappmanifest(\\n        url,\\n        base::bindonce(\\n            &installablepaymentappcrawler::onpaymentwebappmanifestdownloaded,\\n            weak_ptr_factory_.getweakptr(), method_manifest_url, url));\\n  }\\n  finishcrawlingpaymentappsifready();\\n}\\n',\n",
       "       'void appcachehost::selectcacheforsharedworker(int64 appcache_id) {\\n   dcheck(pending_start_update_callback_.is_null() &&\\n          pending_swap_cache_callback_.is_null() &&\\n          pending_get_status_callback_.is_null() &&\\n         !is_selection_pending() && !was_select_cache_called_);\\n   was_select_cache_called_ = true;\\n   if (appcache_id != kappcachenocacheid) {\\n     loadselectedcache(appcache_id);\\n    return;\\n   }\\n   finishcacheselection(null, null);\\n }\\n',\n",
       "       'void browserpolicyconnector::setdevicecredentials(\\n     const std::string& owner_email,\\n     const std::string& token,\\n     tokentype token_type) {\\n#if defined(os_chromeos)\\n  if (device_data_store_.get()) {\\n    device_data_store_->set_user_name(owner_email);\\n    switch (token_type) {\\n      case token_type_oauth:\\n        device_data_store_->setoauthtoken(token);\\n        break;\\n      case token_type_gaia:\\n        device_data_store_->setgaiatoken(token);\\n        break;\\n      default:\\n        notreached() << \"invalid token type \" << token_type;\\n    }\\n  }\\n#endif\\n}\\n',\n",
       "       'static void willremovechildren(containernode* container)\\n{\\n     nodevector children;\\n     getchildnodes(container, children);\\n    container->document().nodechildrenwillberemoved(container);\\n     childlistmutationscope mutation(container);\\n     for (nodevector::const_iterator it = children.begin(); it != children.end(); it++) {\\n         node* child = it->get();\\n        mutation.willremovechild(child);\\n        child->notifymutationobserversnodewilldetach();\\n        dispatchchildremovalevents(child);\\n    }\\n    childframedisconnector(container).disconnect(childframedisconnector::descendantsonly);\\n}\\n',\n",
       "       'void browser::findinpage(bool find_next, bool forward_direction) {\\n  showfindbar();\\n  if (find_next) {\\n    string16 find_text;\\n#if defined(os_macosx)\\n     find_text = getfindpboardtext();\\n #endif\\n     getselectedtabcontentswrapper()->\\n        getfindmanager()->startfinding(find_text,\\n                                       forward_direction,\\n                                       false);  // not case sensitive.\\n   }\\n }\\n',\n",
       "       'void socketstreamdispatcherhost::onsslcertificateerror(\\n    net::socketstream* socket, const net::sslinfo& ssl_info, bool fatal) {\\n  int socket_id = socketstreamhost::socketidfromsocketstream(socket);\\n  dvlog(1) << \"socketstreamdispatcherhost::onsslcertificateerror socket_id=\"\\n           << socket_id;\\n  if (socket_id == content::knosocketid) {\\n    log(error) << \"nosocketid in onsslcertificateerror\";\\n    return;\\n  }\\n   socketstreamhost* socket_stream_host = hosts_.lookup(socket_id);\\n   dcheck(socket_stream_host);\\n   content::globalrequestid request_id(-1, socket_id);\\n  sslmanager::onsslcertificateerror(ssl_delegate_weak_factory_.getweakptr(),\\n      request_id, resourcetype::sub_resource, socket->url(),\\n       render_process_id_, socket_stream_host->render_view_id(), ssl_info,\\n       fatal);\\n }\\n',\n",
       "       'bool partialmagnificationcontroller::ispartialmagnified() const {\\n  return scale_ >= kminpartialmagnifiedscalethreshold;\\n}\\n',\n",
       "       '   void startanimation() {\\n    if (!getcompositor()->hasanimationobserver(this))\\n      getcompositor()->addanimationobserver(this);\\n   }\\n',\n",
       "       'void messageservice::openchanneltoextension(\\n    int source_process_id, int source_routing_id, int receiver_port_id,\\n    const std::string& source_extension_id,\\n    const std::string& target_extension_id,\\n    const std::string& channel_name) {\\n  content::renderprocesshost* source =\\n      content::renderprocesshost::fromid(source_process_id);\\n  if (!source)\\n    return;\\n  profile* profile = profile::frombrowsercontext(source->getbrowsercontext());\\n  messageport* receiver = new extensionmessageport(\\n      getextensionprocess(profile, target_extension_id), msg_routing_control,\\n      target_extension_id);\\n  webcontents* source_contents = tab_util::getwebcontentsbyid(\\n      source_process_id, source_routing_id);\\n   std::string tab_json = \"null\";\\n   if (source_contents) {\\n     scoped_ptr<dictionaryvalue> tab_value(extensiontabutil::createtabvalue(\\n        source_contents, extensiontabutil::include_privacy_sensitive_fields));\\n     base::jsonwriter::write(tab_value.get(), &tab_json);\\n   }\\n  openchannelparams* params = new openchannelparams(source, tab_json, receiver,\\n                                                    receiver_port_id,\\n                                                    source_extension_id,\\n                                                    target_extension_id,\\n                                                    channel_name);\\n  if (maybeaddpendingopenchanneltask(profile, params)) {\\n    return;\\n  }\\n  openchannelimpl(scoped_ptr<openchannelparams>(params));\\n}\\n',\n",
       "       ' void frameimpl::goforward() {\\n  notimplemented();\\n }\\n',\n",
       "       ' void workerprocesslaunchertest::killprocess(dword exit_code) {\\n  exit_code_ = exit_code;\\n   bool result = setevent(process_exit_event_);\\n   expect_true(result);\\n }\\n',\n",
       "       ' void translatemessageinfobar::layout() {\\n   translateinfobarbase::layout();\\n  int x = icon_->bounds().right() + infobar::kiconlabelspacing;\\n   gfx::size label_pref_size = label_->getpreferredsize();\\n   int available_width = getavailablewidth() - x;\\n   gfx::size button_pref_size;\\n   if (button_) {\\n     button_pref_size = button_->getpreferredsize();\\n     available_width -=\\n        (button_pref_size.width() + infobar::kbuttoninlabelspacing);\\n   }\\n  label_->setbounds(x, infobar::offsety(this, label_pref_size),\\n                     std::min(label_pref_size.width(), available_width),\\n                     label_pref_size.height());\\n   if (button_) {\\n     button_->setbounds(label_->bounds().right() +\\n                          infobar::kbuttoninlabelspacing,\\n                       infobar::offsety(this, button_pref_size),\\n                        button_pref_size.width(), button_pref_size.height());\\n   }\\n }\\n',\n",
       "       'void hostcache::set(const key& key,\\n                    const entry& entry,\\n                    base::timeticks now,\\n                    base::timedelta ttl) {\\n  trace_event0(knettracingcategory, \"hostcache::set\");\\n  dcheck_called_on_valid_thread(thread_checker_);\\n   if (caching_is_disabled())\\n     return;\\n   auto it = entries_.find(key);\\n   if (it != entries_.end()) {\\n     bool is_stale = it->second.isstale(now, network_changes_);\\n     recordset(is_stale ? set_update_stale : set_update_valid, now, &it->second,\\n              entry);\\n     entries_.erase(it);\\n   } else {\\n     if (size() == max_entries_)\\n       evictoneentry(now);\\n    recordset(set_insert, now, nullptr, entry);\\n   }\\n   addentry(key(key), entry(entry, now, ttl, network_changes_));\\n }\\n',\n",
       "       ' storagehandler::storagehandler()\\n     : devtoolsdomainhandler(storage::metainfo::domainname),\\n      process_(nullptr),\\n       weak_ptr_factory_(this) {}\\n',\n",
       "       ' void bluetoothdevicechromeos::rejectpairing() {\\n  runpairingcallbacks(rejected);\\n }\\n',\n",
       "       'renderwidgethostimpl* webcontentsimpl::getrenderwidgethostwithpagefocus() {\\n  webcontentsimpl* focused_web_contents = getfocusedwebcontents();\\n   if (focused_web_contents->showinginterstitialpage()) {\\n     return static_cast<renderframehostimpl*>(\\n               focused_web_contents->getrendermanager()\\n                   ->interstitial_page()\\n                   ->getmainframe())\\n         ->getrenderwidgethost();\\n   }\\n  return focused_web_contents->getmainframe()->getrenderwidgethost();\\n}\\n',\n",
       "       ' dictionaryvalue* extensiontabutil::createtabvalue(\\n     const webcontents* contents,\\n     tabstripmodel* tab_strip,\\n    int tab_index,\\n    includeprivacysensitivefields include_privacy_sensitive_fields) {\\n   notimplemented();\\n   return null;\\n }\\n',\n",
       "       'inline void pulseaudiomixer::mainloopunlock() const {\\n   --mainloop_lock_count_;\\n   pa_threaded_mainloop_unlock(pa_mainloop_);\\n }\\n',\n",
       "       'void unloadcontroller::tabdetachedimpl(tabcontents* contents) {\\n   if (is_attempting_to_close_browser_)\\n    clearunloadstate(contents->web_contents(), false);\\n  registrar_.remove(\\n      this,\\n      content::notification_web_contents_disconnected,\\n      content::source<content::webcontents>(contents->web_contents()));\\n }\\n',\n",
       "       'scrollanchor::examineresult scrollanchor::examine(\\n    const layoutobject* candidate) const {\\n  if (candidate == scrollerlayoutbox(scroller_))\\n    return examineresult(kcontinue);\\n  if (candidate->styleref().overflowanchor() == eoverflowanchor::knone)\\n    return examineresult(kskip);\\n  if (candidate->islayoutinline())\\n    return examineresult(kcontinue);\\n  if (candidate->isanonymous())\\n    return examineresult(kcontinue);\\n  if (!candidate->istext() && !candidate->isbox())\\n    return examineresult(kskip);\\n  if (!candidatemaymovewithscroller(candidate, scroller_))\\n    return examineresult(kskip);\\n  layoutrect candidate_rect = relativebounds(candidate, scroller_);\\n   layoutrect visible_rect =\\n       scrollerlayoutbox(scroller_)->overflowcliprect(layoutpoint());\\n   bool occupies_space =\\n       candidate_rect.width() > 0 && candidate_rect.height() > 0;\\n   if (occupies_space && visible_rect.intersects(candidate_rect)) {\\n    return examineresult(\\n        visible_rect.contains(candidate_rect) ? kreturn : kconstrain,\\n        cornertoanchor(scroller_));\\n  } else {\\n    return examineresult(kskip);\\n  }\\n}\\n',\n",
       "       'bool paramtraits<logfont>::read(const message* m, pickleiterator* iter,\\n                                 param_type* r) {\\n   const char *data;\\n   int data_size = 0;\\n  bool result = m->readdata(iter, &data, &data_size);\\n  if (result && data_size == sizeof(logfont)) {\\n    memcpy(r, data, sizeof(logfont));\\n  } else {\\n    result = false;\\n    notreached();\\n   }\\n  return result;\\n }\\n',\n",
       "       '   void createpersistentmemoryallocator() {\\n    globalhistogramallocator::getcreatehistogramresulthistogram();\\n     globalhistogramallocator::createwithlocalmemory(\\n         kallocatormemorysize, 0, \"sparsehistogramallocatortest\");\\n     allocator_ = globalhistogramallocator::get()->memory_allocator();\\n  }\\n',\n",
       "       ' void eventreaderlibevdevcros::onfilecanreadwithoutblocking(int fd) {\\n   if (evdevread(&evdev_)) {\\n     if (errno == eintr || errno == eagain)\\n       return;\\n    if (errno != enodev)\\n      plog(error) << \"error reading device \" << path_.value();\\n    stop();\\n    return;\\n  }\\n}\\n',\n",
       "       'void automationprovider::windowgetviewbounds(int handle, int view_id,\\n                                             bool screen_coordinates,\\n                                             bool* success,\\n                                             gfx::rect* bounds) {\\n  *success = false;\\n  gtkwindow* window = window_tracker_->getresource(handle);\\n  if (window) {\\n    gtkwidget* widget = viewidutil::getwidget(gtk_widget(window),\\n                                              static_cast<viewid>(view_id));\\n     if (!widget)\\n       return;\\n     *success = true;\\n    *bounds = gfx::rect(0, 0,\\n                        widget->allocation.width, widget->allocation.height);\\n     gint x, y;\\n     if (screen_coordinates) {\\n       gfx::point point = gtk_util::getwidgetscreenposition(widget);\\n      x = point.x();\\n      y = point.y();\\n    } else {\\n      gtk_widget_translate_coordinates(widget, gtk_widget(window),\\n                                       0, 0, &x, &y);\\n    }\\n    bounds->set_origin(gfx::point(x, y));\\n  }\\n}\\n',\n",
       "       'bool sharedmemoryhandleprovider::initfrommojohandle(\\n    mojo::scopedsharedbufferhandle buffer_handle) {\\n#if dcheck_is_on()\\n  dcheck_eq(map_ref_count_, 0);\\n#endif\\n   dcheck(!shared_memory_);\\n   base::sharedmemoryhandle memory_handle;\\n  const mojoresult result =\\n      mojo::unwrapsharedmemoryhandle(std::move(buffer_handle), &memory_handle,\\n                                     &mapped_size_, &read_only_flag_);\\n   if (result != mojo_result_ok)\\n     return false;\\n   shared_memory_.emplace(memory_handle, read_only_flag_);\\n   return true;\\n }\\n',\n",
       "       'void renderthreadimpl::shutdown() {\\n  for_each_observer(\\n      renderprocessobserver, observers_, onrenderprocessshutdown());\\n  childthread::shutdown();\\n  if (memory_observer_) {\\n    message_loop()->removetaskobserver(memory_observer_.get());\\n    memory_observer_.reset();\\n  }\\n   if (webkit_platform_support_) {\\n     webkit_platform_support_->web_database_observer_impl()->\\n         waitforalldatabasestoclose();\\n   }\\n  if (devtools_agent_message_filter_.get()) {\\n    removefilter(devtools_agent_message_filter_.get());\\n    devtools_agent_message_filter_ = null;\\n  }\\n  removefilter(audio_input_message_filter_.get());\\n  audio_input_message_filter_ = null;\\n  removefilter(audio_message_filter_.get());\\n  audio_message_filter_ = null;\\n#if defined(enable_webrtc)\\n  rtcpeerconnectionhandler::destructallhandlers();\\n  peer_connection_factory_.reset();\\n#endif\\n  removefilter(vc_manager_->video_capture_message_filter());\\n  vc_manager_.reset();\\n  removefilter(db_message_filter_.get());\\n  db_message_filter_ = null;\\n  if (file_thread_)\\n    file_thread_->stop();\\n  if (compositor_output_surface_filter_.get()) {\\n    removefilter(compositor_output_surface_filter_.get());\\n    compositor_output_surface_filter_ = null;\\n  }\\n  media_thread_.reset();\\n  compositor_thread_.reset();\\n  input_handler_manager_.reset();\\n  if (input_event_filter_.get()) {\\n    removefilter(input_event_filter_.get());\\n    input_event_filter_ = null;\\n  }\\n  embedded_worker_dispatcher_.reset();\\n  main_thread_indexed_db_dispatcher_.reset();\\n  if (webkit_platform_support_)\\n    blink::shutdown();\\n  lazy_tls.pointer()->set(null);\\n#if defined(os_win)\\n  npchannelbase::cleanupchannels();\\n#endif\\n}\\n',\n",
       "       '   mockaudiorendererhost(base::runloop* auth_run_loop,\\n                         int render_process_id,\\n                         media::audiomanager* audio_manager,\\n                         audiomirroringmanager* mirroring_manager,\\n                         mediastreammanager* media_stream_manager,\\n                         const std::string& salt)\\n       : audiorendererhost(render_process_id,\\n                           audio_manager,\\n                           mirroring_manager,\\n                           media_stream_manager,\\n                           salt),\\n        shared_memory_length_(0),\\n        auth_run_loop_(auth_run_loop) {\\n    set_render_frame_id_validate_function_for_testing(&validaterenderframeid);\\n  }\\n',\n",
       "       ' x11surfacefactory::getallowedglimplementations() {\\n   std::vector<gl::glimplementation> impls;\\n   impls.push_back(gl::kglimplementationeglgles2);\\n  impls.push_back(gl::kglimplementationdesktopgl);\\n  impls.push_back(gl::kglimplementationosmesagl);\\n  return impls;\\n }\\n',\n",
       "       ' void networkhandler::clearbrowsercookies(\\n     std::unique_ptr<clearbrowsercookiescallback> callback) {\\n  if (!process_) {\\n     callback->sendfailure(response::internalerror());\\n     return;\\n   }\\n  browserthread::posttask(\\n       browserthread::io, from_here,\\n       base::bindonce(\\n           &clearcookiesonio,\\n          base::unretained(\\n              process_->getstoragepartition()->geturlrequestcontext()),\\n           std::move(callback)));\\n }\\n',\n",
       "       'void webgl2renderingcontextbase::teximage3d(\\n    glenum target,\\n    glint level,\\n    glint internalformat,\\n    glsizei width,\\n    glsizei height,\\n    glsizei depth,\\n    glint border,\\n    glenum format,\\n    glenum type,\\n    maybeshared<domarraybufferview> pixels,\\n    gluint src_offset) {\\n  if (iscontextlost())\\n    return;\\n  if (bound_pixel_unpack_buffer_) {\\n    synthesizeglerror(gl_invalid_operation, \"teximage3d\",\\n                       \"a buffer is bound to pixel_unpack_buffer\");\\n     return;\\n   }\\n   teximagehelperdomarraybufferview(\\n       kteximage3d, target, level, internalformat, width, height, depth, border,\\n       format, type, 0, 0, 0, pixels.view(), knullnotreachable, src_offset);\\n}\\n',\n",
       "       'void conversioncontext::convert(const paintchunksubset& paint_chunks,\\n                                const displayitemlist& display_items) {\\n  for (const auto& chunk : paint_chunks) {\\n    const auto& chunk_state = chunk.properties;\\n    bool switched_to_chunk_state = false;\\n    for (const auto& item : display_items.itemsinpaintchunk(chunk)) {\\n      dcheck(item.isdrawing());\\n      auto record =\\n          static_cast<const drawingdisplayitem&>(item).getpaintrecord();\\n       if ((!record || record->size() == 0) &&\\n          chunk_state.effect() == effectpaintpropertynode::root()) {\\n         continue;\\n       }\\n      translateforlayeroffsetonce();\\n      if (!switched_to_chunk_state) {\\n        switchtochunkstate(chunk);\\n        switched_to_chunk_state = true;\\n      }\\n      cc_list_.startpaint();\\n      if (record && record->size() != 0)\\n        cc_list_.push<cc::drawrecordop>(std::move(record));\\n      cc_list_.endpaintofunpaired(\\n          chunk_to_layer_mapper_.mapvisualrect(item.visualrect()));\\n    }\\n    updateeffectbounds(chunk.bounds, chunk_state.transform());\\n  }\\n}\\n',\n",
       "       'void mojovideoencodeaccelerator::useoutputbitstreambuffer(\\n    const bitstreambuffer& buffer) {\\n  dvlog(2) << __func__ << \" buffer.id()= \" << buffer.id()\\n            << \" buffer.size()= \" << buffer.size() << \"b\";\\n   dcheck_called_on_valid_sequence(sequence_checker_);\\n   mojo::scopedsharedbufferhandle buffer_handle = mojo::wrapsharedmemoryhandle(\\n      buffer.handle().duplicate(), buffer.size(), true /* read_only */);\\n   vea_->useoutputbitstreambuffer(buffer.id(), std::move(buffer_handle));\\n }\\n',\n",
       "       'bool glsurfaceeglsurfacecontrol::resize(const gfx::size& size,\\n                                         float scale_factor,\\n                                         colorspace color_space,\\n                                         bool has_alpha) {\\n   return true;\\n }\\n',\n",
       "       '  static void focusincallback(ibuspanelservice* panel,\\n                              const gchar* path,\\n                              gpointer user_data) {\\n    g_return_if_fail(user_data);\\n    inputmethodstatusconnection* self\\n        = static_cast<inputmethodstatusconnection*>(user_data);\\n    self->focusin(path);\\n   }\\n',\n",
       "       'bool debuggerattachfunction::runasync() {\\n  std::unique_ptr<attach::params> params(attach::params::create(*args_));\\n  extension_function_validate(params.get());\\n  copydebuggee(&debuggee_, params->target);\\n  if (!initagenthost())\\n    return false;\\n  if (!devtoolsagenthost::issupportedprotocolversion(\\n          params->required_version)) {\\n    error_ = errorutils::formaterrormessage(\\n        keys::kprotocolversionnotsupportederror,\\n        params->required_version);\\n    return false;\\n  }\\n  if (findclienthost()) {\\n    formaterrormessage(keys::kalreadyattachederror);\\n     return false;\\n   }\\n  new extensiondevtoolsclienthost(getprofile(), agent_host_.get(),\\n                                  extension()->id(), extension()->name(),\\n                                  debuggee_);\\n   sendresponse(true);\\n   return true;\\n }\\n',\n",
       "       '  static void connectionchangehandler(void* object, bool connected) {\\n     if (!browserthread::currentlyon(browserthread::ui)) {\\n       log(error) << \"not on ui thread\";\\n       return;\\n     }\\n    inputmethodlibraryimpl* input_method_library =\\n        static_cast<inputmethodlibraryimpl*>(object);\\n    input_method_library->ime_connected_ = connected;\\n     if (connected) {\\n      input_method_library->pending_config_requests_.clear();\\n      input_method_library->pending_config_requests_.insert(\\n          input_method_library->current_config_values_.begin(),\\n          input_method_library->current_config_values_.end());\\n      input_method_library->flushimeconfig();\\n      input_method_library->changeinputmethod(\\n          input_method_library->previous_input_method().id);\\n      input_method_library->changeinputmethod(\\n          input_method_library->current_input_method().id);\\n     }\\n   }\\n',\n",
       "       'idnspoofchecker::idnspoofchecker() {\\n  uerrorcode status = u_zero_error;\\n  checker_ = uspoof_open(&status);\\n  if (u_failure(status)) {\\n    checker_ = nullptr;\\n    return;\\n  }\\n  uspoof_setrestrictionlevel(checker_, uspoof_moderately_restrictive);\\n  setallowedunicodeset(&status);\\n  int32_t checks = uspoof_getchecks(checker_, &status) | uspoof_aux_info;\\n  uspoof_setchecks(checker_, checks, &status);\\n  deviation_characters_ =\\n      icu::unicodeset(unicode_string_simple(\"[\\\\\\\\u00df\\\\\\\\u03c2\\\\\\\\u200c\\\\\\\\u200d]\"),\\n                      status);\\n  deviation_characters_.freeze();\\n  non_ascii_latin_letters_ = icu::unicodeset(\\n      unicode_string_simple(\"[[:latin:] - [a-za-z]]\"), status);\\n  non_ascii_latin_letters_.freeze();\\n  kana_letters_exceptions_ = icu::unicodeset(unicode_string_simple(\\n       \"[\\\\\\\\u3078-\\\\\\\\u307a\\\\\\\\u30d8-\\\\\\\\u30da\\\\\\\\u30fb\\\\\\\\u30fc]\"), status);\\n   kana_letters_exceptions_.freeze();\\n   dcheck(u_success(status));\\n }\\n',\n",
       "       ' void offscreencanvas::dispose() {\\n   if (context_) {\\n     context_->detachhost();\\n     context_ = nullptr;\\n  }\\n  if (hasplaceholdercanvas() && gettopexecutioncontext() &&\\n      gettopexecutioncontext()->isworkerglobalscope()) {\\n    workeranimationframeprovider* animation_frame_provider =\\n        to<workerglobalscope>(gettopexecutioncontext())\\n            ->getanimationframeprovider();\\n    if (animation_frame_provider)\\n      animation_frame_provider->deregisteroffscreencanvas(this);\\n  }\\n}\\n',\n",
       "       'static v8::handle<v8::value> enabledatruntimemethod2callback(const v8::arguments& args)\\n {\\n     inc_stats(\"dom.testobj.enabledatruntimemethod2\");\\n     if (args.length() < 1)\\n        return v8proxy::thrownotenoughargumentserror();\\n     testobj* imp = v8testobj::tonative(args.holder());\\n     exception_block(int, intarg, v8int::hasinstance(maybe_missing_parameter(args, 0, defaultisundefined)) ? v8int::tonative(v8::handle<v8::object>::cast(maybe_missing_parameter(args, 0, defaultisundefined))) : 0);\\n     imp->enabledatruntimemethod2(intarg);\\n    return v8::handle<v8::value>();\\n}\\n',\n",
       "       'void logoservice::setlogocachefortests(std::unique_ptr<logocache> cache) {\\n  logo_cache_for_test_ = std::move(cache);\\n}\\n',\n",
       "       'bool fileutilproxy::write(\\n    scoped_refptr<messageloopproxy> message_loop_proxy,\\n    platformfile file,\\n    int64 offset,\\n     const char* buffer,\\n     int bytes_to_write,\\n     writecallback* callback) {\\n  if (bytes_to_write <= 0)\\n     return false;\\n   return start(from_here, message_loop_proxy,\\n                new relaywrite(file, offset, buffer, bytes_to_write, callback));\\n }\\n',\n",
       "       'bool cclayertreehost::initialize()\\n{\\n    trace_event(\"cclayertreehost::initialize\", this, 0);\\n    if (m_settings.enablecompositorthread) {\\n        m_settings.acceleratepainting = false;\\n        m_settings.showfpscounter = false;\\n        m_settings.showplatformlayertree = false;\\n        m_proxy = ccthreadproxy::create(this);\\n    } else\\n        m_proxy = ccsinglethreadproxy::create(this);\\n    m_proxy->start();\\n    if (!m_proxy->initializelayerrenderer())\\n        return false;\\n    m_compositoridentifier = m_proxy->compositoridentifier();\\n     m_settings.acceleratepainting = m_proxy->layerrenderercapabilities().usingacceleratedpainting;\\n    setneedscommitthenredraw();\\n     m_contentstexturemanager = texturemanager::create(texturemanager::highlimitbytes(), m_proxy->layerrenderercapabilities().maxtexturesize);\\n     return true;\\n }\\n',\n",
       "       'void storagehandler::setrenderer(renderprocesshost* process_host,\\n                                  renderframehostimpl* frame_host) {\\n  process_ = process_host;\\n }\\n',\n",
       "       ' void acceleratedstaticbitmapimage::retainoriginalskimage() {\\n   dcheck(texture_holder_->isskiatextureholder());\\n   original_skia_image_ = texture_holder_->getskimage();\\n   original_skia_image_context_provider_wrapper_ = contextproviderwrapper();\\n   dcheck(original_skia_image_);\\n   thread* thread = platform::current()->currentthread();\\n  original_skia_image_thread_id_ = thread->threadid();\\n   original_skia_image_task_runner_ = thread->gettaskrunner();\\n }\\n',\n",
       "       'void renderviewimpl::onswapout(const viewmsg_swapout_params& params) {\\n  onstop();\\n  if (!is_swapped_out_) {\\n    syncnavigationstate();\\n    webview()->dispatchunloadevent();\\n    setswappedout(true);\\n    weburlrequest request(gurl(\"about:swappedout\"));\\n     webview()->mainframe()->loadrequest(request);\\n   }\\n  send(new viewhostmsg_swapout_ack(routing_id_, params));\\n}\\n',\n",
       "       '  void gobackcrosssite() {\\n     navigationentry* entry = contents()->controller().getentryatoffset(-1);\\n     assert_true(entry);\\n     contents()->controller().goback();\\n    contents()->testdidnavigate(\\n        contents()->pending_rvh(), entry->page_id(), gurl(entry->url()),\\n        content::page_transition_typed);\\n   }\\n',\n",
       "       'v8contextnativehandler::v8contextnativehandler(scriptcontext* context,\\n                                               dispatcher* dispatcher)\\n    : objectbackednativehandler(context),\\n      context_(context),\\n      dispatcher_(dispatcher) {\\n  routefunction(\"getavailability\",\\n                base::bind(&v8contextnativehandler::getavailability,\\n                           base::unretained(this)));\\n  routefunction(\"getmodulesystem\",\\n                 base::bind(&v8contextnativehandler::getmodulesystem,\\n                            base::unretained(this)));\\n   routefunction(\\n      \"runwithnativesenabledmodulesystem\",\\n      base::bind(&v8contextnativehandler::runwithnativesenabledmodulesystem,\\n                  base::unretained(this)));\\n }\\n',\n",
       "       'void inspectoroverlay::update()\\n{\\n    if (isempty()) {\\n        m_client->hidehighlight();\\n        return;\\n    }\\n    frameview* view = m_page->mainframe()->view();\\n    if (!view)\\n        return;\\n    intrect viewrect = view->visiblecontentrect();\\n    frameview* overlayview = overlaypage()->mainframe()->view();\\n    intsize frameviewfullsize = view->visiblecontentrect(scrollablearea::includescrollbars).size();\\n    intsize size = m_size.isempty() ? frameviewfullsize : m_size;\\n    size.scale(m_page->pagescalefactor());\\n    overlayview->resize(size);\\n    reset(size, m_size.isempty() ? intsize() : frameviewfullsize, viewrect.x(), viewrect.y());\\n    drawgutter();\\n    drawnodehighlight();\\n    drawquadhighlight();\\n     if (!m_inspectmodeenabled)\\n         drawpausedindebuggermessage();\\n     drawviewsize();\\n    drawoverridesmessage();\\n     overlaypage()->mainframe()->document()->recalcstyle(force);\\n    if (overlayview->needslayout())\\n        overlayview->layout();\\n    m_client->highlight();\\n}\\n',\n",
       "       ' void hostcache::clear() {\\n   dcheck_called_on_valid_thread(thread_checker_);\\n   recorderaseall(erase_clear, base::timeticks::now());\\n   entries_.clear();\\n }\\n',\n",
       "       'void mojojpegdecodeaccelerator::decode(\\n    const bitstreambuffer& bitstream_buffer,\\n    const scoped_refptr<videoframe>& video_frame) {\\n  dcheck(io_task_runner_->belongstocurrentthread());\\n  dcheck(jpeg_decoder_.is_bound());\\n  dcheck(\\n      base::sharedmemory::ishandlevalid(video_frame->shared_memory_handle()));\\n  base::sharedmemoryhandle output_handle =\\n      base::sharedmemory::duplicatehandle(video_frame->shared_memory_handle());\\n  if (!base::sharedmemory::ishandlevalid(output_handle)) {\\n    dlog(error) << \"failed to duplicate handle of videoframe\";\\n    return;\\n  }\\n   size_t output_buffer_size = videoframe::allocationsize(\\n       video_frame->format(), video_frame->coded_size());\\n   mojo::scopedsharedbufferhandle output_frame_handle =\\n      mojo::wrapsharedmemoryhandle(output_handle, output_buffer_size,\\n                                   false /* read_only */);\\n   jpeg_decoder_->decode(bitstream_buffer, video_frame->coded_size(),\\n                        std::move(output_frame_handle),\\n                        base::checked_cast<uint32_t>(output_buffer_size),\\n                        base::bind(&mojojpegdecodeaccelerator::ondecodeack,\\n                                   base::unretained(this)));\\n}\\n',\n",
       "       'vp9parser::frameinfo::frameinfo(const uint8_t* ptr, off_t size)\\n    : ptr(ptr), size(size) {}\\n',\n",
       "       'static v8::handle<v8::value> excitingfunctioncallback(const v8::arguments& args)\\n {\\n     inc_stats(\"dom.testactivedomobject.excitingfunction\");\\n     if (args.length() < 1)\\n        return v8proxy::thrownotenoughargumentserror();\\n     testactivedomobject* imp = v8testactivedomobject::tonative(args.holder());\\n     if (!v8bindingsecurity::canaccessframe(v8bindingstate::only(), imp->frame(), true))\\n         return v8::handle<v8::value>();\\n    exception_block(node*, nextchild, v8node::hasinstance(maybe_missing_parameter(args, 0, defaultisundefined)) ? v8node::tonative(v8::handle<v8::object>::cast(maybe_missing_parameter(args, 0, defaultisundefined))) : 0);\\n    imp->excitingfunction(nextchild);\\n    return v8::handle<v8::value>();\\n}\\n',\n",
       "       ' void appmodaldialog::completedialog() {\\n  appmodaldialogqueue::getinstance()->shownextdialog();\\n }\\n',\n",
       "       'void bluetoothdevicechromeos::displaypasskey(\\n    const dbus::objectpath& device_path,\\n    uint32 passkey,\\n    uint16 entered) {\\n  dcheck(agent_.get());\\n  dcheck(device_path == object_path_);\\n  vlog(1) << object_path_.value() << \": displaypasskey: \" << passkey\\n          << \" (\" << entered << \" entered)\";\\n  if (entered == 0)\\n    uma_histogram_enumeration(\"bluetooth.pairingmethod\",\\n                              uma_pairing_method_display_passkey,\\n                              uma_pairing_method_count);\\n  dcheck(pairing_delegate_);\\n  if (entered == 0)\\n    pairing_delegate_->displaypasskey(this, passkey);\\n  pairing_delegate_->keysentered(this, entered);\\n  pairing_delegate_used_ = true;\\n}\\n',\n",
       "       'void registrationmanager::setregisteredids(const objectidset& ids) {\\n   dcheck(calledonvalidthread());\\n   const objectidset& old_ids = getregisteredids();\\n  const objectidset& to_register = ids;\\n  objectidset to_unregister;\\n  std::set_difference(old_ids.begin(), old_ids.end(),\\n                      ids.begin(), ids.end(),\\n                      std::inserter(to_unregister, to_unregister.begin()),\\n                      objectidlessthan());\\n  for (objectidset::const_iterator it = to_unregister.begin();\\n       it != to_unregister.end(); ++it) {\\n    unregisterid(*it);\\n  }\\n  for (objectidset::const_iterator it = to_register.begin();\\n       it != to_register.end(); ++it) {\\n    if (!containskey(registration_statuses_, *it)) {\\n      registration_statuses_.insert(\\n          std::make_pair(*it, new registrationstatus(*it, this)));\\n    }\\n    if (!isidregistered(*it)) {\\n      tryregisterid(*it, false /* is-retry */);\\n    }\\n  }\\n}\\n',\n",
       "       'webcontents* tabscapturevisibletabfunction::getwebcontentsforid(\\n    int window_id,\\n    std::string* error) {\\n  browser* browser = null;\\n  if (!getbrowserfromwindowid(chrome_details_, window_id, &browser, error))\\n    return nullptr;\\n  webcontents* contents = browser->tab_strip_model()->getactivewebcontents();\\n  if (!contents) {\\n    *error = \"no active web contents to capture\";\\n    return nullptr;\\n  }\\n   if (!extension()->permissions_data()->cancapturevisiblepage(\\n           contents->getlastcommittedurl(),\\n          sessiontabhelper::idfortab(contents).id(), error)) {\\n     return nullptr;\\n   }\\n   return contents;\\n}\\n',\n",
       "       'void updatecontentlengthprefs(int received_content_length,\\n                              int original_content_length,\\n                              bool via_data_reduction_proxy) {\\n   dcheck(browserthread::currentlyon(browserthread::ui));\\n   dcheck_ge(received_content_length, 0);\\n   dcheck_ge(original_content_length, 0);\\n  if (!g_browser_process)\\n    return;\\n  prefservice* prefs = g_browser_process->local_state();\\n  if (!prefs)\\n    return;\\n#if defined(os_android)\\n  bool with_data_reduction_proxy_enabled =\\n      g_browser_process->profile_manager()->getdefaultprofile()->\\n      getprefs()->getboolean(prefs::kspdyproxyauthenabled);\\n#else\\n  bool with_data_reduction_proxy_enabled = false;\\n#endif\\n  chrome_browser_net::updatecontentlengthprefs(\\n       received_content_length,\\n       original_content_length,\\n       with_data_reduction_proxy_enabled,\\n      via_data_reduction_proxy, prefs);\\n }\\n',\n",
       "       ' static encodedjsvalue jsc_host_call jstestobjconstructorfunctionoverloadedmethod12(execstate* exec)\\n {\\n     if (exec->argumentcount() < 1)\\n        return throwvmerror(exec, createtypeerror(exec, \"not enough arguments\"));\\n     const string& type(ustringtostring(maybe_missing_parameter(exec, 0, defaultisundefined).isempty() ? ustring() : maybe_missing_parameter(exec, 0, defaultisundefined).tostring(exec)->value(exec)));\\n     if (exec->hadexception())\\n         return jsvalue::encode(jsundefined());\\n    testobj::overloadedmethod1(type);\\n    return jsvalue::encode(jsundefined());\\n}\\n',\n",
       "       'uint32_t clientsharedbitmapmanager::notifyallocatedsharedbitmap(\\n    base::sharedmemory* memory,\\n    const sharedbitmapid& id) {\\n  base::sharedmemoryhandle handle_to_send =\\n      base::sharedmemory::duplicatehandle(memory->handle());\\n  if (!base::sharedmemory::ishandlevalid(handle_to_send)) {\\n    log(error) << \"failed to duplicate shared memory handle for bitmap.\";\\n    return 0;\\n   }\\n   mojo::scopedsharedbufferhandle buffer_handle = mojo::wrapsharedmemoryhandle(\\n      handle_to_send, memory->mapped_size(), true /* read_only */);\\n   {\\n     base::autolock lock(lock_);\\n    (*shared_bitmap_allocation_notifier_)\\n        ->didallocatesharedbitmap(std::move(buffer_handle), id);\\n    return ++last_sequence_number_;\\n  }\\n}\\n',\n",
       "       ' void livesynctest::setupmockgaiaresponses() {\\n   username_ = \"user@gmail.com\";\\n   password_ = \"password\";\\n  factory_.reset(new fakeurlfetcherfactory());\\n   factory_->setfakeresponse(kclientloginurl, \"sid=sid\\\\nlsid=lsid\", true);\\n   factory_->setfakeresponse(kgetuserinfourl, \"email=user@gmail.com\", true);\\n   factory_->setfakeresponse(kissueauthtokenurl, \"auth\", true);\\n  factory_->setfakeresponse(ksearchdomaincheckurl, \".google.com\", true);\\n  urlfetcher::set_factory(factory_.get());\\n}\\n',\n",
       "       'bool printrenderframehelper::previewpagerendered(int page_number,\\n                                                 pdfmetafileskia* metafile) {\\n  dcheck_ge(page_number, first_page_index);\\n  if (!print_preview_context_.ismodifiable() ||\\n      !print_preview_context_.generate_draft_pages()) {\\n    dcheck(!metafile);\\n    return true;\\n  }\\n  if (!metafile) {\\n    notreached();\\n    print_preview_context_.set_error(\\n        preview_error_page_rendered_without_metafile);\\n    return false;\\n   }\\n   printhostmsg_didpreviewpage_params preview_page_params;\\n  if (!copymetafiledatatosharedmem(*metafile,\\n                                   &preview_page_params.metafile_data_handle)) {\\n    log(error) << \"copymetafiledatatosharedmem failed\";\\n     print_preview_context_.set_error(preview_error_metafile_copy_failed);\\n     return false;\\n   }\\n  preview_page_params.data_size = metafile->getdatasize();\\n  preview_page_params.page_number = page_number;\\n  preview_page_params.preview_request_id =\\n      print_pages_params_->params.preview_request_id;\\n  send(new printhostmsg_didpreviewpage(routing_id(), preview_page_params));\\n  return true;\\n}\\n',\n",
       "       ' node::insertionnotificationrequest htmlbodyelement::insertedinto(containernode* insertionpoint)\\n {\\n     htmlelement::insertedinto(insertionpoint);\\n    if (insertionpoint->indocument()) {\\n        element* ownerelement = document().ownerelement();\\n        if (ishtmlframeelementbase(ownerelement)) {\\n            htmlframeelementbase& ownerframeelement = tohtmlframeelementbase(*ownerelement);\\n            int marginwidth = ownerframeelement.marginwidth();\\n            if (marginwidth != -1)\\n                setintegralattribute(marginwidthattr, marginwidth);\\n            int marginheight = ownerframeelement.marginheight();\\n            if (marginheight != -1)\\n                setintegralattribute(marginheightattr, marginheight);\\n        }\\n    }\\n    return insertiondone;\\n }\\n',\n",
       "       'void webviewplugin::destroy() {\\n  if (delegate_) {\\n     delegate_->willdestroyplugin();\\n     delegate_ = null;\\n   }\\n  if (container_)\\n    container_->element().setattribute(\"title\", old_title_);\\n   container_ = null;\\n   messageloop::current()->deletesoon(from_here, this);\\n }\\n',\n",
       "       'void downloadcontroller::startandroiddownloadinternal(\\n    const content::resourcerequestinfo::webcontentsgetter& wc_getter,\\n    bool must_download, const downloadinfo& info, bool allowed) {\\n  dcheck_currently_on(browserthread::ui);\\n  if (!allowed)\\n    return;\\n  webcontents* web_contents = wc_getter.run();\\n  if (!web_contents)\\n    return;\\n  base::string16 filename = net::getsuggestedfilename(\\n      info.url, info.content_disposition,\\n      std::string(),  // referrer_charset\\n      std::string(),  // suggested_name\\n      info.original_mime_type,\\n      default_file_name_);\\n  chromedownloaddelegate::fromwebcontents(web_contents)->requesthttpgetdownload(\\n      info.url.spec(), info.user_agent,\\n      info.content_disposition, info.original_mime_type,\\n      info.cookie, info.referer, filename,\\n      info.total_bytes, info.has_user_gesture,\\n      must_download);\\n}\\n',\n",
       "       'void pulseaudiomixer::getaudioinfocallback(pa_context* unused,\\n                                            const pa_sink_info* sink_info,\\n                                            int eol,\\n                                            void* userdata) {\\n  callbackwrapper* data = static_cast<callbackwrapper*>(userdata);\\n  audioinfo* info = static_cast<audioinfo*>(data->userdata);\\n  if (eol == 0) {\\n    info->cvolume = sink_info->volume;\\n    info->muted = sink_info->mute ? true : false;\\n    data->done = true;\\n  }\\n   data->instance->mainloopsignal();\\n }\\n',\n",
       "       'void inspectorhandler::setrenderer(renderprocesshost* process_host,\\n                                    renderframehostimpl* frame_host) {\\n   host_ = frame_host;\\n }\\n',\n",
       "       ' mojo::scopedsharedbufferhandle gamepadprovider::getsharedbufferhandle() {\\n  base::sharedmemoryhandle handle = base::sharedmemory::duplicatehandle(\\n      gamepad_shared_buffer_->shared_memory()->handle());\\n  return mojo::wrapsharedmemoryhandle(handle, sizeof(gamepadhardwarebuffer),\\n                                      true /* read_only */);\\n }\\n'],\n",
       "      dtype='<U3010')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7832154c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   virtual size_t getnumactiveinputmethods() {\n",
      "    scoped_ptr<inputmethoddescriptors> descriptors(getactiveinputmethods());\n",
      "     return descriptors->size();\n",
      "   }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# We choose a sample from test set\n",
    "idx = 0\n",
    "text_sample = true_positives[idx]\n",
    "class_names = ['neutral', 'vulnerable']\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "print(text_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00c2c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline with text encoding and padding, ending with predict_proba\n",
    "def pipeline(text_sample):\n",
    "    model_variation = \"microsoft/codebert-base-mlm\" # \"neulab/codebert-cpp\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_variation, do_lower_case=False) # , do_lower_case=True\n",
    "    codebert = TFAutoModel.from_pretrained(model_variation) # , from_pt=True\n",
    "\n",
    "    codebert_embeddings = codebert.get_input_embeddings()\n",
    "    embedding_matrix = codebert_embeddings.weights[0].numpy()\n",
    "    num_words = len(embedding_matrix)\n",
    "    dim = len(embedding_matrix[0])\n",
    "\n",
    "    sequence = tokenizer(text_sample, return_tensors=\"tf\", truncation=True, add_special_tokens=False)\n",
    "\n",
    "    lines_pad_x_train = padSequences(sequence, max_len)\n",
    "    lines_pad_x_train = [arr.tolist() for arr in lines_pad_x_train]\n",
    "    lines_pad_x_train = np.array(lines_pad_x_train)\n",
    "\n",
    "    #myModel = buildLstmCNN(max_len, num_words, dim, seed, embedding_matrix)\n",
    "    myModel = load_model(\"best_model.h5\", custom_objects={\"f2_metric\": f2_metric})\n",
    "\n",
    "    predScores = myModel.predict(lines_pad_x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "268bd795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at microsoft/codebert-base-mlm were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base-mlm.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50265\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py:717\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[1;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[1;32m--> 717\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[0;32m    720\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03mNote: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m  ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Can't convert non-rectangular Python sequence to Tensor.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [51], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m explainer \u001b[38;5;241m=\u001b[39m LimeTextExplainer(class_names\u001b[38;5;241m=\u001b[39mclass_names)\n\u001b[1;32m----> 2\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m exp\u001b[38;5;241m.\u001b[39mshow_in_notebook(text\u001b[38;5;241m=\u001b[39mtext_sample)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\lime\\lime_text.py:413\u001b[0m, in \u001b[0;36mLimeTextExplainer.explain_instance\u001b[1;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[0;32m    406\u001b[0m indexed_string \u001b[38;5;241m=\u001b[39m (IndexedCharacters(\n\u001b[0;32m    407\u001b[0m     text_instance, bow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbow, mask_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_string)\n\u001b[0;32m    408\u001b[0m                   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchar_level \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m    409\u001b[0m                   IndexedString(text_instance, bow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbow,\n\u001b[0;32m    410\u001b[0m                                 split_expression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_expression,\n\u001b[0;32m    411\u001b[0m                                 mask_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_string))\n\u001b[0;32m    412\u001b[0m domain_mapper \u001b[38;5;241m=\u001b[39m TextDomainMapper(indexed_string)\n\u001b[1;32m--> 413\u001b[0m data, yss, distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__data_labels_distances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexed_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_metric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(yss[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\lime\\lime_text.py:482\u001b[0m, in \u001b[0;36mLimeTextExplainer.__data_labels_distances\u001b[1;34m(self, indexed_string, classifier_fn, num_samples, distance_metric)\u001b[0m\n\u001b[0;32m    480\u001b[0m     data[i, inactive] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    481\u001b[0m     inverse_data\u001b[38;5;241m.\u001b[39mappend(indexed_string\u001b[38;5;241m.\u001b[39minverse_removing(inactive))\n\u001b[1;32m--> 482\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minverse_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    483\u001b[0m distances \u001b[38;5;241m=\u001b[39m distance_fn(sp\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mcsr_matrix(data))\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, labels, distances\n",
      "Cell \u001b[1;32mIn [50], line 13\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(text_sample)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(num_words)\n\u001b[0;32m     11\u001b[0m dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(embedding_matrix[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 13\u001b[0m sequence \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m lines_pad_x_train \u001b[38;5;241m=\u001b[39m padSequences(sequence, max_len)\n\u001b[0;32m     16\u001b[0m lines_pad_x_train \u001b[38;5;241m=\u001b[39m [arr\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m lines_pad_x_train]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2523\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2522\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2523\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_one(text\u001b[38;5;241m=\u001b[39mtext, text_pair\u001b[38;5;241m=\u001b[39mtext_pair, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mall_kwargs)\n\u001b[0;32m   2524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2525\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2609\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2604\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2605\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2606\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2607\u001b[0m         )\n\u001b[0;32m   2608\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[1;32m-> 2609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m   2610\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   2611\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2612\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   2613\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   2614\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   2615\u001b[0m         stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   2616\u001b[0m         is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   2617\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   2618\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2619\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   2620\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   2621\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   2622\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   2623\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   2624\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   2625\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2626\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2627\u001b[0m     )\n\u001b[0;32m   2628\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m   2630\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   2631\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2647\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2648\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2800\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2790\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   2791\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   2792\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   2793\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2797\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2798\u001b[0m )\n\u001b[1;32m-> 2800\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\n\u001b[0;32m   2801\u001b[0m     batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   2802\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2803\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m   2804\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   2805\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   2806\u001b[0m     stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   2807\u001b[0m     is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   2808\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   2809\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2810\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   2811\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   2812\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   2813\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   2814\u001b[0m     return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   2815\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   2816\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2817\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2818\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\models\\roberta\\tokenization_roberta_fast.py:263\u001b[0m, in \u001b[0;36mRobertaTokenizerFast._batch_encode_plus\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    261\u001b[0m )\n\u001b[1;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:477\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids \u001b[38;5;129;01min\u001b[39;00m sanitized_tokens[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)\n\u001b[1;32m--> 477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msanitized_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitized_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py:210\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[1;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[0;32m    206\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py:733\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[1;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    729\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    730\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    731\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    732\u001b[0m             )\n\u001b[1;32m--> 733\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    734\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    735\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    736\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features (`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    737\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    738\u001b[0m         )\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "exp = explainer.explain_instance(text_sample, pipeline, num_features=20)\n",
    "exp.show_in_notebook(text=text_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
